{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pBIGASN0H_e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def sigmoid_derivat(dA, x):\n",
        "  \"\"\"\n",
        "  sigmoid'(x) = x' * sigmoid(x) * (1 - sigmoid(x))\n",
        "  \"\"\"\n",
        "  f = sigmoid(x)\n",
        "\n",
        "  return dA * f * (1- f)\n",
        "\n",
        "def relu_derivat(dA, x):\n",
        "  \"\"\" relu'(x) = [0 daca x <=0 altfel 1] * x' \"\"\"\n",
        "  dX = np.array(dA, copy=True)\n",
        "  dX[x <= 0] = 0\n",
        "  return dX\n"
      ],
      "metadata": {
        "id": "P5_BnPTM1CSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bce(y, y_hat):\n",
        "  n = y.shape[1]\n",
        "  loss = (-1/n)*(np.dot(y, np.log(y_hat).T) + np.dot(1 - y, np.log(1-y_hat).T))\n",
        "\n",
        "  return np.squeeze(loss)"
      ],
      "metadata": {
        "id": "S8HrIAxr2mGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score(y, y_hat):\n",
        "  classes = (y_hat >= 0.5).astype(int)\n",
        "\n",
        "  return (classes == y).mean()"
      ],
      "metadata": {
        "id": "9MNl3LSK4KHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## dA_curr: Gradient of the loss with respect to the current layer's activation\n",
        "## W_curr: Current layer's weights\n",
        "## b_curr: Current layer's biases\n",
        "## Z_curr: Linear combination of inputs (Z = W * A_prev + b)\n",
        "## A_prev: Activations of the previous layer\n",
        "\n",
        "class NN():\n",
        "    \"\"\"\n",
        "    Varianta definire NN cu specificare input si output pentru fiecare unitate. Varianta vectorizata. Implementarile vectorizate consuma mai putine resurse computationale decat cele iterative\n",
        "    \"\"\"\n",
        "    def __init__(self, architecture, random_seed=42):\n",
        "        np.random.seed(random_seed)\n",
        "\n",
        "        self.activation_functions = {\n",
        "            'sigmoid': sigmoid,\n",
        "            'relu': relu\n",
        "        }\n",
        "\n",
        "        self.derivatives = {\n",
        "            'relu': relu_derivat,\n",
        "            'sigmoid': sigmoid_derivat\n",
        "        }\n",
        "\n",
        "\n",
        "        number_of_layers = len(architecture)\n",
        "        params_values = {}\n",
        "\n",
        "        for idx, layer in enumerate(architecture):\n",
        "            layer_idx = idx + 1\n",
        "\n",
        "            layer_input_size = layer[\"input_dim\"]\n",
        "\n",
        "            layer_output_size = layer[\"units\"]\n",
        "\n",
        "            params_values['W' + str(layer_idx)] = np.random.randn(layer_output_size, layer_input_size) * 0.1\n",
        "\n",
        "            params_values['b' + str(layer_idx)] = np.random.randn(layer_output_size, 1) * 0.1\n",
        "\n",
        "\n",
        "        self.params = params_values\n",
        "        self.architecture = architecture\n",
        "\n",
        "    def summary(self):\n",
        "        print(\"{:^15s} {:^15s} {:^15s} {:^15s} {:^15s} {:^15s} \\n\".format(\n",
        "            \"Input shape\",\n",
        "            \"Output shape\",\n",
        "            \"Weights shape\",\n",
        "            \"Bias shape\",\n",
        "            \"Activation\",\n",
        "            \"Params\"\n",
        "        ))\n",
        "        print(\"{:_<100s}\".format(''))\n",
        "        total_params = 0\n",
        "        for idx, layer in enumerate(self.architecture):\n",
        "            layer_idx = idx + 1\n",
        "            in_shape = layer[\"input_dim\"]\n",
        "            out_shape = layer[\"units\"]\n",
        "\n",
        "            weights_shape = self.params['W' + str(layer_idx)].shape\n",
        "            bias_shape = self.params['b' + str(layer_idx)].shape\n",
        "\n",
        "            activation = layer[\"activation\"]\n",
        "\n",
        "            weights_params = 1\n",
        "            for dim in weights_shape:\n",
        "                weights_params *= dim\n",
        "\n",
        "            bias_params = 1\n",
        "            for dim in bias_shape:\n",
        "                bias_params *= dim\n",
        "\n",
        "            num_params = bias_params + weights_params\n",
        "            total_params += num_params\n",
        "\n",
        "            print(\"{:^15d} {:^15d} {:^15s} {:^15s} {:^15s} {:^15d} \\n\".format(\n",
        "                in_shape,\n",
        "                out_shape,\n",
        "                str(weights_shape),\n",
        "                str(bias_shape),\n",
        "                activation,\n",
        "                num_params\n",
        "            ))\n",
        "            print(\"-\"*100)\n",
        "\n",
        "        print(\"Total number of parameters: {}\".format(total_params))\n",
        "\n",
        "    def forward(self, w, b, x, activation='relu'):\n",
        "        z = np.dot(w, x) + b\n",
        "\n",
        "        return self.activation_functions[activation](z), z\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\" Functie cu care realizam predictii prin metoda propagarii inainte. \"\"\"\n",
        "        memory = {}\n",
        "        current_activation = x\n",
        "\n",
        "        for idx, layer in enumerate(self.architecture):\n",
        "            layer_idx = idx + 1\n",
        "            previous_activation = current_activation\n",
        "\n",
        "            activation_function = layer[\"activation\"]\n",
        "\n",
        "            w = self.params[\"W\" + str(layer_idx)]\n",
        "\n",
        "            b = self.params[\"b\" + str(layer_idx)]\n",
        "\n",
        "            current_activation, z = self.forward(w, b, previous_activation, activation_function)\n",
        "\n",
        "            memory[\"x\" + str(idx)] = previous_activation\n",
        "            memory[\"z\" + str(layer_idx)] = z\n",
        "\n",
        "        return current_activation, memory\n",
        "\n",
        "    def backward(self, dA_curr, W_curr, b_curr, Z_curr, A_prev, activation=\"relu\"):\n",
        "        # number of examples\n",
        "        m = A_prev.shape[1]\n",
        "\n",
        "        # selection of activation function\n",
        "        backward_activation_func = self.derivatives[activation]\n",
        "\n",
        "        # calculation of the activation function derivative\n",
        "        dZ_curr = backward_activation_func(dA_curr, Z_curr)\n",
        "\n",
        "        # derivative of the matrix W\n",
        "        dW_curr = np.dot(dZ_curr, A_prev.T) / m\n",
        "        # derivative of the vector b\n",
        "        db_curr = np.sum(dZ_curr, axis=1, keepdims=True) / m\n",
        "        # derivative of the matrix A_prev\n",
        "        dA_prev = np.dot(W_curr.T, dZ_curr)\n",
        "\n",
        "        return dA_prev, dW_curr, db_curr\n",
        "\n",
        "    def backward_propagation(self, Y_hat, Y, memory):\n",
        "        grads_values = {}\n",
        "\n",
        "        # number of examples\n",
        "        m = Y.shape[1]\n",
        "        # a hack ensuring the same shape of the prediction vector and labels vector\n",
        "        Y = Y.reshape(Y_hat.shape)\n",
        "\n",
        "        # initiation of gradient descent algorithm\n",
        "        dA_prev = - (np.divide(Y, Y_hat) - np.divide(1 - Y, 1 - Y_hat));\n",
        "\n",
        "        for layer_idx_prev, layer in reversed(list(enumerate(self.architecture))):\n",
        "            # we number network layers from 1\n",
        "            layer_idx_curr = layer_idx_prev + 1\n",
        "            # extraction of the activation function for the current layer\n",
        "            activ_function_curr = layer[\"activation\"]\n",
        "\n",
        "            dA_curr = dA_prev\n",
        "\n",
        "            A_prev = memory[\"x\" + str(layer_idx_prev)]\n",
        "            Z_curr = memory[\"z\" + str(layer_idx_curr)]\n",
        "\n",
        "            W_curr = self.params[\"W\" + str(layer_idx_curr)]\n",
        "            b_curr = self.params[\"b\" + str(layer_idx_curr)]\n",
        "\n",
        "            dA_prev, dW_curr, db_curr = self.backward(\n",
        "                dA_curr, W_curr, b_curr, Z_curr, A_prev, activ_function_curr)\n",
        "\n",
        "            grads_values[\"dW\" + str(layer_idx_curr)] = dW_curr\n",
        "            grads_values[\"db\" + str(layer_idx_curr)] = db_curr\n",
        "\n",
        "        return grads_values\n",
        "\n",
        "    def update(self, grads_values, learning_rate):\n",
        "        for layer_idx, layer in enumerate(self.architecture, 1):\n",
        "            self.params[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]\n",
        "            self.params[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
        "\n",
        "    def train(self, X, Y, epochs, learning_rate):\n",
        "        cost_history = []\n",
        "        accuracy_history = []\n",
        "\n",
        "        for i in range(epochs):\n",
        "            Y_hat, mem = self.predict(X)\n",
        "            cost = bce(Y, Y_hat)\n",
        "\n",
        "            cost_history.append(cost)\n",
        "            accuracy = accuracy_score(Y, Y_hat)\n",
        "            accuracy_history.append(accuracy)\n",
        "\n",
        "            grads_values = self.backward_propagation(Y_hat, Y, mem)\n",
        "\n",
        "            self.update(grads_values, learning_rate)\n",
        "\n",
        "            if(i % 50 == 0):\n",
        "                print(\"Iteration: {:05} - cost: {:.5f} - accuracy: {:.5f}\".format(i, cost, accuracy))\n",
        "\n",
        "        return cost_history, accuracy_history\n",
        "\n"
      ],
      "metadata": {
        "id": "rMXl_1SJ4dpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arhitecture = [\n",
        "\n",
        "               {\n",
        "                   \"input_dim\": 2,\n",
        "                   \"units\": 25,\n",
        "                   \"activation\": \"relu\"\n",
        "\n",
        "               },\n",
        "                 {\n",
        "                   \"input_dim\": 25,\n",
        "                   \"units\": 50,\n",
        "                   \"activation\": \"relu\"\n",
        "\n",
        "                 },\n",
        "                 {\n",
        "                   \"input_dim\": 50,\n",
        "                   \"units\": 50,\n",
        "                   \"activation\": \"relu\"\n",
        "\n",
        "               },\n",
        "                 {\n",
        "                   \"input_dim\": 50,\n",
        "                   \"units\": 25,\n",
        "                   \"activation\": \"relu\"\n",
        "\n",
        "               },\n",
        "                 {\n",
        "                   \"input_dim\": 25,\n",
        "                   \"units\": 1,\n",
        "                   \"activation\": \"sigmoid\"\n",
        "\n",
        "               },\n",
        "]"
      ],
      "metadata": {
        "id": "sqso37KG5sjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NN(arhitecture)"
      ],
      "metadata": {
        "id": "9ZuR6CgD6iMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXF_xdOt-3C1",
        "outputId": "0beca63a-a8a7-4758-fba1-f647de5da69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Input shape    Output shape    Weights shape    Bias shape      Activation        Params      \n",
            "\n",
            "____________________________________________________________________________________________________\n",
            "       2              25            (25, 2)         (25, 1)          relu             75        \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "      25              50           (50, 25)         (50, 1)          relu            1300       \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "      50              50           (50, 50)         (50, 1)          relu            2550       \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "      50              25           (25, 50)         (25, 1)          relu            1275       \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "      25               1            (1, 25)         (1, 1)          sigmoid           26        \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Total number of parameters: 5226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.randn(2, 1)"
      ],
      "metadata": {
        "id": "LcC2DL-v-4HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzrx0mxBBvMR",
        "outputId": "c7cb4776-3148-42f0-8547-0ba700646180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc_S9ctLBwui",
        "outputId": "b6ae8e75-1018-4a34-fb1c-34822f2165e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.42884793],\n",
              "       [ 0.41583684]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y, mem = nn.predict(x)"
      ],
      "metadata": {
        "id": "Ucf3kLzDByhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jUbrDbeMB6Su",
        "outputId": "656536ed-535c-4d55-89d4-f428c3790fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x0': array([[-0.42884793],\n",
              "        [ 0.41583684]]),\n",
              " 'z0': array([[ 0.00535737],\n",
              "        [-0.00295102],\n",
              "        [-0.06738686],\n",
              "        [ 0.02535618],\n",
              "        [ 0.14579491],\n",
              "        [ 0.09363482],\n",
              "        [-0.17385949],\n",
              "        [ 0.01966952],\n",
              "        [ 0.08962896],\n",
              "        [ 0.07776615],\n",
              "        [-0.12016008],\n",
              "        [-0.08070811],\n",
              "        [-0.08267519],\n",
              "        [-0.05463763],\n",
              "        [ 0.09488115],\n",
              "        [ 0.23845262],\n",
              "        [-0.0506057 ],\n",
              "        [ 0.01431145],\n",
              "        [-0.05428377],\n",
              "        [ 0.00063322],\n",
              "        [ 0.0115967 ],\n",
              "        [ 0.14624221],\n",
              "        [ 0.02988973],\n",
              "        [ 0.2201778 ],\n",
              "        [-0.35002421]]),\n",
              " 'x1': array([[0.00535737],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.02535618],\n",
              "        [0.14579491],\n",
              "        [0.09363482],\n",
              "        [0.        ],\n",
              "        [0.01966952],\n",
              "        [0.08962896],\n",
              "        [0.07776615],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.09488115],\n",
              "        [0.23845262],\n",
              "        [0.        ],\n",
              "        [0.01431145],\n",
              "        [0.        ],\n",
              "        [0.00063322],\n",
              "        [0.0115967 ],\n",
              "        [0.14624221],\n",
              "        [0.02988973],\n",
              "        [0.2201778 ],\n",
              "        [0.        ]]),\n",
              " 'z1': array([[-0.22625248],\n",
              "        [-0.12853545],\n",
              "        [-0.05801377],\n",
              "        [-0.11133293],\n",
              "        [ 0.07032151],\n",
              "        [ 0.1193524 ],\n",
              "        [ 0.1540591 ],\n",
              "        [-0.08729119],\n",
              "        [ 0.1730319 ],\n",
              "        [ 0.08380713],\n",
              "        [-0.08763477],\n",
              "        [-0.04563226],\n",
              "        [-0.11233022],\n",
              "        [-0.00130073],\n",
              "        [-0.00107372],\n",
              "        [-0.02787038],\n",
              "        [-0.01012478],\n",
              "        [ 0.05162534],\n",
              "        [ 0.12563335],\n",
              "        [ 0.1170158 ],\n",
              "        [-0.13347865],\n",
              "        [-0.16613828],\n",
              "        [ 0.01571228],\n",
              "        [-0.13990836],\n",
              "        [ 0.01373999],\n",
              "        [-0.12605365],\n",
              "        [-0.24659793],\n",
              "        [ 0.07793095],\n",
              "        [ 0.09428078],\n",
              "        [-0.06959315],\n",
              "        [-0.29192347],\n",
              "        [-0.08222652],\n",
              "        [ 0.15179573],\n",
              "        [-0.13991106],\n",
              "        [-0.06525782],\n",
              "        [ 0.0350589 ],\n",
              "        [ 0.08909734],\n",
              "        [ 0.09126179],\n",
              "        [-0.02002646],\n",
              "        [ 0.06041635],\n",
              "        [ 0.03054698],\n",
              "        [ 0.01658977],\n",
              "        [-0.06684029],\n",
              "        [ 0.06855024],\n",
              "        [-0.12634005],\n",
              "        [ 0.02662128],\n",
              "        [ 0.22471324],\n",
              "        [-0.1687971 ],\n",
              "        [-0.15301307],\n",
              "        [ 0.14433995]]),\n",
              " 'x2': array([[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.07032151],\n",
              "        [0.1193524 ],\n",
              "        [0.1540591 ],\n",
              "        [0.        ],\n",
              "        [0.1730319 ],\n",
              "        [0.08380713],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.05162534],\n",
              "        [0.12563335],\n",
              "        [0.1170158 ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.01571228],\n",
              "        [0.        ],\n",
              "        [0.01373999],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.07793095],\n",
              "        [0.09428078],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.15179573],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.0350589 ],\n",
              "        [0.08909734],\n",
              "        [0.09126179],\n",
              "        [0.        ],\n",
              "        [0.06041635],\n",
              "        [0.03054698],\n",
              "        [0.01658977],\n",
              "        [0.        ],\n",
              "        [0.06855024],\n",
              "        [0.        ],\n",
              "        [0.02662128],\n",
              "        [0.22471324],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.14433995]]),\n",
              " 'z2': array([[ 0.20630184],\n",
              "        [ 0.07797758],\n",
              "        [ 0.04063392],\n",
              "        [-0.27725206],\n",
              "        [-0.00592354],\n",
              "        [ 0.07057163],\n",
              "        [ 0.01410779],\n",
              "        [-0.13874289],\n",
              "        [-0.09253492],\n",
              "        [ 0.02277518],\n",
              "        [ 0.12511328],\n",
              "        [-0.20958384],\n",
              "        [-0.07633895],\n",
              "        [ 0.0504631 ],\n",
              "        [ 0.06710348],\n",
              "        [ 0.07766091],\n",
              "        [ 0.04662464],\n",
              "        [-0.08072394],\n",
              "        [-0.22372281],\n",
              "        [-0.1070174 ],\n",
              "        [ 0.08647034],\n",
              "        [ 0.20107568],\n",
              "        [ 0.18000885],\n",
              "        [ 0.04237489],\n",
              "        [ 0.07497887],\n",
              "        [-0.03391559],\n",
              "        [ 0.06183425],\n",
              "        [ 0.14379602],\n",
              "        [-0.10414328],\n",
              "        [ 0.10529323],\n",
              "        [-0.08980819],\n",
              "        [ 0.16693581],\n",
              "        [-0.19033807],\n",
              "        [ 0.02310377],\n",
              "        [-0.06820842],\n",
              "        [-0.16896051],\n",
              "        [ 0.07231836],\n",
              "        [ 0.05790287],\n",
              "        [-0.07231369],\n",
              "        [-0.24559351],\n",
              "        [ 0.05494653],\n",
              "        [ 0.06270359],\n",
              "        [-0.02700752],\n",
              "        [ 0.16011144],\n",
              "        [ 0.09768131],\n",
              "        [ 0.16423818],\n",
              "        [ 0.09174631],\n",
              "        [-0.05348432],\n",
              "        [-0.2542319 ],\n",
              "        [-0.07609785]]),\n",
              " 'x3': array([[0.20630184],\n",
              "        [0.07797758],\n",
              "        [0.04063392],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.07057163],\n",
              "        [0.01410779],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.02277518],\n",
              "        [0.12511328],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.0504631 ],\n",
              "        [0.06710348],\n",
              "        [0.07766091],\n",
              "        [0.04662464],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.08647034],\n",
              "        [0.20107568],\n",
              "        [0.18000885],\n",
              "        [0.04237489],\n",
              "        [0.07497887],\n",
              "        [0.        ],\n",
              "        [0.06183425],\n",
              "        [0.14379602],\n",
              "        [0.        ],\n",
              "        [0.10529323],\n",
              "        [0.        ],\n",
              "        [0.16693581],\n",
              "        [0.        ],\n",
              "        [0.02310377],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.07231836],\n",
              "        [0.05790287],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.05494653],\n",
              "        [0.06270359],\n",
              "        [0.        ],\n",
              "        [0.16011144],\n",
              "        [0.09768131],\n",
              "        [0.16423818],\n",
              "        [0.09174631],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]]),\n",
              " 'z3': array([[ 0.27913717],\n",
              "        [-0.24762071],\n",
              "        [-0.10866093],\n",
              "        [-0.0440869 ],\n",
              "        [-0.01507813],\n",
              "        [-0.02126119],\n",
              "        [-0.03368296],\n",
              "        [-0.10659647],\n",
              "        [-0.02061326],\n",
              "        [ 0.05467084],\n",
              "        [-0.20116475],\n",
              "        [-0.07733753],\n",
              "        [ 0.05971277],\n",
              "        [-0.04638854],\n",
              "        [ 0.0752177 ],\n",
              "        [ 0.03624834],\n",
              "        [-0.10259599],\n",
              "        [-0.00603173],\n",
              "        [-0.00705687],\n",
              "        [-0.1986688 ],\n",
              "        [-0.03679603],\n",
              "        [ 0.15418353],\n",
              "        [-0.07548791],\n",
              "        [-0.10476356],\n",
              "        [ 0.01972888]]),\n",
              " 'x4': array([[0.27913717],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.05467084],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.05971277],\n",
              "        [0.        ],\n",
              "        [0.0752177 ],\n",
              "        [0.03624834],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.15418353],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.01972888]]),\n",
              " 'z4': array([[-0.10673406]])}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uo1VgGqyB7UL",
        "outputId": "e432df05-d105-45dc-ade2-ffc7ddfa384e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.47334179]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_moons(n_samples=1000, noise=0.2, random_state=100)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "s1udFnfYCWut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFdasJN2M-Ct",
        "outputId": "6c1ab40f-b66f-4422-a2d9-e51aeed3b546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBkGOzXaM_6E",
        "outputId": "fa613df3-f04b-413c-8052-bea7680f8430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = DataFrame(dict(x=X[:,0], y = X[:,1], label=y))\n",
        "colors = {0:'red', 1:'blue'}\n",
        "fig, ax = plt.subplots()\n",
        "grouped = df.groupby('label')\n",
        "for key, group in grouped:\n",
        "  group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "bWUCVb1hNC5f",
        "outputId": "071f541e-d42c-4211-bfa4-74c05533b079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = nn.train(X_train.T, y_train.reshape(1, y_train.shape[0]), 1000, 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdM5qjKjN-IT",
        "outputId": "f2673933-f5d6-4476-e3a3-3cc4ce631d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 00000 - cost: 0.69509 - accuracy: 0.49556\n",
            "Iteration: 00050 - cost: 0.69228 - accuracy: 0.49667\n",
            "Iteration: 00100 - cost: 0.69102 - accuracy: 0.50444\n",
            "Iteration: 00150 - cost: 0.68836 - accuracy: 0.67556\n",
            "Iteration: 00200 - cost: 0.68028 - accuracy: 0.82444\n",
            "Iteration: 00250 - cost: 0.64183 - accuracy: 0.84000\n",
            "Iteration: 00300 - cost: 0.43950 - accuracy: 0.85444\n",
            "Iteration: 00350 - cost: 0.29377 - accuracy: 0.87667\n",
            "Iteration: 00400 - cost: 0.28068 - accuracy: 0.87778\n",
            "Iteration: 00450 - cost: 0.27648 - accuracy: 0.88000\n",
            "Iteration: 00500 - cost: 0.27201 - accuracy: 0.88111\n",
            "Iteration: 00550 - cost: 0.26648 - accuracy: 0.88000\n",
            "Iteration: 00600 - cost: 0.25979 - accuracy: 0.88000\n",
            "Iteration: 00650 - cost: 0.25365 - accuracy: 0.88333\n",
            "Iteration: 00700 - cost: 0.24837 - accuracy: 0.88556\n",
            "Iteration: 00750 - cost: 0.24416 - accuracy: 0.88667\n",
            "Iteration: 00800 - cost: 0.23042 - accuracy: 0.89222\n",
            "Iteration: 00850 - cost: 0.21399 - accuracy: 0.90000\n",
            "Iteration: 00900 - cost: 0.18444 - accuracy: 0.91667\n",
            "Iteration: 00950 - cost: 0.15038 - accuracy: 0.94444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred, _ = nn.predict(X_test.T)"
      ],
      "metadata": {
        "id": "VxgnpzfyUruD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twAVetzVUxKO",
        "outputId": "37e9bfea-9fb5-451a-fdad-743a1ec8f027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "58SO7ntQVt2o",
        "outputId": "927d3a5c-c59e-4e41-98ba-110cc904f0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array(0.69508513),\n",
              "  array(0.69495218),\n",
              "  array(0.69482371),\n",
              "  array(0.69469928),\n",
              "  array(0.69457828),\n",
              "  array(0.69446194),\n",
              "  array(0.69435024),\n",
              "  array(0.694244),\n",
              "  array(0.69414352),\n",
              "  array(0.69404844),\n",
              "  array(0.69395841),\n",
              "  array(0.69387309),\n",
              "  array(0.69379217),\n",
              "  array(0.69371536),\n",
              "  array(0.6936424),\n",
              "  array(0.69357303),\n",
              "  array(0.69350703),\n",
              "  array(0.69344419),\n",
              "  array(0.69338434),\n",
              "  array(0.69332726),\n",
              "  array(0.69327282),\n",
              "  array(0.6932208),\n",
              "  array(0.69317106),\n",
              "  array(0.69312343),\n",
              "  array(0.69307777),\n",
              "  array(0.69303396),\n",
              "  array(0.69299188),\n",
              "  array(0.69295141),\n",
              "  array(0.69291248),\n",
              "  array(0.69287496),\n",
              "  array(0.69283876),\n",
              "  array(0.69280378),\n",
              "  array(0.69276994),\n",
              "  array(0.69273716),\n",
              "  array(0.69270537),\n",
              "  array(0.6926745),\n",
              "  array(0.69264446),\n",
              "  array(0.69261521),\n",
              "  array(0.69258669),\n",
              "  array(0.69255886),\n",
              "  array(0.69253165),\n",
              "  array(0.69250497),\n",
              "  array(0.69247879),\n",
              "  array(0.69245308),\n",
              "  array(0.69242782),\n",
              "  array(0.69240297),\n",
              "  array(0.69237847),\n",
              "  array(0.69235434),\n",
              "  array(0.69233053),\n",
              "  array(0.69230697),\n",
              "  array(0.69228363),\n",
              "  array(0.69226051),\n",
              "  array(0.69223757),\n",
              "  array(0.69221479),\n",
              "  array(0.69219213),\n",
              "  array(0.69216957),\n",
              "  array(0.69214712),\n",
              "  array(0.69212473),\n",
              "  array(0.69210241),\n",
              "  array(0.69208011),\n",
              "  array(0.6920578),\n",
              "  array(0.69203548),\n",
              "  array(0.69201311),\n",
              "  array(0.69199068),\n",
              "  array(0.69196819),\n",
              "  array(0.69194561),\n",
              "  array(0.69192295),\n",
              "  array(0.6919002),\n",
              "  array(0.69187732),\n",
              "  array(0.69185431),\n",
              "  array(0.69183112),\n",
              "  array(0.69180778),\n",
              "  array(0.69178431),\n",
              "  array(0.69176066),\n",
              "  array(0.69173681),\n",
              "  array(0.69171274),\n",
              "  array(0.69168847),\n",
              "  array(0.69166397),\n",
              "  array(0.69163925),\n",
              "  array(0.69161432),\n",
              "  array(0.69158918),\n",
              "  array(0.69156377),\n",
              "  array(0.69153805),\n",
              "  array(0.69151206),\n",
              "  array(0.6914858),\n",
              "  array(0.69145922),\n",
              "  array(0.69143231),\n",
              "  array(0.69140509),\n",
              "  array(0.69137754),\n",
              "  array(0.69134967),\n",
              "  array(0.69132145),\n",
              "  array(0.69129288),\n",
              "  array(0.69126394),\n",
              "  array(0.69123462),\n",
              "  array(0.69120487),\n",
              "  array(0.6911747),\n",
              "  array(0.69114408),\n",
              "  array(0.69111303),\n",
              "  array(0.69108152),\n",
              "  array(0.69104955),\n",
              "  array(0.69101712),\n",
              "  array(0.6909842),\n",
              "  array(0.69095075),\n",
              "  array(0.69091679),\n",
              "  array(0.6908823),\n",
              "  array(0.69084728),\n",
              "  array(0.69081171),\n",
              "  array(0.69077556),\n",
              "  array(0.69073879),\n",
              "  array(0.69070141),\n",
              "  array(0.69066341),\n",
              "  array(0.69062477),\n",
              "  array(0.69058547),\n",
              "  array(0.69054549),\n",
              "  array(0.69050481),\n",
              "  array(0.69046341),\n",
              "  array(0.69042126),\n",
              "  array(0.69037831),\n",
              "  array(0.69033458),\n",
              "  array(0.69029005),\n",
              "  array(0.69024463),\n",
              "  array(0.69019836),\n",
              "  array(0.69015123),\n",
              "  array(0.69010325),\n",
              "  array(0.69005434),\n",
              "  array(0.69000448),\n",
              "  array(0.68995363),\n",
              "  array(0.68990173),\n",
              "  array(0.68984874),\n",
              "  array(0.68979469),\n",
              "  array(0.6897396),\n",
              "  array(0.68968337),\n",
              "  array(0.68962603),\n",
              "  array(0.68956751),\n",
              "  array(0.68950777),\n",
              "  array(0.68944681),\n",
              "  array(0.68938451),\n",
              "  array(0.68932087),\n",
              "  array(0.68925584),\n",
              "  array(0.68918938),\n",
              "  array(0.68912151),\n",
              "  array(0.68905216),\n",
              "  array(0.68898127),\n",
              "  array(0.68890886),\n",
              "  array(0.68883509),\n",
              "  array(0.68875987),\n",
              "  array(0.68868296),\n",
              "  array(0.68860459),\n",
              "  array(0.68852449),\n",
              "  array(0.6884427),\n",
              "  array(0.68835926),\n",
              "  array(0.68827431),\n",
              "  array(0.68818761),\n",
              "  array(0.6880991),\n",
              "  array(0.68800878),\n",
              "  array(0.68791654),\n",
              "  array(0.68782209),\n",
              "  array(0.68772532),\n",
              "  array(0.68762641),\n",
              "  array(0.68752598),\n",
              "  array(0.68742347),\n",
              "  array(0.68731859),\n",
              "  array(0.68721129),\n",
              "  array(0.68710143),\n",
              "  array(0.68698887),\n",
              "  array(0.68687351),\n",
              "  array(0.68675517),\n",
              "  array(0.68663382),\n",
              "  array(0.68650963),\n",
              "  array(0.68638254),\n",
              "  array(0.68625243),\n",
              "  array(0.68611908),\n",
              "  array(0.68598244),\n",
              "  array(0.6858425),\n",
              "  array(0.68569918),\n",
              "  array(0.68555243),\n",
              "  array(0.68540196),\n",
              "  array(0.68524773),\n",
              "  array(0.68508964),\n",
              "  array(0.6849274),\n",
              "  array(0.68476077),\n",
              "  array(0.68458979),\n",
              "  array(0.68441425),\n",
              "  array(0.6842339),\n",
              "  array(0.6840486),\n",
              "  array(0.68385828),\n",
              "  array(0.68366275),\n",
              "  array(0.68346179),\n",
              "  array(0.68325525),\n",
              "  array(0.68304306),\n",
              "  array(0.68282516),\n",
              "  array(0.68260129),\n",
              "  array(0.6823712),\n",
              "  array(0.68213479),\n",
              "  array(0.68189184),\n",
              "  array(0.68164211),\n",
              "  array(0.68138557),\n",
              "  array(0.68112168),\n",
              "  array(0.68085027),\n",
              "  array(0.68057085),\n",
              "  array(0.6802831),\n",
              "  array(0.67998676),\n",
              "  array(0.67968134),\n",
              "  array(0.67936635),\n",
              "  array(0.67904156),\n",
              "  array(0.67870682),\n",
              "  array(0.67836179),\n",
              "  array(0.6780058),\n",
              "  array(0.67763842),\n",
              "  array(0.6772593),\n",
              "  array(0.67686809),\n",
              "  array(0.67646443),\n",
              "  array(0.6760476),\n",
              "  array(0.67561677),\n",
              "  array(0.67517147),\n",
              "  array(0.67471135),\n",
              "  array(0.67423553),\n",
              "  array(0.67374373),\n",
              "  array(0.67323517),\n",
              "  array(0.67270974),\n",
              "  array(0.67216625),\n",
              "  array(0.67160379),\n",
              "  array(0.67102145),\n",
              "  array(0.67041936),\n",
              "  array(0.66979665),\n",
              "  array(0.66915212),\n",
              "  array(0.66848722),\n",
              "  array(0.66779984),\n",
              "  array(0.6670891),\n",
              "  array(0.66635585),\n",
              "  array(0.66560091),\n",
              "  array(0.6648232),\n",
              "  array(0.66402045),\n",
              "  array(0.66319149),\n",
              "  array(0.66232996),\n",
              "  array(0.66142752),\n",
              "  array(0.66047124),\n",
              "  array(0.65946067),\n",
              "  array(0.65839674),\n",
              "  array(0.65727553),\n",
              "  array(0.65610188),\n",
              "  array(0.65488279),\n",
              "  array(0.65362617),\n",
              "  array(0.65232341),\n",
              "  array(0.65097634),\n",
              "  array(0.64958046),\n",
              "  array(0.64813274),\n",
              "  array(0.64663865),\n",
              "  array(0.64509187),\n",
              "  array(0.64349015),\n",
              "  array(0.64183216),\n",
              "  array(0.64011532),\n",
              "  array(0.63833634),\n",
              "  array(0.63648956),\n",
              "  array(0.6345812),\n",
              "  array(0.63261286),\n",
              "  array(0.63057353),\n",
              "  array(0.62845895),\n",
              "  array(0.6262692),\n",
              "  array(0.62400076),\n",
              "  array(0.62164903),\n",
              "  array(0.61920931),\n",
              "  array(0.61668219),\n",
              "  array(0.61406617),\n",
              "  array(0.61135375),\n",
              "  array(0.60854649),\n",
              "  array(0.60563422),\n",
              "  array(0.60260925),\n",
              "  array(0.59947367),\n",
              "  array(0.5962276),\n",
              "  array(0.59286486),\n",
              "  array(0.58938677),\n",
              "  array(0.58579402),\n",
              "  array(0.58207858),\n",
              "  array(0.57823697),\n",
              "  array(0.57426604),\n",
              "  array(0.57017094),\n",
              "  array(0.56594933),\n",
              "  array(0.56160274),\n",
              "  array(0.55713556),\n",
              "  array(0.55254253),\n",
              "  array(0.54782975),\n",
              "  array(0.54299485),\n",
              "  array(0.53803805),\n",
              "  array(0.53295738),\n",
              "  array(0.52776109),\n",
              "  array(0.52244573),\n",
              "  array(0.51700606),\n",
              "  array(0.51145014),\n",
              "  array(0.50578276),\n",
              "  array(0.50000913),\n",
              "  array(0.49413942),\n",
              "  array(0.48819327),\n",
              "  array(0.48218439),\n",
              "  array(0.47612623),\n",
              "  array(0.47002754),\n",
              "  array(0.46390561),\n",
              "  array(0.4577756),\n",
              "  array(0.45165083),\n",
              "  array(0.44555344),\n",
              "  array(0.43949825),\n",
              "  array(0.43349745),\n",
              "  array(0.42756461),\n",
              "  array(0.42171398),\n",
              "  array(0.41595679),\n",
              "  array(0.41030489),\n",
              "  array(0.40477112),\n",
              "  array(0.39936877),\n",
              "  array(0.39410542),\n",
              "  array(0.3889879),\n",
              "  array(0.38403009),\n",
              "  array(0.37923346),\n",
              "  array(0.3745997),\n",
              "  array(0.37013404),\n",
              "  array(0.36583514),\n",
              "  array(0.36170366),\n",
              "  array(0.35773658),\n",
              "  array(0.35393306),\n",
              "  array(0.35029201),\n",
              "  array(0.34681092),\n",
              "  array(0.34348501),\n",
              "  array(0.3403071),\n",
              "  array(0.33728141),\n",
              "  array(0.33440611),\n",
              "  array(0.33166918),\n",
              "  array(0.32906433),\n",
              "  array(0.32658458),\n",
              "  array(0.32422336),\n",
              "  array(0.32197802),\n",
              "  array(0.31984935),\n",
              "  array(0.31783047),\n",
              "  array(0.31591985),\n",
              "  array(0.31411354),\n",
              "  array(0.31240439),\n",
              "  array(0.31077388),\n",
              "  array(0.30923205),\n",
              "  array(0.30777328),\n",
              "  array(0.30639044),\n",
              "  array(0.30507527),\n",
              "  array(0.30382907),\n",
              "  array(0.30264578),\n",
              "  array(0.30152347),\n",
              "  array(0.3004637),\n",
              "  array(0.29946035),\n",
              "  array(0.2985088),\n",
              "  array(0.29760828),\n",
              "  array(0.29675631),\n",
              "  array(0.29595102),\n",
              "  array(0.29518789),\n",
              "  array(0.29446096),\n",
              "  array(0.29376938),\n",
              "  array(0.29311172),\n",
              "  array(0.29248723),\n",
              "  array(0.29189096),\n",
              "  array(0.29132698),\n",
              "  array(0.29078938),\n",
              "  array(0.29027531),\n",
              "  array(0.28978665),\n",
              "  array(0.2893225),\n",
              "  array(0.28888246),\n",
              "  array(0.28846502),\n",
              "  array(0.28807037),\n",
              "  array(0.28769753),\n",
              "  array(0.28734305),\n",
              "  array(0.28700407),\n",
              "  array(0.28668386),\n",
              "  array(0.2863764),\n",
              "  array(0.28608217),\n",
              "  array(0.28580032),\n",
              "  array(0.28553037),\n",
              "  array(0.28527276),\n",
              "  array(0.28502917),\n",
              "  array(0.28479651),\n",
              "  array(0.28457385),\n",
              "  array(0.28435966),\n",
              "  array(0.28415274),\n",
              "  array(0.283954),\n",
              "  array(0.28376368),\n",
              "  array(0.28357995),\n",
              "  array(0.28340142),\n",
              "  array(0.28322948),\n",
              "  array(0.28306403),\n",
              "  array(0.28290409),\n",
              "  array(0.28274955),\n",
              "  array(0.28260059),\n",
              "  array(0.28245678),\n",
              "  array(0.28231726),\n",
              "  array(0.28218158),\n",
              "  array(0.28204923),\n",
              "  array(0.28192003),\n",
              "  array(0.28179389),\n",
              "  array(0.2816709),\n",
              "  array(0.28155037),\n",
              "  array(0.28143324),\n",
              "  array(0.28131958),\n",
              "  array(0.28120764),\n",
              "  array(0.28109812),\n",
              "  array(0.28099026),\n",
              "  array(0.28088438),\n",
              "  array(0.28078079),\n",
              "  array(0.28067956),\n",
              "  array(0.2805801),\n",
              "  array(0.28048209),\n",
              "  array(0.28038501),\n",
              "  array(0.28028836),\n",
              "  array(0.2801935),\n",
              "  array(0.28010115),\n",
              "  array(0.28001045),\n",
              "  array(0.27992144),\n",
              "  array(0.27983352),\n",
              "  array(0.27974686),\n",
              "  array(0.27966032),\n",
              "  array(0.27957521),\n",
              "  array(0.27949021),\n",
              "  array(0.27940501),\n",
              "  array(0.27932111),\n",
              "  array(0.27923818),\n",
              "  array(0.27915506),\n",
              "  array(0.27906769),\n",
              "  array(0.27897683),\n",
              "  array(0.27889227),\n",
              "  array(0.27881241),\n",
              "  array(0.27873295),\n",
              "  array(0.278655),\n",
              "  array(0.27857692),\n",
              "  array(0.27850108),\n",
              "  array(0.27842634),\n",
              "  array(0.2783523),\n",
              "  array(0.27827378),\n",
              "  array(0.27819297),\n",
              "  array(0.2781118),\n",
              "  array(0.27803025),\n",
              "  array(0.27794907),\n",
              "  array(0.2778694),\n",
              "  array(0.27779048),\n",
              "  array(0.27771259),\n",
              "  array(0.27763444),\n",
              "  array(0.27755421),\n",
              "  array(0.27747548),\n",
              "  array(0.27739687),\n",
              "  array(0.27731739),\n",
              "  array(0.27723701),\n",
              "  array(0.27715549),\n",
              "  array(0.27707149),\n",
              "  array(0.27698741),\n",
              "  array(0.27690244),\n",
              "  array(0.27681863),\n",
              "  array(0.27673534),\n",
              "  array(0.27665068),\n",
              "  array(0.27656599),\n",
              "  array(0.27648067),\n",
              "  array(0.27639462),\n",
              "  array(0.2763082),\n",
              "  array(0.27622161),\n",
              "  array(0.2761328),\n",
              "  array(0.27604521),\n",
              "  array(0.27595785),\n",
              "  array(0.27586975),\n",
              "  array(0.27578164),\n",
              "  array(0.27569425),\n",
              "  array(0.27560697),\n",
              "  array(0.27552036),\n",
              "  array(0.27543343),\n",
              "  array(0.27534539),\n",
              "  array(0.27525706),\n",
              "  array(0.27516816),\n",
              "  array(0.27507896),\n",
              "  array(0.27498939),\n",
              "  array(0.27489886),\n",
              "  array(0.27480747),\n",
              "  array(0.27471522),\n",
              "  array(0.27462382),\n",
              "  array(0.27453401),\n",
              "  array(0.27444396),\n",
              "  array(0.27435395),\n",
              "  array(0.27426326),\n",
              "  array(0.27417271),\n",
              "  array(0.27408245),\n",
              "  array(0.27399198),\n",
              "  array(0.27390138),\n",
              "  array(0.27381117),\n",
              "  array(0.2737225),\n",
              "  array(0.27363339),\n",
              "  array(0.27354345),\n",
              "  array(0.27345307),\n",
              "  array(0.27336187),\n",
              "  array(0.27327196),\n",
              "  array(0.27318338),\n",
              "  array(0.27309589),\n",
              "  array(0.2730057),\n",
              "  array(0.27291579),\n",
              "  array(0.27282625),\n",
              "  array(0.27273724),\n",
              "  array(0.27264841),\n",
              "  array(0.27255913),\n",
              "  array(0.27246945),\n",
              "  array(0.27237945),\n",
              "  array(0.27228815),\n",
              "  array(0.2721964),\n",
              "  array(0.27210545),\n",
              "  array(0.27201446),\n",
              "  array(0.27192317),\n",
              "  array(0.27183149),\n",
              "  array(0.27173945),\n",
              "  array(0.27164563),\n",
              "  array(0.27155031),\n",
              "  array(0.27145333),\n",
              "  array(0.27135494),\n",
              "  array(0.27125563),\n",
              "  array(0.27115623),\n",
              "  array(0.27105669),\n",
              "  array(0.27095758),\n",
              "  array(0.27085756),\n",
              "  array(0.2707577),\n",
              "  array(0.2706577),\n",
              "  array(0.27055739),\n",
              "  array(0.27045648),\n",
              "  array(0.2703542),\n",
              "  array(0.27025064),\n",
              "  array(0.27014535),\n",
              "  array(0.27003933),\n",
              "  array(0.26993244),\n",
              "  array(0.26982479),\n",
              "  array(0.26971503),\n",
              "  array(0.26960565),\n",
              "  array(0.26949524),\n",
              "  array(0.26938508),\n",
              "  array(0.26927371),\n",
              "  array(0.26915988),\n",
              "  array(0.26904317),\n",
              "  array(0.26892492),\n",
              "  array(0.26880514),\n",
              "  array(0.26868475),\n",
              "  array(0.26856591),\n",
              "  array(0.26844704),\n",
              "  array(0.26832812),\n",
              "  array(0.26820896),\n",
              "  array(0.2680895),\n",
              "  array(0.2679696),\n",
              "  array(0.26785049),\n",
              "  array(0.26773115),\n",
              "  array(0.26761063),\n",
              "  array(0.26748909),\n",
              "  array(0.26736645),\n",
              "  array(0.26724335),\n",
              "  array(0.26711962),\n",
              "  array(0.26699528),\n",
              "  array(0.26686956),\n",
              "  array(0.26674109),\n",
              "  array(0.26661157),\n",
              "  array(0.26648189),\n",
              "  array(0.26635113),\n",
              "  array(0.26622053),\n",
              "  array(0.26608925),\n",
              "  array(0.26595775),\n",
              "  array(0.26582571),\n",
              "  array(0.26569304),\n",
              "  array(0.26555898),\n",
              "  array(0.26542723),\n",
              "  array(0.26529519),\n",
              "  array(0.26516242),\n",
              "  array(0.26502872),\n",
              "  array(0.26489503),\n",
              "  array(0.2647607),\n",
              "  array(0.26462627),\n",
              "  array(0.26449125),\n",
              "  array(0.26435478),\n",
              "  array(0.26421625),\n",
              "  array(0.26407806),\n",
              "  array(0.26394024),\n",
              "  array(0.26380226),\n",
              "  array(0.26366416),\n",
              "  array(0.26352631),\n",
              "  array(0.26338959),\n",
              "  array(0.26325401),\n",
              "  array(0.26311837),\n",
              "  array(0.26298249),\n",
              "  array(0.26284581),\n",
              "  array(0.26270843),\n",
              "  array(0.26257079),\n",
              "  array(0.26243283),\n",
              "  array(0.26229475),\n",
              "  array(0.26215749),\n",
              "  array(0.2620205),\n",
              "  array(0.26188473),\n",
              "  array(0.26174883),\n",
              "  array(0.26161306),\n",
              "  array(0.2614774),\n",
              "  array(0.26134353),\n",
              "  array(0.26121092),\n",
              "  array(0.26107844),\n",
              "  array(0.26094583),\n",
              "  array(0.26081275),\n",
              "  array(0.26068184),\n",
              "  array(0.26055477),\n",
              "  array(0.26042768),\n",
              "  array(0.2603004),\n",
              "  array(0.26017255),\n",
              "  array(0.26004457),\n",
              "  array(0.25991716),\n",
              "  array(0.25978973),\n",
              "  array(0.25966227),\n",
              "  array(0.25953479),\n",
              "  array(0.25940744),\n",
              "  array(0.25928086),\n",
              "  array(0.25915425),\n",
              "  array(0.25902793),\n",
              "  array(0.2589012),\n",
              "  array(0.25877444),\n",
              "  array(0.25864774),\n",
              "  array(0.25852125),\n",
              "  array(0.25839502),\n",
              "  array(0.25826895),\n",
              "  array(0.25814319),\n",
              "  array(0.25801756),\n",
              "  array(0.25789161),\n",
              "  array(0.25776593),\n",
              "  array(0.25764026),\n",
              "  array(0.25751468),\n",
              "  array(0.25738925),\n",
              "  array(0.25726416),\n",
              "  array(0.25713923),\n",
              "  array(0.25701479),\n",
              "  array(0.25689058),\n",
              "  array(0.25676632),\n",
              "  array(0.25664249),\n",
              "  array(0.2565201),\n",
              "  array(0.25639819),\n",
              "  array(0.25627646),\n",
              "  array(0.25615506),\n",
              "  array(0.2560338),\n",
              "  array(0.25591265),\n",
              "  array(0.25579165),\n",
              "  array(0.25567087),\n",
              "  array(0.25555022),\n",
              "  array(0.25542973),\n",
              "  array(0.2553095),\n",
              "  array(0.25518954),\n",
              "  array(0.2550697),\n",
              "  array(0.25495011),\n",
              "  array(0.25483067),\n",
              "  array(0.25471143),\n",
              "  array(0.25459257),\n",
              "  array(0.25447398),\n",
              "  array(0.25435609),\n",
              "  array(0.25423841),\n",
              "  array(0.25412087),\n",
              "  array(0.25400371),\n",
              "  array(0.25388674),\n",
              "  array(0.25376961),\n",
              "  array(0.25365252),\n",
              "  array(0.25353555),\n",
              "  array(0.25341905),\n",
              "  array(0.25330293),\n",
              "  array(0.25318731),\n",
              "  array(0.25307196),\n",
              "  array(0.25295715),\n",
              "  array(0.25284286),\n",
              "  array(0.25272901),\n",
              "  array(0.25261526),\n",
              "  array(0.25250215),\n",
              "  array(0.25238927),\n",
              "  array(0.25227694),\n",
              "  array(0.25216491),\n",
              "  array(0.25205329),\n",
              "  array(0.25194203),\n",
              "  array(0.25183126),\n",
              "  array(0.25172103),\n",
              "  array(0.25161142),\n",
              "  array(0.2515024),\n",
              "  array(0.25139381),\n",
              "  array(0.25128578),\n",
              "  array(0.25117826),\n",
              "  array(0.25107095),\n",
              "  array(0.25096419),\n",
              "  array(0.25085783),\n",
              "  array(0.2507516),\n",
              "  array(0.25064595),\n",
              "  array(0.25054043),\n",
              "  array(0.25043579),\n",
              "  array(0.25033206),\n",
              "  array(0.25022851),\n",
              "  array(0.25012556),\n",
              "  array(0.2500232),\n",
              "  array(0.24992153),\n",
              "  array(0.24982064),\n",
              "  array(0.24972031),\n",
              "  array(0.24962041),\n",
              "  array(0.24952083),\n",
              "  array(0.24942165),\n",
              "  array(0.24932308),\n",
              "  array(0.24922508),\n",
              "  array(0.2491277),\n",
              "  array(0.24903063),\n",
              "  array(0.24893394),\n",
              "  array(0.24883774),\n",
              "  array(0.24874212),\n",
              "  array(0.24864726),\n",
              "  array(0.24855282),\n",
              "  array(0.24845902),\n",
              "  array(0.24836586),\n",
              "  array(0.24827311),\n",
              "  array(0.24818081),\n",
              "  array(0.24808887),\n",
              "  array(0.24799722),\n",
              "  array(0.24790598),\n",
              "  array(0.24781499),\n",
              "  array(0.24772449),\n",
              "  array(0.24763464),\n",
              "  array(0.24754541),\n",
              "  array(0.24745664),\n",
              "  array(0.24736802),\n",
              "  array(0.24727994),\n",
              "  array(0.24719215),\n",
              "  array(0.24710498),\n",
              "  array(0.24701803),\n",
              "  array(0.24693153),\n",
              "  array(0.24684552),\n",
              "  array(0.24675956),\n",
              "  array(0.24667406),\n",
              "  array(0.24658864),\n",
              "  array(0.24650353),\n",
              "  array(0.24641883),\n",
              "  array(0.24633478),\n",
              "  array(0.24625073),\n",
              "  array(0.24616726),\n",
              "  array(0.24608367),\n",
              "  array(0.24600068),\n",
              "  array(0.24591803),\n",
              "  array(0.24583591),\n",
              "  array(0.24575384),\n",
              "  array(0.24567227),\n",
              "  array(0.24559103),\n",
              "  array(0.24551036),\n",
              "  array(0.24542979),\n",
              "  array(0.24534981),\n",
              "  array(0.24526998),\n",
              "  array(0.24519032),\n",
              "  array(0.24511072),\n",
              "  array(0.24503142),\n",
              "  array(0.2449525),\n",
              "  array(0.24487354),\n",
              "  array(0.24479499),\n",
              "  array(0.2447168),\n",
              "  array(0.24463893),\n",
              "  array(0.2445612),\n",
              "  array(0.24448288),\n",
              "  array(0.24440464),\n",
              "  array(0.24432602),\n",
              "  array(0.24424586),\n",
              "  array(0.24416222),\n",
              "  array(0.24407686),\n",
              "  array(0.24399155),\n",
              "  array(0.24390654),\n",
              "  array(0.24382004),\n",
              "  array(0.24372452),\n",
              "  array(0.24361836),\n",
              "  array(0.24349161),\n",
              "  array(0.24334759),\n",
              "  array(0.24315695),\n",
              "  array(0.24292107),\n",
              "  array(0.24261257),\n",
              "  array(0.24223963),\n",
              "  array(0.24178731),\n",
              "  array(0.24130478),\n",
              "  array(0.24078504),\n",
              "  array(0.24024941),\n",
              "  array(0.23969031),\n",
              "  array(0.23915787),\n",
              "  array(0.23872759),\n",
              "  array(0.2383656),\n",
              "  array(0.2380336),\n",
              "  array(0.23772069),\n",
              "  array(0.23744401),\n",
              "  array(0.23717817),\n",
              "  array(0.23691807),\n",
              "  array(0.23665232),\n",
              "  array(0.23639304),\n",
              "  array(0.23613213),\n",
              "  array(0.23586763),\n",
              "  array(0.23559998),\n",
              "  array(0.23532791),\n",
              "  array(0.2350602),\n",
              "  array(0.23479527),\n",
              "  array(0.23452893),\n",
              "  array(0.23426564),\n",
              "  array(0.23400171),\n",
              "  array(0.23374004),\n",
              "  array(0.23348569),\n",
              "  array(0.23323025),\n",
              "  array(0.23297452),\n",
              "  array(0.23271902),\n",
              "  array(0.23246681),\n",
              "  array(0.2322149),\n",
              "  array(0.23196269),\n",
              "  array(0.23170948),\n",
              "  array(0.23145386),\n",
              "  array(0.23119612),\n",
              "  array(0.23093691),\n",
              "  array(0.23067833),\n",
              "  array(0.23041978),\n",
              "  array(0.23015977),\n",
              "  array(0.22989757),\n",
              "  array(0.22963356),\n",
              "  array(0.22936675),\n",
              "  array(0.22909729),\n",
              "  array(0.2288247),\n",
              "  array(0.22854987),\n",
              "  array(0.22827337),\n",
              "  array(0.22799498),\n",
              "  array(0.22771371),\n",
              "  array(0.22742902),\n",
              "  array(0.22714326),\n",
              "  array(0.22685586),\n",
              "  array(0.22656941),\n",
              "  array(0.22628131),\n",
              "  array(0.22599099),\n",
              "  array(0.22569743),\n",
              "  array(0.22540047),\n",
              "  array(0.22510024),\n",
              "  array(0.22479685),\n",
              "  array(0.22449015),\n",
              "  array(0.22418128),\n",
              "  array(0.2238692),\n",
              "  array(0.22355414),\n",
              "  array(0.22323602),\n",
              "  array(0.22291396),\n",
              "  array(0.22258886),\n",
              "  array(0.22225981),\n",
              "  array(0.22192792),\n",
              "  array(0.22159209),\n",
              "  array(0.22125223),\n",
              "  array(0.22090838),\n",
              "  array(0.22056045),\n",
              "  array(0.22020878),\n",
              "  array(0.21985395),\n",
              "  array(0.21949447),\n",
              "  array(0.21913083),\n",
              "  array(0.21876296),\n",
              "  array(0.21839057),\n",
              "  array(0.21801333),\n",
              "  array(0.21763118),\n",
              "  array(0.21724481),\n",
              "  array(0.21685394),\n",
              "  array(0.21645829),\n",
              "  array(0.21605771),\n",
              "  array(0.21565357),\n",
              "  array(0.21524447),\n",
              "  array(0.21483112),\n",
              "  array(0.21441251),\n",
              "  array(0.2139885),\n",
              "  array(0.21355909),\n",
              "  array(0.21312431),\n",
              "  array(0.21268365),\n",
              "  array(0.21223745),\n",
              "  array(0.21178569),\n",
              "  array(0.21132861),\n",
              "  array(0.21086667),\n",
              "  array(0.21039831),\n",
              "  array(0.20992456),\n",
              "  array(0.20944523),\n",
              "  array(0.20896017),\n",
              "  array(0.20847004),\n",
              "  array(0.2079731),\n",
              "  array(0.20747032),\n",
              "  array(0.20696203),\n",
              "  array(0.20644767),\n",
              "  array(0.20592808),\n",
              "  array(0.20540203),\n",
              "  array(0.20487003),\n",
              "  array(0.20433243),\n",
              "  array(0.20378671),\n",
              "  array(0.20323297),\n",
              "  array(0.2026718),\n",
              "  array(0.2021046),\n",
              "  array(0.20152966),\n",
              "  array(0.20094675),\n",
              "  array(0.2003539),\n",
              "  array(0.19975185),\n",
              "  array(0.1991391),\n",
              "  array(0.19851867),\n",
              "  array(0.19788827),\n",
              "  array(0.19724675),\n",
              "  array(0.19659581),\n",
              "  array(0.19593519),\n",
              "  array(0.19526144),\n",
              "  array(0.19457954),\n",
              "  array(0.19388967),\n",
              "  array(0.19319279),\n",
              "  array(0.19249057),\n",
              "  array(0.19177855),\n",
              "  array(0.19105952),\n",
              "  array(0.19033263),\n",
              "  array(0.18960022),\n",
              "  array(0.18886412),\n",
              "  array(0.18812333),\n",
              "  array(0.18738109),\n",
              "  array(0.18663701),\n",
              "  array(0.1858918),\n",
              "  array(0.18515714),\n",
              "  array(0.18444281),\n",
              "  array(0.18375479),\n",
              "  array(0.18308594),\n",
              "  array(0.18249681),\n",
              "  array(0.18197716),\n",
              "  array(0.18162082),\n",
              "  array(0.18138189),\n",
              "  array(0.18157579),\n",
              "  array(0.18196152),\n",
              "  array(0.18349854),\n",
              "  array(0.18512326),\n",
              "  array(0.18970748),\n",
              "  array(0.19321896),\n",
              "  array(0.20405502),\n",
              "  array(0.20852651),\n",
              "  array(0.22905828),\n",
              "  array(0.22835796),\n",
              "  array(0.25439904),\n",
              "  array(0.23773079),\n",
              "  array(0.25541046),\n",
              "  array(0.22544671),\n",
              "  array(0.23057859),\n",
              "  array(0.20612518),\n",
              "  array(0.20624469),\n",
              "  array(0.19198978),\n",
              "  array(0.19182593),\n",
              "  array(0.18373925),\n",
              "  array(0.18379508),\n",
              "  array(0.17878044),\n",
              "  array(0.17898369),\n",
              "  array(0.17512001),\n",
              "  array(0.17536315),\n",
              "  array(0.17218398),\n",
              "  array(0.1723706),\n",
              "  array(0.1694786),\n",
              "  array(0.16963858),\n",
              "  array(0.16691276),\n",
              "  array(0.1669312),\n",
              "  array(0.16429664),\n",
              "  array(0.16424316),\n",
              "  array(0.16170797),\n",
              "  array(0.1616309),\n",
              "  array(0.15917654),\n",
              "  array(0.15903841),\n",
              "  array(0.15682836),\n",
              "  array(0.15665256),\n",
              "  array(0.1544193),\n",
              "  array(0.15429195),\n",
              "  array(0.15227352),\n",
              "  array(0.15219644),\n",
              "  array(0.15037905),\n",
              "  array(0.15034164),\n",
              "  array(0.1485665),\n",
              "  array(0.14853159),\n",
              "  array(0.1468323),\n",
              "  array(0.14685726),\n",
              "  array(0.14523104),\n",
              "  array(0.14536591),\n",
              "  array(0.14380687),\n",
              "  array(0.14401514),\n",
              "  array(0.14251153),\n",
              "  array(0.14278827),\n",
              "  array(0.14132202),\n",
              "  array(0.14167992),\n",
              "  array(0.14021259),\n",
              "  array(0.14064878),\n",
              "  array(0.13920887),\n",
              "  array(0.13968203),\n",
              "  array(0.13810348),\n",
              "  array(0.13858485),\n",
              "  array(0.13694045),\n",
              "  array(0.13742736),\n",
              "  array(0.13569591),\n",
              "  array(0.1361424),\n",
              "  array(0.13436035),\n",
              "  array(0.13477561),\n",
              "  array(0.13300657),\n",
              "  array(0.13331034),\n",
              "  array(0.13155633),\n",
              "  array(0.13180703),\n",
              "  array(0.13011271),\n",
              "  array(0.1303054),\n",
              "  array(0.12866301),\n",
              "  array(0.12877815),\n",
              "  array(0.12716756),\n",
              "  array(0.12719742),\n",
              "  array(0.12562927),\n",
              "  array(0.12559043),\n",
              "  array(0.1241127),\n",
              "  array(0.12400799),\n",
              "  array(0.12260107),\n",
              "  array(0.12243284),\n",
              "  array(0.12113154),\n",
              "  array(0.12091237),\n",
              "  array(0.11970748),\n",
              "  array(0.1195089),\n",
              "  array(0.11842526),\n",
              "  array(0.11822783),\n",
              "  array(0.11720316),\n",
              "  array(0.11698695)],\n",
              " [0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.4955555555555556,\n",
              "  0.49666666666666665,\n",
              "  0.51,\n",
              "  0.5411111111111111,\n",
              "  0.5955555555555555,\n",
              "  0.66,\n",
              "  0.7188888888888889,\n",
              "  0.76,\n",
              "  0.7911111111111111,\n",
              "  0.7966666666666666,\n",
              "  0.8033333333333333,\n",
              "  0.8077777777777778,\n",
              "  0.8111111111111111,\n",
              "  0.8022222222222222,\n",
              "  0.7711111111111111,\n",
              "  0.7455555555555555,\n",
              "  0.7155555555555555,\n",
              "  0.68,\n",
              "  0.6422222222222222,\n",
              "  0.6155555555555555,\n",
              "  0.5888888888888889,\n",
              "  0.5533333333333333,\n",
              "  0.54,\n",
              "  0.5322222222222223,\n",
              "  0.5255555555555556,\n",
              "  0.5177777777777778,\n",
              "  0.5144444444444445,\n",
              "  0.5122222222222222,\n",
              "  0.5111111111111111,\n",
              "  0.5088888888888888,\n",
              "  0.5066666666666667,\n",
              "  0.5066666666666667,\n",
              "  0.5055555555555555,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5044444444444445,\n",
              "  0.5055555555555555,\n",
              "  0.5066666666666667,\n",
              "  0.5077777777777778,\n",
              "  0.5077777777777778,\n",
              "  0.5077777777777778,\n",
              "  0.5077777777777778,\n",
              "  0.5077777777777778,\n",
              "  0.5088888888888888,\n",
              "  0.51,\n",
              "  0.51,\n",
              "  0.5122222222222222,\n",
              "  0.5122222222222222,\n",
              "  0.5155555555555555,\n",
              "  0.5155555555555555,\n",
              "  0.5166666666666667,\n",
              "  0.5166666666666667,\n",
              "  0.5211111111111111,\n",
              "  0.5266666666666666,\n",
              "  0.5288888888888889,\n",
              "  0.5322222222222223,\n",
              "  0.5388888888888889,\n",
              "  0.54,\n",
              "  0.5455555555555556,\n",
              "  0.5488888888888889,\n",
              "  0.5566666666666666,\n",
              "  0.5611111111111111,\n",
              "  0.5722222222222222,\n",
              "  0.5788888888888889,\n",
              "  0.5844444444444444,\n",
              "  0.6011111111111112,\n",
              "  0.6066666666666667,\n",
              "  0.6133333333333333,\n",
              "  0.62,\n",
              "  0.6366666666666667,\n",
              "  0.6466666666666666,\n",
              "  0.6555555555555556,\n",
              "  0.6644444444444444,\n",
              "  0.6755555555555556,\n",
              "  0.6822222222222222,\n",
              "  0.6866666666666666,\n",
              "  0.6933333333333334,\n",
              "  0.6977777777777778,\n",
              "  0.7011111111111111,\n",
              "  0.7055555555555556,\n",
              "  0.7111111111111111,\n",
              "  0.7144444444444444,\n",
              "  0.7244444444444444,\n",
              "  0.7277777777777777,\n",
              "  0.7311111111111112,\n",
              "  0.7344444444444445,\n",
              "  0.7377777777777778,\n",
              "  0.7455555555555555,\n",
              "  0.7488888888888889,\n",
              "  0.7488888888888889,\n",
              "  0.7533333333333333,\n",
              "  0.7577777777777778,\n",
              "  0.7588888888888888,\n",
              "  0.76,\n",
              "  0.7644444444444445,\n",
              "  0.7677777777777778,\n",
              "  0.7722222222222223,\n",
              "  0.7766666666666666,\n",
              "  0.7777777777777778,\n",
              "  0.7811111111111111,\n",
              "  0.7822222222222223,\n",
              "  0.7855555555555556,\n",
              "  0.79,\n",
              "  0.79,\n",
              "  0.7944444444444444,\n",
              "  0.7977777777777778,\n",
              "  0.7966666666666666,\n",
              "  0.8011111111111111,\n",
              "  0.8011111111111111,\n",
              "  0.8011111111111111,\n",
              "  0.8,\n",
              "  0.8022222222222222,\n",
              "  0.8022222222222222,\n",
              "  0.8044444444444444,\n",
              "  0.8055555555555556,\n",
              "  0.8077777777777778,\n",
              "  0.8088888888888889,\n",
              "  0.81,\n",
              "  0.8122222222222222,\n",
              "  0.8122222222222222,\n",
              "  0.8177777777777778,\n",
              "  0.8177777777777778,\n",
              "  0.82,\n",
              "  0.8244444444444444,\n",
              "  0.8244444444444444,\n",
              "  0.8288888888888889,\n",
              "  0.8277777777777777,\n",
              "  0.8288888888888889,\n",
              "  0.8288888888888889,\n",
              "  0.8288888888888889,\n",
              "  0.8288888888888889,\n",
              "  0.8311111111111111,\n",
              "  0.8311111111111111,\n",
              "  0.8311111111111111,\n",
              "  0.8344444444444444,\n",
              "  0.8355555555555556,\n",
              "  0.8377777777777777,\n",
              "  0.8355555555555556,\n",
              "  0.8366666666666667,\n",
              "  0.8366666666666667,\n",
              "  0.8388888888888889,\n",
              "  0.8422222222222222,\n",
              "  0.8411111111111111,\n",
              "  0.8377777777777777,\n",
              "  0.8377777777777777,\n",
              "  0.8366666666666667,\n",
              "  0.8366666666666667,\n",
              "  0.8366666666666667,\n",
              "  0.8355555555555556,\n",
              "  0.8344444444444444,\n",
              "  0.8355555555555556,\n",
              "  0.8333333333333334,\n",
              "  0.8344444444444444,\n",
              "  0.8333333333333334,\n",
              "  0.8344444444444444,\n",
              "  0.8355555555555556,\n",
              "  0.8344444444444444,\n",
              "  0.8344444444444444,\n",
              "  0.8344444444444444,\n",
              "  0.8344444444444444,\n",
              "  0.8344444444444444,\n",
              "  0.8344444444444444,\n",
              "  0.8355555555555556,\n",
              "  0.8366666666666667,\n",
              "  0.8366666666666667,\n",
              "  0.8377777777777777,\n",
              "  0.8366666666666667,\n",
              "  0.8388888888888889,\n",
              "  0.8377777777777777,\n",
              "  0.8355555555555556,\n",
              "  0.8377777777777777,\n",
              "  0.8388888888888889,\n",
              "  0.8388888888888889,\n",
              "  0.84,\n",
              "  0.84,\n",
              "  0.84,\n",
              "  0.84,\n",
              "  0.84,\n",
              "  0.84,\n",
              "  0.8388888888888889,\n",
              "  0.8377777777777777,\n",
              "  0.8377777777777777,\n",
              "  0.8377777777777777,\n",
              "  0.8377777777777777,\n",
              "  0.8377777777777777,\n",
              "  0.8377777777777777,\n",
              "  0.8388888888888889,\n",
              "  0.8388888888888889,\n",
              "  0.84,\n",
              "  0.84,\n",
              "  0.8411111111111111,\n",
              "  0.8422222222222222,\n",
              "  0.8422222222222222,\n",
              "  0.8411111111111111,\n",
              "  0.8422222222222222,\n",
              "  0.84,\n",
              "  0.84,\n",
              "  0.84,\n",
              "  0.8422222222222222,\n",
              "  0.8433333333333334,\n",
              "  0.8411111111111111,\n",
              "  0.8422222222222222,\n",
              "  0.8422222222222222,\n",
              "  0.8422222222222222,\n",
              "  0.8433333333333334,\n",
              "  0.8444444444444444,\n",
              "  0.8455555555555555,\n",
              "  0.8444444444444444,\n",
              "  0.8444444444444444,\n",
              "  0.8455555555555555,\n",
              "  0.8455555555555555,\n",
              "  0.8455555555555555,\n",
              "  0.8455555555555555,\n",
              "  0.8433333333333334,\n",
              "  0.8433333333333334,\n",
              "  0.8455555555555555,\n",
              "  0.8466666666666667,\n",
              "  0.8477777777777777,\n",
              "  0.8511111111111112,\n",
              "  0.8522222222222222,\n",
              "  0.8522222222222222,\n",
              "  0.8533333333333334,\n",
              "  0.8533333333333334,\n",
              "  0.8544444444444445,\n",
              "  0.8544444444444445,\n",
              "  0.8544444444444445,\n",
              "  0.8555555555555555,\n",
              "  0.8566666666666667,\n",
              "  0.8566666666666667,\n",
              "  0.8588888888888889,\n",
              "  0.8588888888888889,\n",
              "  0.8588888888888889,\n",
              "  0.86,\n",
              "  0.8611111111111112,\n",
              "  0.8611111111111112,\n",
              "  0.8622222222222222,\n",
              "  0.8622222222222222,\n",
              "  0.8633333333333333,\n",
              "  0.8644444444444445,\n",
              "  0.8655555555555555,\n",
              "  0.8666666666666667,\n",
              "  0.8666666666666667,\n",
              "  0.8688888888888889,\n",
              "  0.8688888888888889,\n",
              "  0.8688888888888889,\n",
              "  0.8688888888888889,\n",
              "  0.8688888888888889,\n",
              "  0.8688888888888889,\n",
              "  0.87,\n",
              "  0.8711111111111111,\n",
              "  0.8711111111111111,\n",
              "  0.8711111111111111,\n",
              "  0.8711111111111111,\n",
              "  0.8711111111111111,\n",
              "  0.8711111111111111,\n",
              "  0.8733333333333333,\n",
              "  0.8733333333333333,\n",
              "  0.8733333333333333,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8744444444444445,\n",
              "  0.8755555555555555,\n",
              "  0.8766666666666667,\n",
              "  0.8766666666666667,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8766666666666667,\n",
              "  0.8766666666666667,\n",
              "  0.8766666666666667,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8766666666666667,\n",
              "  0.8766666666666667,\n",
              "  0.8766666666666667,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8766666666666667,\n",
              "  0.8766666666666667,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8755555555555555,\n",
              "  0.8766666666666667,\n",
              "  0.8766666666666667,\n",
              "  0.8766666666666667,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8777777777777778,\n",
              "  0.8788888888888889,\n",
              "  0.8788888888888889,\n",
              "  0.8788888888888889,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.8822222222222222,\n",
              "  0.8822222222222222,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.8788888888888889,\n",
              "  0.8788888888888889,\n",
              "  0.8788888888888889,\n",
              "  0.8788888888888889,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.8788888888888889,\n",
              "  0.8788888888888889,\n",
              "  0.8788888888888889,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.88,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8811111111111111,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8822222222222222,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8833333333333333,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8844444444444445,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8855555555555555,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8866666666666667,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8877777777777778,\n",
              "  0.8888888888888888,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8911111111111111,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8922222222222222,\n",
              "  0.8933333333333333,\n",
              "  0.8933333333333333,\n",
              "  0.8933333333333333,\n",
              "  0.8933333333333333,\n",
              "  0.8944444444444445,\n",
              "  0.8944444444444445,\n",
              "  0.8944444444444445,\n",
              "  0.8944444444444445,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8966666666666666,\n",
              "  0.8988888888888888,\n",
              "  0.8988888888888888,\n",
              "  0.8988888888888888,\n",
              "  0.8988888888888888,\n",
              "  0.8988888888888888,\n",
              "  0.8988888888888888,\n",
              "  0.8988888888888888,\n",
              "  0.8988888888888888,\n",
              "  0.8988888888888888,\n",
              "  0.8988888888888888,\n",
              "  0.9,\n",
              "  0.9011111111111111,\n",
              "  0.9011111111111111,\n",
              "  0.9011111111111111,\n",
              "  0.9011111111111111,\n",
              "  0.9022222222222223,\n",
              "  0.9022222222222223,\n",
              "  0.9022222222222223,\n",
              "  0.9022222222222223,\n",
              "  0.9022222222222223,\n",
              "  0.9044444444444445,\n",
              "  0.9044444444444445,\n",
              "  0.9044444444444445,\n",
              "  0.9044444444444445,\n",
              "  0.9055555555555556,\n",
              "  0.9055555555555556,\n",
              "  0.9055555555555556,\n",
              "  0.9055555555555556,\n",
              "  0.9055555555555556,\n",
              "  0.9055555555555556,\n",
              "  0.9066666666666666,\n",
              "  0.9066666666666666,\n",
              "  0.9066666666666666,\n",
              "  0.9066666666666666,\n",
              "  0.9066666666666666,\n",
              "  0.9077777777777778,\n",
              "  0.9077777777777778,\n",
              "  0.9077777777777778,\n",
              "  0.9077777777777778,\n",
              "  0.9077777777777778,\n",
              "  0.9077777777777778,\n",
              "  0.9077777777777778,\n",
              "  0.9077777777777778,\n",
              "  0.9088888888888889,\n",
              "  0.91,\n",
              "  0.9111111111111111,\n",
              "  0.91,\n",
              "  0.9122222222222223,\n",
              "  0.91,\n",
              "  0.9122222222222223,\n",
              "  0.91,\n",
              "  0.9133333333333333,\n",
              "  0.9133333333333333,\n",
              "  0.9133333333333333,\n",
              "  0.9133333333333333,\n",
              "  0.9155555555555556,\n",
              "  0.9155555555555556,\n",
              "  0.9166666666666666,\n",
              "  0.9166666666666666,\n",
              "  0.9188888888888889,\n",
              "  0.9166666666666666,\n",
              "  0.9188888888888889,\n",
              "  0.9177777777777778,\n",
              "  0.92,\n",
              "  0.9188888888888889,\n",
              "  0.92,\n",
              "  0.9222222222222223,\n",
              "  0.9155555555555556,\n",
              "  0.9255555555555556,\n",
              "  0.9166666666666666,\n",
              "  0.9177777777777778,\n",
              "  0.9166666666666666,\n",
              "  0.9122222222222223,\n",
              "  0.9155555555555556,\n",
              "  0.9066666666666666,\n",
              "  0.9055555555555556,\n",
              "  0.9022222222222223,\n",
              "  0.9033333333333333,\n",
              "  0.8988888888888888,\n",
              "  0.9033333333333333,\n",
              "  0.9033333333333333,\n",
              "  0.9011111111111111,\n",
              "  0.9066666666666666,\n",
              "  0.9144444444444444,\n",
              "  0.9144444444444444,\n",
              "  0.9166666666666666,\n",
              "  0.92,\n",
              "  0.9177777777777778,\n",
              "  0.9255555555555556,\n",
              "  0.92,\n",
              "  0.9277777777777778,\n",
              "  0.92,\n",
              "  0.9311111111111111,\n",
              "  0.9222222222222223,\n",
              "  0.9311111111111111,\n",
              "  0.9222222222222223,\n",
              "  0.9322222222222222,\n",
              "  0.9266666666666666,\n",
              "  0.9344444444444444,\n",
              "  0.93,\n",
              "  0.9355555555555556,\n",
              "  0.93,\n",
              "  0.9388888888888889,\n",
              "  0.9344444444444444,\n",
              "  0.9422222222222222,\n",
              "  0.9355555555555556,\n",
              "  0.9422222222222222,\n",
              "  0.9366666666666666,\n",
              "  0.9433333333333334,\n",
              "  0.9388888888888889,\n",
              "  0.9444444444444444,\n",
              "  0.9411111111111111,\n",
              "  0.9466666666666667,\n",
              "  0.9411111111111111,\n",
              "  0.9466666666666667,\n",
              "  0.9422222222222222,\n",
              "  0.9477777777777778,\n",
              "  0.9422222222222222,\n",
              "  0.9488888888888889,\n",
              "  0.9433333333333334,\n",
              "  0.95,\n",
              "  0.9444444444444444,\n",
              "  0.9511111111111111,\n",
              "  0.9466666666666667,\n",
              "  0.95,\n",
              "  0.9466666666666667,\n",
              "  0.95,\n",
              "  0.9466666666666667,\n",
              "  0.95,\n",
              "  0.9477777777777778,\n",
              "  0.95,\n",
              "  0.9488888888888889,\n",
              "  0.9522222222222222,\n",
              "  0.9488888888888889,\n",
              "  0.9522222222222222,\n",
              "  0.9488888888888889,\n",
              "  0.9522222222222222,\n",
              "  0.9488888888888889,\n",
              "  0.9522222222222222,\n",
              "  0.9488888888888889,\n",
              "  0.9533333333333334,\n",
              "  0.95,\n",
              "  0.9544444444444444,\n",
              "  0.95,\n",
              "  0.9544444444444444,\n",
              "  0.95,\n",
              "  0.9544444444444444,\n",
              "  0.9511111111111111,\n",
              "  0.9555555555555556,\n",
              "  0.9511111111111111,\n",
              "  0.9555555555555556,\n",
              "  0.9522222222222222,\n",
              "  0.9555555555555556,\n",
              "  0.9544444444444444,\n",
              "  0.9544444444444444,\n",
              "  0.9566666666666667,\n",
              "  0.9533333333333334,\n",
              "  0.9566666666666667,\n",
              "  0.9533333333333334,\n",
              "  0.9566666666666667])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implemantare folosind tensorflow"
      ],
      "metadata": {
        "id": "Gikl2dHoU9Ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input"
      ],
      "metadata": {
        "id": "I8BXPRIqU0hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(2,)),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "ShkAvpfZWQv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "quRs420SWwFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HLupyETwXF5D",
        "outputId": "052df287-393a-4bf3-df19-0be3b3d3f896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │              \u001b[38;5;34m75\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m1,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m2,550\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │           \u001b[38;5;34m1,275\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m26\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,226\u001b[0m (20.41 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,226</span> (20.41 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,226\u001b[0m (20.41 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,226</span> (20.41 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(epochs=1000, x=X_train, y=y_train, batch_size=256, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDdwGSBSXKJF",
        "outputId": "461060c2-062f-476b-c0be-cd9d441e97d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.4793 - loss: 0.6911 - val_accuracy: 0.4900 - val_loss: 0.6912\n",
            "Epoch 2/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5054 - loss: 0.6891 - val_accuracy: 0.5500 - val_loss: 0.6895\n",
            "Epoch 3/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6071 - loss: 0.6865 - val_accuracy: 0.6100 - val_loss: 0.6879\n",
            "Epoch 4/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6778 - loss: 0.6850 - val_accuracy: 0.6200 - val_loss: 0.6865\n",
            "Epoch 5/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7224 - loss: 0.6832 - val_accuracy: 0.6600 - val_loss: 0.6852\n",
            "Epoch 6/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7530 - loss: 0.6815 - val_accuracy: 0.7000 - val_loss: 0.6839\n",
            "Epoch 7/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7567 - loss: 0.6799 - val_accuracy: 0.7000 - val_loss: 0.6827\n",
            "Epoch 8/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7656 - loss: 0.6789 - val_accuracy: 0.7000 - val_loss: 0.6814\n",
            "Epoch 9/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7642 - loss: 0.6772 - val_accuracy: 0.7000 - val_loss: 0.6802\n",
            "Epoch 10/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7802 - loss: 0.6759 - val_accuracy: 0.7000 - val_loss: 0.6790\n",
            "Epoch 11/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7849 - loss: 0.6740 - val_accuracy: 0.7000 - val_loss: 0.6779\n",
            "Epoch 12/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7819 - loss: 0.6723 - val_accuracy: 0.7000 - val_loss: 0.6768\n",
            "Epoch 13/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7818 - loss: 0.6719 - val_accuracy: 0.6900 - val_loss: 0.6757\n",
            "Epoch 14/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7907 - loss: 0.6691 - val_accuracy: 0.7000 - val_loss: 0.6747\n",
            "Epoch 15/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7986 - loss: 0.6682 - val_accuracy: 0.7000 - val_loss: 0.6737\n",
            "Epoch 16/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7958 - loss: 0.6669 - val_accuracy: 0.7000 - val_loss: 0.6727\n",
            "Epoch 17/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7984 - loss: 0.6661 - val_accuracy: 0.7000 - val_loss: 0.6717\n",
            "Epoch 18/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7971 - loss: 0.6651 - val_accuracy: 0.7000 - val_loss: 0.6707\n",
            "Epoch 19/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7962 - loss: 0.6637 - val_accuracy: 0.7000 - val_loss: 0.6697\n",
            "Epoch 20/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7941 - loss: 0.6626 - val_accuracy: 0.7000 - val_loss: 0.6687\n",
            "Epoch 21/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8071 - loss: 0.6609 - val_accuracy: 0.7100 - val_loss: 0.6677\n",
            "Epoch 22/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8031 - loss: 0.6597 - val_accuracy: 0.7100 - val_loss: 0.6667\n",
            "Epoch 23/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7955 - loss: 0.6590 - val_accuracy: 0.7100 - val_loss: 0.6657\n",
            "Epoch 24/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7998 - loss: 0.6572 - val_accuracy: 0.7100 - val_loss: 0.6647\n",
            "Epoch 25/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8083 - loss: 0.6554 - val_accuracy: 0.7100 - val_loss: 0.6637\n",
            "Epoch 26/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8084 - loss: 0.6544 - val_accuracy: 0.7100 - val_loss: 0.6626\n",
            "Epoch 27/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7927 - loss: 0.6541 - val_accuracy: 0.7100 - val_loss: 0.6615\n",
            "Epoch 28/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8155 - loss: 0.6510 - val_accuracy: 0.7200 - val_loss: 0.6603\n",
            "Epoch 29/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8027 - loss: 0.6510 - val_accuracy: 0.7200 - val_loss: 0.6592\n",
            "Epoch 30/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8025 - loss: 0.6492 - val_accuracy: 0.7200 - val_loss: 0.6581\n",
            "Epoch 31/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8049 - loss: 0.6475 - val_accuracy: 0.7200 - val_loss: 0.6569\n",
            "Epoch 32/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8122 - loss: 0.6454 - val_accuracy: 0.7200 - val_loss: 0.6557\n",
            "Epoch 33/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8118 - loss: 0.6464 - val_accuracy: 0.7200 - val_loss: 0.6545\n",
            "Epoch 34/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8226 - loss: 0.6424 - val_accuracy: 0.7200 - val_loss: 0.6533\n",
            "Epoch 35/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8175 - loss: 0.6425 - val_accuracy: 0.7300 - val_loss: 0.6521\n",
            "Epoch 36/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8284 - loss: 0.6405 - val_accuracy: 0.7200 - val_loss: 0.6509\n",
            "Epoch 37/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8187 - loss: 0.6407 - val_accuracy: 0.7300 - val_loss: 0.6496\n",
            "Epoch 38/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8162 - loss: 0.6380 - val_accuracy: 0.7300 - val_loss: 0.6484\n",
            "Epoch 39/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8110 - loss: 0.6382 - val_accuracy: 0.7300 - val_loss: 0.6471\n",
            "Epoch 40/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8275 - loss: 0.6336 - val_accuracy: 0.7200 - val_loss: 0.6458\n",
            "Epoch 41/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8223 - loss: 0.6332 - val_accuracy: 0.7200 - val_loss: 0.6445\n",
            "Epoch 42/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8352 - loss: 0.6306 - val_accuracy: 0.7200 - val_loss: 0.6431\n",
            "Epoch 43/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8235 - loss: 0.6281 - val_accuracy: 0.7200 - val_loss: 0.6417\n",
            "Epoch 44/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8159 - loss: 0.6297 - val_accuracy: 0.7200 - val_loss: 0.6404\n",
            "Epoch 45/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8303 - loss: 0.6245 - val_accuracy: 0.7200 - val_loss: 0.6389\n",
            "Epoch 46/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8237 - loss: 0.6256 - val_accuracy: 0.7300 - val_loss: 0.6375\n",
            "Epoch 47/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8330 - loss: 0.6223 - val_accuracy: 0.7300 - val_loss: 0.6360\n",
            "Epoch 48/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8215 - loss: 0.6218 - val_accuracy: 0.7200 - val_loss: 0.6345\n",
            "Epoch 49/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8303 - loss: 0.6192 - val_accuracy: 0.7400 - val_loss: 0.6330\n",
            "Epoch 50/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8154 - loss: 0.6188 - val_accuracy: 0.7400 - val_loss: 0.6314\n",
            "Epoch 51/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8254 - loss: 0.6158 - val_accuracy: 0.7600 - val_loss: 0.6299\n",
            "Epoch 52/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8276 - loss: 0.6144 - val_accuracy: 0.7700 - val_loss: 0.6283\n",
            "Epoch 53/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8298 - loss: 0.6123 - val_accuracy: 0.7700 - val_loss: 0.6267\n",
            "Epoch 54/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8307 - loss: 0.6096 - val_accuracy: 0.7700 - val_loss: 0.6251\n",
            "Epoch 55/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8383 - loss: 0.6080 - val_accuracy: 0.7800 - val_loss: 0.6233\n",
            "Epoch 56/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8305 - loss: 0.6086 - val_accuracy: 0.7800 - val_loss: 0.6216\n",
            "Epoch 57/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8186 - loss: 0.6075 - val_accuracy: 0.7800 - val_loss: 0.6199\n",
            "Epoch 58/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8317 - loss: 0.5996 - val_accuracy: 0.7800 - val_loss: 0.6181\n",
            "Epoch 59/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8192 - loss: 0.6003 - val_accuracy: 0.7800 - val_loss: 0.6164\n",
            "Epoch 60/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8312 - loss: 0.5982 - val_accuracy: 0.7800 - val_loss: 0.6146\n",
            "Epoch 61/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8312 - loss: 0.5965 - val_accuracy: 0.7800 - val_loss: 0.6128\n",
            "Epoch 62/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8252 - loss: 0.5942 - val_accuracy: 0.7800 - val_loss: 0.6109\n",
            "Epoch 63/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8245 - loss: 0.5921 - val_accuracy: 0.7800 - val_loss: 0.6090\n",
            "Epoch 64/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8362 - loss: 0.5883 - val_accuracy: 0.7800 - val_loss: 0.6071\n",
            "Epoch 65/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8294 - loss: 0.5860 - val_accuracy: 0.7800 - val_loss: 0.6052\n",
            "Epoch 66/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8305 - loss: 0.5835 - val_accuracy: 0.7800 - val_loss: 0.6032\n",
            "Epoch 67/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8291 - loss: 0.5806 - val_accuracy: 0.7800 - val_loss: 0.6013\n",
            "Epoch 68/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8334 - loss: 0.5783 - val_accuracy: 0.7800 - val_loss: 0.5992\n",
            "Epoch 69/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8288 - loss: 0.5755 - val_accuracy: 0.7800 - val_loss: 0.5972\n",
            "Epoch 70/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8335 - loss: 0.5723 - val_accuracy: 0.7800 - val_loss: 0.5952\n",
            "Epoch 71/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8176 - loss: 0.5751 - val_accuracy: 0.7800 - val_loss: 0.5931\n",
            "Epoch 72/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8341 - loss: 0.5665 - val_accuracy: 0.7800 - val_loss: 0.5910\n",
            "Epoch 73/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8307 - loss: 0.5671 - val_accuracy: 0.7800 - val_loss: 0.5889\n",
            "Epoch 74/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8350 - loss: 0.5625 - val_accuracy: 0.7800 - val_loss: 0.5867\n",
            "Epoch 75/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8231 - loss: 0.5658 - val_accuracy: 0.7800 - val_loss: 0.5845\n",
            "Epoch 76/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8336 - loss: 0.5560 - val_accuracy: 0.7800 - val_loss: 0.5823\n",
            "Epoch 77/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8250 - loss: 0.5554 - val_accuracy: 0.7800 - val_loss: 0.5801\n",
            "Epoch 78/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8228 - loss: 0.5552 - val_accuracy: 0.7800 - val_loss: 0.5778\n",
            "Epoch 79/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8293 - loss: 0.5499 - val_accuracy: 0.7800 - val_loss: 0.5756\n",
            "Epoch 80/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8307 - loss: 0.5459 - val_accuracy: 0.7800 - val_loss: 0.5733\n",
            "Epoch 81/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8213 - loss: 0.5475 - val_accuracy: 0.7800 - val_loss: 0.5709\n",
            "Epoch 82/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8432 - loss: 0.5354 - val_accuracy: 0.7800 - val_loss: 0.5686\n",
            "Epoch 83/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8333 - loss: 0.5405 - val_accuracy: 0.7800 - val_loss: 0.5663\n",
            "Epoch 84/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8285 - loss: 0.5385 - val_accuracy: 0.7800 - val_loss: 0.5638\n",
            "Epoch 85/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8343 - loss: 0.5343 - val_accuracy: 0.7800 - val_loss: 0.5613\n",
            "Epoch 86/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8290 - loss: 0.5331 - val_accuracy: 0.7800 - val_loss: 0.5589\n",
            "Epoch 87/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8401 - loss: 0.5232 - val_accuracy: 0.7800 - val_loss: 0.5565\n",
            "Epoch 88/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8324 - loss: 0.5207 - val_accuracy: 0.7800 - val_loss: 0.5540\n",
            "Epoch 89/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8344 - loss: 0.5233 - val_accuracy: 0.7800 - val_loss: 0.5516\n",
            "Epoch 90/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8326 - loss: 0.5190 - val_accuracy: 0.7800 - val_loss: 0.5492\n",
            "Epoch 91/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8357 - loss: 0.5143 - val_accuracy: 0.7800 - val_loss: 0.5468\n",
            "Epoch 92/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8428 - loss: 0.5064 - val_accuracy: 0.7800 - val_loss: 0.5443\n",
            "Epoch 93/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8416 - loss: 0.5098 - val_accuracy: 0.7800 - val_loss: 0.5418\n",
            "Epoch 94/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8290 - loss: 0.5040 - val_accuracy: 0.7800 - val_loss: 0.5392\n",
            "Epoch 95/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8471 - loss: 0.4970 - val_accuracy: 0.7800 - val_loss: 0.5368\n",
            "Epoch 96/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8392 - loss: 0.5052 - val_accuracy: 0.7800 - val_loss: 0.5343\n",
            "Epoch 97/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8459 - loss: 0.4950 - val_accuracy: 0.7800 - val_loss: 0.5319\n",
            "Epoch 98/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8341 - loss: 0.4953 - val_accuracy: 0.7800 - val_loss: 0.5295\n",
            "Epoch 99/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8294 - loss: 0.4953 - val_accuracy: 0.7800 - val_loss: 0.5271\n",
            "Epoch 100/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8396 - loss: 0.4881 - val_accuracy: 0.7900 - val_loss: 0.5246\n",
            "Epoch 101/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8353 - loss: 0.4866 - val_accuracy: 0.7900 - val_loss: 0.5221\n",
            "Epoch 102/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8381 - loss: 0.4795 - val_accuracy: 0.7900 - val_loss: 0.5196\n",
            "Epoch 103/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8403 - loss: 0.4793 - val_accuracy: 0.8000 - val_loss: 0.5171\n",
            "Epoch 104/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8396 - loss: 0.4780 - val_accuracy: 0.8100 - val_loss: 0.5146\n",
            "Epoch 105/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8449 - loss: 0.4730 - val_accuracy: 0.8100 - val_loss: 0.5122\n",
            "Epoch 106/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8454 - loss: 0.4658 - val_accuracy: 0.8100 - val_loss: 0.5097\n",
            "Epoch 107/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8423 - loss: 0.4682 - val_accuracy: 0.8100 - val_loss: 0.5075\n",
            "Epoch 108/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8378 - loss: 0.4671 - val_accuracy: 0.8100 - val_loss: 0.5049\n",
            "Epoch 109/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8358 - loss: 0.4636 - val_accuracy: 0.8100 - val_loss: 0.5023\n",
            "Epoch 110/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8377 - loss: 0.4648 - val_accuracy: 0.8100 - val_loss: 0.5000\n",
            "Epoch 111/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8364 - loss: 0.4643 - val_accuracy: 0.8100 - val_loss: 0.4975\n",
            "Epoch 112/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8457 - loss: 0.4518 - val_accuracy: 0.8200 - val_loss: 0.4949\n",
            "Epoch 113/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8388 - loss: 0.4560 - val_accuracy: 0.8200 - val_loss: 0.4924\n",
            "Epoch 114/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8514 - loss: 0.4461 - val_accuracy: 0.8200 - val_loss: 0.4897\n",
            "Epoch 115/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8447 - loss: 0.4497 - val_accuracy: 0.8200 - val_loss: 0.4876\n",
            "Epoch 116/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8568 - loss: 0.4346 - val_accuracy: 0.8200 - val_loss: 0.4853\n",
            "Epoch 117/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8498 - loss: 0.4426 - val_accuracy: 0.8200 - val_loss: 0.4830\n",
            "Epoch 118/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8420 - loss: 0.4397 - val_accuracy: 0.8200 - val_loss: 0.4802\n",
            "Epoch 119/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8462 - loss: 0.4344 - val_accuracy: 0.8200 - val_loss: 0.4777\n",
            "Epoch 120/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8319 - loss: 0.4413 - val_accuracy: 0.8200 - val_loss: 0.4752\n",
            "Epoch 121/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8387 - loss: 0.4359 - val_accuracy: 0.8200 - val_loss: 0.4728\n",
            "Epoch 122/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8474 - loss: 0.4293 - val_accuracy: 0.8200 - val_loss: 0.4704\n",
            "Epoch 123/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8516 - loss: 0.4206 - val_accuracy: 0.8200 - val_loss: 0.4682\n",
            "Epoch 124/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8476 - loss: 0.4231 - val_accuracy: 0.8200 - val_loss: 0.4657\n",
            "Epoch 125/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8497 - loss: 0.4228 - val_accuracy: 0.8200 - val_loss: 0.4633\n",
            "Epoch 126/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8398 - loss: 0.4287 - val_accuracy: 0.8200 - val_loss: 0.4613\n",
            "Epoch 127/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8391 - loss: 0.4238 - val_accuracy: 0.8300 - val_loss: 0.4589\n",
            "Epoch 128/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8536 - loss: 0.4107 - val_accuracy: 0.8300 - val_loss: 0.4565\n",
            "Epoch 129/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8405 - loss: 0.4189 - val_accuracy: 0.8300 - val_loss: 0.4542\n",
            "Epoch 130/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8447 - loss: 0.4187 - val_accuracy: 0.8300 - val_loss: 0.4519\n",
            "Epoch 131/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8496 - loss: 0.4140 - val_accuracy: 0.8300 - val_loss: 0.4496\n",
            "Epoch 132/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8474 - loss: 0.4058 - val_accuracy: 0.8300 - val_loss: 0.4472\n",
            "Epoch 133/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8554 - loss: 0.4052 - val_accuracy: 0.8300 - val_loss: 0.4450\n",
            "Epoch 134/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8564 - loss: 0.4025 - val_accuracy: 0.8300 - val_loss: 0.4425\n",
            "Epoch 135/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8455 - loss: 0.4034 - val_accuracy: 0.8300 - val_loss: 0.4402\n",
            "Epoch 136/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8583 - loss: 0.3952 - val_accuracy: 0.8300 - val_loss: 0.4378\n",
            "Epoch 137/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8556 - loss: 0.3955 - val_accuracy: 0.8400 - val_loss: 0.4354\n",
            "Epoch 138/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8629 - loss: 0.3865 - val_accuracy: 0.8400 - val_loss: 0.4332\n",
            "Epoch 139/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8601 - loss: 0.3870 - val_accuracy: 0.8400 - val_loss: 0.4306\n",
            "Epoch 140/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8554 - loss: 0.3939 - val_accuracy: 0.8400 - val_loss: 0.4283\n",
            "Epoch 141/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8642 - loss: 0.3809 - val_accuracy: 0.8400 - val_loss: 0.4260\n",
            "Epoch 142/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8577 - loss: 0.3852 - val_accuracy: 0.8400 - val_loss: 0.4237\n",
            "Epoch 143/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8646 - loss: 0.3846 - val_accuracy: 0.8400 - val_loss: 0.4217\n",
            "Epoch 144/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8617 - loss: 0.3758 - val_accuracy: 0.8400 - val_loss: 0.4192\n",
            "Epoch 145/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8657 - loss: 0.3712 - val_accuracy: 0.8400 - val_loss: 0.4168\n",
            "Epoch 146/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8681 - loss: 0.3736 - val_accuracy: 0.8400 - val_loss: 0.4148\n",
            "Epoch 147/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8712 - loss: 0.3668 - val_accuracy: 0.8400 - val_loss: 0.4127\n",
            "Epoch 148/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8556 - loss: 0.3786 - val_accuracy: 0.8400 - val_loss: 0.4104\n",
            "Epoch 149/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8714 - loss: 0.3598 - val_accuracy: 0.8300 - val_loss: 0.4084\n",
            "Epoch 150/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8611 - loss: 0.3767 - val_accuracy: 0.8300 - val_loss: 0.4064\n",
            "Epoch 151/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8637 - loss: 0.3685 - val_accuracy: 0.8300 - val_loss: 0.4046\n",
            "Epoch 152/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8640 - loss: 0.3719 - val_accuracy: 0.8300 - val_loss: 0.4027\n",
            "Epoch 153/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8735 - loss: 0.3579 - val_accuracy: 0.8300 - val_loss: 0.4005\n",
            "Epoch 154/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8603 - loss: 0.3629 - val_accuracy: 0.8300 - val_loss: 0.3984\n",
            "Epoch 155/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8619 - loss: 0.3701 - val_accuracy: 0.8300 - val_loss: 0.3966\n",
            "Epoch 156/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8586 - loss: 0.3686 - val_accuracy: 0.8300 - val_loss: 0.3948\n",
            "Epoch 157/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8681 - loss: 0.3566 - val_accuracy: 0.8300 - val_loss: 0.3930\n",
            "Epoch 158/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8617 - loss: 0.3609 - val_accuracy: 0.8300 - val_loss: 0.3912\n",
            "Epoch 159/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8733 - loss: 0.3505 - val_accuracy: 0.8300 - val_loss: 0.3893\n",
            "Epoch 160/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8783 - loss: 0.3411 - val_accuracy: 0.8300 - val_loss: 0.3874\n",
            "Epoch 161/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8634 - loss: 0.3555 - val_accuracy: 0.8200 - val_loss: 0.3857\n",
            "Epoch 162/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8624 - loss: 0.3563 - val_accuracy: 0.8200 - val_loss: 0.3839\n",
            "Epoch 163/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8616 - loss: 0.3583 - val_accuracy: 0.8200 - val_loss: 0.3823\n",
            "Epoch 164/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8636 - loss: 0.3491 - val_accuracy: 0.8200 - val_loss: 0.3808\n",
            "Epoch 165/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8689 - loss: 0.3412 - val_accuracy: 0.8300 - val_loss: 0.3793\n",
            "Epoch 166/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8770 - loss: 0.3360 - val_accuracy: 0.8200 - val_loss: 0.3774\n",
            "Epoch 167/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8689 - loss: 0.3423 - val_accuracy: 0.8200 - val_loss: 0.3757\n",
            "Epoch 168/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8719 - loss: 0.3419 - val_accuracy: 0.8200 - val_loss: 0.3741\n",
            "Epoch 169/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8791 - loss: 0.3281 - val_accuracy: 0.8200 - val_loss: 0.3725\n",
            "Epoch 170/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8660 - loss: 0.3393 - val_accuracy: 0.8200 - val_loss: 0.3712\n",
            "Epoch 171/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8638 - loss: 0.3385 - val_accuracy: 0.8200 - val_loss: 0.3698\n",
            "Epoch 172/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8698 - loss: 0.3339 - val_accuracy: 0.8200 - val_loss: 0.3683\n",
            "Epoch 173/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8671 - loss: 0.3345 - val_accuracy: 0.8300 - val_loss: 0.3670\n",
            "Epoch 174/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8653 - loss: 0.3384 - val_accuracy: 0.8400 - val_loss: 0.3657\n",
            "Epoch 175/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8733 - loss: 0.3262 - val_accuracy: 0.8400 - val_loss: 0.3645\n",
            "Epoch 176/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8666 - loss: 0.3324 - val_accuracy: 0.8400 - val_loss: 0.3633\n",
            "Epoch 177/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8720 - loss: 0.3215 - val_accuracy: 0.8400 - val_loss: 0.3622\n",
            "Epoch 178/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8718 - loss: 0.3261 - val_accuracy: 0.8400 - val_loss: 0.3610\n",
            "Epoch 179/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8720 - loss: 0.3210 - val_accuracy: 0.8400 - val_loss: 0.3596\n",
            "Epoch 180/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8730 - loss: 0.3207 - val_accuracy: 0.8400 - val_loss: 0.3587\n",
            "Epoch 181/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8755 - loss: 0.3166 - val_accuracy: 0.8400 - val_loss: 0.3575\n",
            "Epoch 182/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8843 - loss: 0.3061 - val_accuracy: 0.8400 - val_loss: 0.3566\n",
            "Epoch 183/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8744 - loss: 0.3123 - val_accuracy: 0.8400 - val_loss: 0.3556\n",
            "Epoch 184/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8721 - loss: 0.3185 - val_accuracy: 0.8400 - val_loss: 0.3544\n",
            "Epoch 185/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8684 - loss: 0.3174 - val_accuracy: 0.8400 - val_loss: 0.3531\n",
            "Epoch 186/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8708 - loss: 0.3198 - val_accuracy: 0.8400 - val_loss: 0.3525\n",
            "Epoch 187/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8614 - loss: 0.3292 - val_accuracy: 0.8400 - val_loss: 0.3515\n",
            "Epoch 188/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8666 - loss: 0.3165 - val_accuracy: 0.8400 - val_loss: 0.3505\n",
            "Epoch 189/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8725 - loss: 0.3143 - val_accuracy: 0.8400 - val_loss: 0.3496\n",
            "Epoch 190/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8786 - loss: 0.3045 - val_accuracy: 0.8400 - val_loss: 0.3481\n",
            "Epoch 191/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8712 - loss: 0.3146 - val_accuracy: 0.8400 - val_loss: 0.3474\n",
            "Epoch 192/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8684 - loss: 0.3157 - val_accuracy: 0.8500 - val_loss: 0.3464\n",
            "Epoch 193/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8760 - loss: 0.3055 - val_accuracy: 0.8500 - val_loss: 0.3453\n",
            "Epoch 194/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8735 - loss: 0.3036 - val_accuracy: 0.8500 - val_loss: 0.3444\n",
            "Epoch 195/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8665 - loss: 0.3166 - val_accuracy: 0.8500 - val_loss: 0.3438\n",
            "Epoch 196/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8773 - loss: 0.2999 - val_accuracy: 0.8500 - val_loss: 0.3430\n",
            "Epoch 197/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8697 - loss: 0.3103 - val_accuracy: 0.8500 - val_loss: 0.3422\n",
            "Epoch 198/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8666 - loss: 0.3153 - val_accuracy: 0.8500 - val_loss: 0.3416\n",
            "Epoch 199/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8696 - loss: 0.3093 - val_accuracy: 0.8500 - val_loss: 0.3412\n",
            "Epoch 200/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8638 - loss: 0.3168 - val_accuracy: 0.8500 - val_loss: 0.3402\n",
            "Epoch 201/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8691 - loss: 0.3066 - val_accuracy: 0.8500 - val_loss: 0.3393\n",
            "Epoch 202/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8674 - loss: 0.3054 - val_accuracy: 0.8500 - val_loss: 0.3385\n",
            "Epoch 203/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8662 - loss: 0.3098 - val_accuracy: 0.8500 - val_loss: 0.3379\n",
            "Epoch 204/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8592 - loss: 0.3149 - val_accuracy: 0.8500 - val_loss: 0.3373\n",
            "Epoch 205/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8699 - loss: 0.3032 - val_accuracy: 0.8500 - val_loss: 0.3366\n",
            "Epoch 206/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8744 - loss: 0.2966 - val_accuracy: 0.8500 - val_loss: 0.3356\n",
            "Epoch 207/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8697 - loss: 0.3014 - val_accuracy: 0.8500 - val_loss: 0.3350\n",
            "Epoch 208/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8654 - loss: 0.3061 - val_accuracy: 0.8500 - val_loss: 0.3343\n",
            "Epoch 209/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8704 - loss: 0.3067 - val_accuracy: 0.8500 - val_loss: 0.3335\n",
            "Epoch 210/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8699 - loss: 0.2928 - val_accuracy: 0.8500 - val_loss: 0.3328\n",
            "Epoch 211/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8708 - loss: 0.2968 - val_accuracy: 0.8500 - val_loss: 0.3323\n",
            "Epoch 212/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8713 - loss: 0.2992 - val_accuracy: 0.8500 - val_loss: 0.3321\n",
            "Epoch 213/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8816 - loss: 0.2876 - val_accuracy: 0.8500 - val_loss: 0.3312\n",
            "Epoch 214/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8662 - loss: 0.3057 - val_accuracy: 0.8500 - val_loss: 0.3306\n",
            "Epoch 215/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8751 - loss: 0.2913 - val_accuracy: 0.8500 - val_loss: 0.3297\n",
            "Epoch 216/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8702 - loss: 0.2940 - val_accuracy: 0.8500 - val_loss: 0.3289\n",
            "Epoch 217/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8728 - loss: 0.2871 - val_accuracy: 0.8500 - val_loss: 0.3284\n",
            "Epoch 218/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8670 - loss: 0.3010 - val_accuracy: 0.8500 - val_loss: 0.3280\n",
            "Epoch 219/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8732 - loss: 0.2940 - val_accuracy: 0.8500 - val_loss: 0.3277\n",
            "Epoch 220/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8794 - loss: 0.2881 - val_accuracy: 0.8500 - val_loss: 0.3273\n",
            "Epoch 221/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8785 - loss: 0.2916 - val_accuracy: 0.8500 - val_loss: 0.3268\n",
            "Epoch 222/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8683 - loss: 0.2982 - val_accuracy: 0.8500 - val_loss: 0.3261\n",
            "Epoch 223/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8698 - loss: 0.2919 - val_accuracy: 0.8500 - val_loss: 0.3257\n",
            "Epoch 224/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8726 - loss: 0.2947 - val_accuracy: 0.8500 - val_loss: 0.3253\n",
            "Epoch 225/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8837 - loss: 0.2747 - val_accuracy: 0.8500 - val_loss: 0.3248\n",
            "Epoch 226/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8700 - loss: 0.2957 - val_accuracy: 0.8500 - val_loss: 0.3241\n",
            "Epoch 227/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8734 - loss: 0.2934 - val_accuracy: 0.8500 - val_loss: 0.3237\n",
            "Epoch 228/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8696 - loss: 0.2929 - val_accuracy: 0.8500 - val_loss: 0.3229\n",
            "Epoch 229/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8790 - loss: 0.2857 - val_accuracy: 0.8500 - val_loss: 0.3222\n",
            "Epoch 230/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8629 - loss: 0.3057 - val_accuracy: 0.8500 - val_loss: 0.3215\n",
            "Epoch 231/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8765 - loss: 0.2884 - val_accuracy: 0.8400 - val_loss: 0.3209\n",
            "Epoch 232/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8777 - loss: 0.2821 - val_accuracy: 0.8500 - val_loss: 0.3205\n",
            "Epoch 233/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8736 - loss: 0.2911 - val_accuracy: 0.8400 - val_loss: 0.3201\n",
            "Epoch 234/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8727 - loss: 0.3002 - val_accuracy: 0.8400 - val_loss: 0.3196\n",
            "Epoch 235/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8724 - loss: 0.2961 - val_accuracy: 0.8400 - val_loss: 0.3188\n",
            "Epoch 236/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8763 - loss: 0.2855 - val_accuracy: 0.8400 - val_loss: 0.3183\n",
            "Epoch 237/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8827 - loss: 0.2778 - val_accuracy: 0.8400 - val_loss: 0.3182\n",
            "Epoch 238/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8814 - loss: 0.2800 - val_accuracy: 0.8400 - val_loss: 0.3177\n",
            "Epoch 239/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8804 - loss: 0.2805 - val_accuracy: 0.8400 - val_loss: 0.3170\n",
            "Epoch 240/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8725 - loss: 0.2935 - val_accuracy: 0.8400 - val_loss: 0.3167\n",
            "Epoch 241/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8744 - loss: 0.2884 - val_accuracy: 0.8400 - val_loss: 0.3163\n",
            "Epoch 242/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8722 - loss: 0.2897 - val_accuracy: 0.8400 - val_loss: 0.3162\n",
            "Epoch 243/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8810 - loss: 0.2768 - val_accuracy: 0.8400 - val_loss: 0.3161\n",
            "Epoch 244/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8721 - loss: 0.2857 - val_accuracy: 0.8400 - val_loss: 0.3154\n",
            "Epoch 245/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8809 - loss: 0.2778 - val_accuracy: 0.8400 - val_loss: 0.3151\n",
            "Epoch 246/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8733 - loss: 0.2924 - val_accuracy: 0.8400 - val_loss: 0.3145\n",
            "Epoch 247/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8666 - loss: 0.2944 - val_accuracy: 0.8400 - val_loss: 0.3139\n",
            "Epoch 248/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8719 - loss: 0.2898 - val_accuracy: 0.8400 - val_loss: 0.3135\n",
            "Epoch 249/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8763 - loss: 0.2805 - val_accuracy: 0.8500 - val_loss: 0.3133\n",
            "Epoch 250/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8856 - loss: 0.2683 - val_accuracy: 0.8400 - val_loss: 0.3125\n",
            "Epoch 251/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8724 - loss: 0.2910 - val_accuracy: 0.8300 - val_loss: 0.3121\n",
            "Epoch 252/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8867 - loss: 0.2734 - val_accuracy: 0.8300 - val_loss: 0.3115\n",
            "Epoch 253/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8818 - loss: 0.2660 - val_accuracy: 0.8400 - val_loss: 0.3113\n",
            "Epoch 254/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8715 - loss: 0.2883 - val_accuracy: 0.8400 - val_loss: 0.3110\n",
            "Epoch 255/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8871 - loss: 0.2598 - val_accuracy: 0.8400 - val_loss: 0.3104\n",
            "Epoch 256/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8800 - loss: 0.2774 - val_accuracy: 0.8400 - val_loss: 0.3099\n",
            "Epoch 257/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8666 - loss: 0.2880 - val_accuracy: 0.8400 - val_loss: 0.3096\n",
            "Epoch 258/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8763 - loss: 0.2777 - val_accuracy: 0.8400 - val_loss: 0.3091\n",
            "Epoch 259/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8683 - loss: 0.2906 - val_accuracy: 0.8400 - val_loss: 0.3082\n",
            "Epoch 260/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8788 - loss: 0.2750 - val_accuracy: 0.8400 - val_loss: 0.3080\n",
            "Epoch 261/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8932 - loss: 0.2592 - val_accuracy: 0.8400 - val_loss: 0.3074\n",
            "Epoch 262/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8677 - loss: 0.2866 - val_accuracy: 0.8400 - val_loss: 0.3073\n",
            "Epoch 263/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8689 - loss: 0.2826 - val_accuracy: 0.8400 - val_loss: 0.3069\n",
            "Epoch 264/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8705 - loss: 0.2799 - val_accuracy: 0.8400 - val_loss: 0.3066\n",
            "Epoch 265/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8802 - loss: 0.2802 - val_accuracy: 0.8400 - val_loss: 0.3062\n",
            "Epoch 266/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8845 - loss: 0.2659 - val_accuracy: 0.8400 - val_loss: 0.3058\n",
            "Epoch 267/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8819 - loss: 0.2701 - val_accuracy: 0.8400 - val_loss: 0.3052\n",
            "Epoch 268/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8844 - loss: 0.2586 - val_accuracy: 0.8400 - val_loss: 0.3052\n",
            "Epoch 269/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8781 - loss: 0.2787 - val_accuracy: 0.8400 - val_loss: 0.3047\n",
            "Epoch 270/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8934 - loss: 0.2525 - val_accuracy: 0.8400 - val_loss: 0.3045\n",
            "Epoch 271/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8829 - loss: 0.2699 - val_accuracy: 0.8400 - val_loss: 0.3044\n",
            "Epoch 272/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8796 - loss: 0.2692 - val_accuracy: 0.8400 - val_loss: 0.3042\n",
            "Epoch 273/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8771 - loss: 0.2773 - val_accuracy: 0.8400 - val_loss: 0.3035\n",
            "Epoch 274/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8811 - loss: 0.2728 - val_accuracy: 0.8400 - val_loss: 0.3034\n",
            "Epoch 275/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8840 - loss: 0.2622 - val_accuracy: 0.8400 - val_loss: 0.3026\n",
            "Epoch 276/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8795 - loss: 0.2727 - val_accuracy: 0.8400 - val_loss: 0.3021\n",
            "Epoch 277/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8868 - loss: 0.2653 - val_accuracy: 0.8400 - val_loss: 0.3014\n",
            "Epoch 278/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8750 - loss: 0.2808 - val_accuracy: 0.8400 - val_loss: 0.3015\n",
            "Epoch 279/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8864 - loss: 0.2626 - val_accuracy: 0.8400 - val_loss: 0.3008\n",
            "Epoch 280/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8843 - loss: 0.2644 - val_accuracy: 0.8400 - val_loss: 0.3007\n",
            "Epoch 281/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8819 - loss: 0.2656 - val_accuracy: 0.8400 - val_loss: 0.3003\n",
            "Epoch 282/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8979 - loss: 0.2445 - val_accuracy: 0.8400 - val_loss: 0.2992\n",
            "Epoch 283/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8818 - loss: 0.2670 - val_accuracy: 0.8400 - val_loss: 0.2986\n",
            "Epoch 284/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8849 - loss: 0.2549 - val_accuracy: 0.8400 - val_loss: 0.2986\n",
            "Epoch 285/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8792 - loss: 0.2690 - val_accuracy: 0.8400 - val_loss: 0.2983\n",
            "Epoch 286/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8795 - loss: 0.2767 - val_accuracy: 0.8400 - val_loss: 0.2978\n",
            "Epoch 287/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8866 - loss: 0.2661 - val_accuracy: 0.8400 - val_loss: 0.2973\n",
            "Epoch 288/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8781 - loss: 0.2728 - val_accuracy: 0.8400 - val_loss: 0.2971\n",
            "Epoch 289/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8778 - loss: 0.2659 - val_accuracy: 0.8400 - val_loss: 0.2969\n",
            "Epoch 290/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8829 - loss: 0.2699 - val_accuracy: 0.8400 - val_loss: 0.2966\n",
            "Epoch 291/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8925 - loss: 0.2473 - val_accuracy: 0.8400 - val_loss: 0.2960\n",
            "Epoch 292/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8852 - loss: 0.2634 - val_accuracy: 0.8400 - val_loss: 0.2952\n",
            "Epoch 293/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8731 - loss: 0.2708 - val_accuracy: 0.8400 - val_loss: 0.2945\n",
            "Epoch 294/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8813 - loss: 0.2631 - val_accuracy: 0.8400 - val_loss: 0.2945\n",
            "Epoch 295/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8732 - loss: 0.2761 - val_accuracy: 0.8400 - val_loss: 0.2942\n",
            "Epoch 296/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8811 - loss: 0.2623 - val_accuracy: 0.8400 - val_loss: 0.2942\n",
            "Epoch 297/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8935 - loss: 0.2452 - val_accuracy: 0.8400 - val_loss: 0.2941\n",
            "Epoch 298/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8884 - loss: 0.2547 - val_accuracy: 0.8400 - val_loss: 0.2934\n",
            "Epoch 299/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8706 - loss: 0.2668 - val_accuracy: 0.8400 - val_loss: 0.2932\n",
            "Epoch 300/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8726 - loss: 0.2688 - val_accuracy: 0.8400 - val_loss: 0.2928\n",
            "Epoch 301/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8789 - loss: 0.2594 - val_accuracy: 0.8400 - val_loss: 0.2926\n",
            "Epoch 302/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8835 - loss: 0.2624 - val_accuracy: 0.8400 - val_loss: 0.2922\n",
            "Epoch 303/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8837 - loss: 0.2558 - val_accuracy: 0.8400 - val_loss: 0.2919\n",
            "Epoch 304/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8815 - loss: 0.2591 - val_accuracy: 0.8400 - val_loss: 0.2915\n",
            "Epoch 305/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8709 - loss: 0.2764 - val_accuracy: 0.8400 - val_loss: 0.2909\n",
            "Epoch 306/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8813 - loss: 0.2640 - val_accuracy: 0.8400 - val_loss: 0.2907\n",
            "Epoch 307/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8753 - loss: 0.2661 - val_accuracy: 0.8400 - val_loss: 0.2901\n",
            "Epoch 308/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8792 - loss: 0.2584 - val_accuracy: 0.8400 - val_loss: 0.2899\n",
            "Epoch 309/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8754 - loss: 0.2642 - val_accuracy: 0.8400 - val_loss: 0.2898\n",
            "Epoch 310/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8799 - loss: 0.2599 - val_accuracy: 0.8400 - val_loss: 0.2894\n",
            "Epoch 311/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8752 - loss: 0.2688 - val_accuracy: 0.8400 - val_loss: 0.2894\n",
            "Epoch 312/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8892 - loss: 0.2488 - val_accuracy: 0.8400 - val_loss: 0.2886\n",
            "Epoch 313/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8849 - loss: 0.2456 - val_accuracy: 0.8400 - val_loss: 0.2882\n",
            "Epoch 314/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8862 - loss: 0.2457 - val_accuracy: 0.8400 - val_loss: 0.2879\n",
            "Epoch 315/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8844 - loss: 0.2517 - val_accuracy: 0.8500 - val_loss: 0.2888\n",
            "Epoch 316/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8858 - loss: 0.2573 - val_accuracy: 0.8500 - val_loss: 0.2879\n",
            "Epoch 317/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8797 - loss: 0.2547 - val_accuracy: 0.8500 - val_loss: 0.2870\n",
            "Epoch 318/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8810 - loss: 0.2573 - val_accuracy: 0.8500 - val_loss: 0.2870\n",
            "Epoch 319/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8811 - loss: 0.2475 - val_accuracy: 0.8500 - val_loss: 0.2860\n",
            "Epoch 320/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8778 - loss: 0.2591 - val_accuracy: 0.8500 - val_loss: 0.2853\n",
            "Epoch 321/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8936 - loss: 0.2393 - val_accuracy: 0.8500 - val_loss: 0.2848\n",
            "Epoch 322/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8836 - loss: 0.2553 - val_accuracy: 0.8500 - val_loss: 0.2845\n",
            "Epoch 323/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8788 - loss: 0.2641 - val_accuracy: 0.8500 - val_loss: 0.2840\n",
            "Epoch 324/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8873 - loss: 0.2600 - val_accuracy: 0.8500 - val_loss: 0.2837\n",
            "Epoch 325/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8840 - loss: 0.2536 - val_accuracy: 0.8500 - val_loss: 0.2831\n",
            "Epoch 326/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8844 - loss: 0.2537 - val_accuracy: 0.8500 - val_loss: 0.2830\n",
            "Epoch 327/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8867 - loss: 0.2545 - val_accuracy: 0.8500 - val_loss: 0.2827\n",
            "Epoch 328/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8944 - loss: 0.2456 - val_accuracy: 0.8500 - val_loss: 0.2824\n",
            "Epoch 329/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8914 - loss: 0.2551 - val_accuracy: 0.8500 - val_loss: 0.2820\n",
            "Epoch 330/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8863 - loss: 0.2497 - val_accuracy: 0.8500 - val_loss: 0.2822\n",
            "Epoch 331/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8836 - loss: 0.2516 - val_accuracy: 0.8500 - val_loss: 0.2819\n",
            "Epoch 332/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8867 - loss: 0.2454 - val_accuracy: 0.8500 - val_loss: 0.2818\n",
            "Epoch 333/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8871 - loss: 0.2469 - val_accuracy: 0.8500 - val_loss: 0.2812\n",
            "Epoch 334/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8844 - loss: 0.2503 - val_accuracy: 0.8500 - val_loss: 0.2805\n",
            "Epoch 335/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8910 - loss: 0.2563 - val_accuracy: 0.8500 - val_loss: 0.2807\n",
            "Epoch 336/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8825 - loss: 0.2621 - val_accuracy: 0.8500 - val_loss: 0.2808\n",
            "Epoch 337/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8822 - loss: 0.2595 - val_accuracy: 0.8500 - val_loss: 0.2803\n",
            "Epoch 338/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8790 - loss: 0.2541 - val_accuracy: 0.8500 - val_loss: 0.2799\n",
            "Epoch 339/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8875 - loss: 0.2421 - val_accuracy: 0.8500 - val_loss: 0.2794\n",
            "Epoch 340/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8806 - loss: 0.2602 - val_accuracy: 0.8500 - val_loss: 0.2794\n",
            "Epoch 341/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8911 - loss: 0.2440 - val_accuracy: 0.8500 - val_loss: 0.2788\n",
            "Epoch 342/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8864 - loss: 0.2498 - val_accuracy: 0.8500 - val_loss: 0.2783\n",
            "Epoch 343/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8891 - loss: 0.2460 - val_accuracy: 0.8500 - val_loss: 0.2776\n",
            "Epoch 344/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8842 - loss: 0.2544 - val_accuracy: 0.8500 - val_loss: 0.2772\n",
            "Epoch 345/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8851 - loss: 0.2562 - val_accuracy: 0.8500 - val_loss: 0.2771\n",
            "Epoch 346/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8894 - loss: 0.2390 - val_accuracy: 0.8500 - val_loss: 0.2767\n",
            "Epoch 347/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8860 - loss: 0.2493 - val_accuracy: 0.8500 - val_loss: 0.2764\n",
            "Epoch 348/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8884 - loss: 0.2405 - val_accuracy: 0.8500 - val_loss: 0.2760\n",
            "Epoch 349/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8859 - loss: 0.2457 - val_accuracy: 0.8500 - val_loss: 0.2756\n",
            "Epoch 350/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8918 - loss: 0.2354 - val_accuracy: 0.8500 - val_loss: 0.2752\n",
            "Epoch 351/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8919 - loss: 0.2417 - val_accuracy: 0.8500 - val_loss: 0.2747\n",
            "Epoch 352/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8983 - loss: 0.2369 - val_accuracy: 0.8500 - val_loss: 0.2740\n",
            "Epoch 353/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8916 - loss: 0.2465 - val_accuracy: 0.8500 - val_loss: 0.2743\n",
            "Epoch 354/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8864 - loss: 0.2509 - val_accuracy: 0.8500 - val_loss: 0.2736\n",
            "Epoch 355/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8985 - loss: 0.2399 - val_accuracy: 0.8500 - val_loss: 0.2733\n",
            "Epoch 356/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8956 - loss: 0.2407 - val_accuracy: 0.8500 - val_loss: 0.2732\n",
            "Epoch 357/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8972 - loss: 0.2425 - val_accuracy: 0.8500 - val_loss: 0.2729\n",
            "Epoch 358/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8890 - loss: 0.2403 - val_accuracy: 0.8500 - val_loss: 0.2727\n",
            "Epoch 359/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8955 - loss: 0.2382 - val_accuracy: 0.8500 - val_loss: 0.2724\n",
            "Epoch 360/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8949 - loss: 0.2445 - val_accuracy: 0.8500 - val_loss: 0.2719\n",
            "Epoch 361/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8911 - loss: 0.2425 - val_accuracy: 0.8500 - val_loss: 0.2715\n",
            "Epoch 362/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8951 - loss: 0.2394 - val_accuracy: 0.8500 - val_loss: 0.2720\n",
            "Epoch 363/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9100 - loss: 0.2212 - val_accuracy: 0.8500 - val_loss: 0.2715\n",
            "Epoch 364/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9010 - loss: 0.2246 - val_accuracy: 0.8500 - val_loss: 0.2708\n",
            "Epoch 365/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8944 - loss: 0.2420 - val_accuracy: 0.8500 - val_loss: 0.2705\n",
            "Epoch 366/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9007 - loss: 0.2333 - val_accuracy: 0.8500 - val_loss: 0.2702\n",
            "Epoch 367/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9017 - loss: 0.2294 - val_accuracy: 0.8500 - val_loss: 0.2695\n",
            "Epoch 368/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8879 - loss: 0.2529 - val_accuracy: 0.8500 - val_loss: 0.2692\n",
            "Epoch 369/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8894 - loss: 0.2519 - val_accuracy: 0.8500 - val_loss: 0.2690\n",
            "Epoch 370/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8956 - loss: 0.2480 - val_accuracy: 0.8500 - val_loss: 0.2688\n",
            "Epoch 371/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8978 - loss: 0.2310 - val_accuracy: 0.8500 - val_loss: 0.2687\n",
            "Epoch 372/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8905 - loss: 0.2418 - val_accuracy: 0.8500 - val_loss: 0.2681\n",
            "Epoch 373/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9048 - loss: 0.2271 - val_accuracy: 0.8500 - val_loss: 0.2673\n",
            "Epoch 374/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9042 - loss: 0.2309 - val_accuracy: 0.8500 - val_loss: 0.2669\n",
            "Epoch 375/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9043 - loss: 0.2324 - val_accuracy: 0.8500 - val_loss: 0.2665\n",
            "Epoch 376/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8956 - loss: 0.2347 - val_accuracy: 0.8500 - val_loss: 0.2662\n",
            "Epoch 377/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8964 - loss: 0.2347 - val_accuracy: 0.8600 - val_loss: 0.2654\n",
            "Epoch 378/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8991 - loss: 0.2378 - val_accuracy: 0.8600 - val_loss: 0.2649\n",
            "Epoch 379/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9096 - loss: 0.2294 - val_accuracy: 0.8600 - val_loss: 0.2647\n",
            "Epoch 380/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9038 - loss: 0.2314 - val_accuracy: 0.8500 - val_loss: 0.2648\n",
            "Epoch 381/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8927 - loss: 0.2454 - val_accuracy: 0.8600 - val_loss: 0.2642\n",
            "Epoch 382/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8995 - loss: 0.2379 - val_accuracy: 0.8600 - val_loss: 0.2637\n",
            "Epoch 383/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9022 - loss: 0.2369 - val_accuracy: 0.8500 - val_loss: 0.2637\n",
            "Epoch 384/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9043 - loss: 0.2282 - val_accuracy: 0.8500 - val_loss: 0.2636\n",
            "Epoch 385/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8966 - loss: 0.2355 - val_accuracy: 0.8600 - val_loss: 0.2629\n",
            "Epoch 386/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9007 - loss: 0.2264 - val_accuracy: 0.8600 - val_loss: 0.2625\n",
            "Epoch 387/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8958 - loss: 0.2454 - val_accuracy: 0.8600 - val_loss: 0.2620\n",
            "Epoch 388/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9046 - loss: 0.2264 - val_accuracy: 0.8500 - val_loss: 0.2624\n",
            "Epoch 389/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9023 - loss: 0.2279 - val_accuracy: 0.8600 - val_loss: 0.2639\n",
            "Epoch 390/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9065 - loss: 0.2245 - val_accuracy: 0.8600 - val_loss: 0.2628\n",
            "Epoch 391/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8979 - loss: 0.2404 - val_accuracy: 0.8600 - val_loss: 0.2618\n",
            "Epoch 392/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9069 - loss: 0.2235 - val_accuracy: 0.8600 - val_loss: 0.2605\n",
            "Epoch 393/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9062 - loss: 0.2236 - val_accuracy: 0.8700 - val_loss: 0.2602\n",
            "Epoch 394/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9069 - loss: 0.2287 - val_accuracy: 0.8600 - val_loss: 0.2593\n",
            "Epoch 395/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9084 - loss: 0.2225 - val_accuracy: 0.8600 - val_loss: 0.2589\n",
            "Epoch 396/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9064 - loss: 0.2291 - val_accuracy: 0.8700 - val_loss: 0.2588\n",
            "Epoch 397/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9090 - loss: 0.2207 - val_accuracy: 0.8700 - val_loss: 0.2585\n",
            "Epoch 398/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9046 - loss: 0.2312 - val_accuracy: 0.8700 - val_loss: 0.2578\n",
            "Epoch 399/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9098 - loss: 0.2154 - val_accuracy: 0.8700 - val_loss: 0.2575\n",
            "Epoch 400/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8963 - loss: 0.2332 - val_accuracy: 0.8700 - val_loss: 0.2573\n",
            "Epoch 401/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9107 - loss: 0.2199 - val_accuracy: 0.8700 - val_loss: 0.2572\n",
            "Epoch 402/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9004 - loss: 0.2241 - val_accuracy: 0.8700 - val_loss: 0.2564\n",
            "Epoch 403/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9054 - loss: 0.2202 - val_accuracy: 0.8700 - val_loss: 0.2561\n",
            "Epoch 404/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9044 - loss: 0.2254 - val_accuracy: 0.8700 - val_loss: 0.2564\n",
            "Epoch 405/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9032 - loss: 0.2319 - val_accuracy: 0.8700 - val_loss: 0.2563\n",
            "Epoch 406/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9026 - loss: 0.2244 - val_accuracy: 0.8700 - val_loss: 0.2557\n",
            "Epoch 407/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9029 - loss: 0.2287 - val_accuracy: 0.8700 - val_loss: 0.2553\n",
            "Epoch 408/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9004 - loss: 0.2331 - val_accuracy: 0.8700 - val_loss: 0.2552\n",
            "Epoch 409/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9088 - loss: 0.2145 - val_accuracy: 0.8700 - val_loss: 0.2546\n",
            "Epoch 410/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9143 - loss: 0.2134 - val_accuracy: 0.8700 - val_loss: 0.2553\n",
            "Epoch 411/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9058 - loss: 0.2286 - val_accuracy: 0.8700 - val_loss: 0.2546\n",
            "Epoch 412/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9070 - loss: 0.2291 - val_accuracy: 0.8700 - val_loss: 0.2540\n",
            "Epoch 413/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9060 - loss: 0.2261 - val_accuracy: 0.8700 - val_loss: 0.2531\n",
            "Epoch 414/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9089 - loss: 0.2207 - val_accuracy: 0.8700 - val_loss: 0.2532\n",
            "Epoch 415/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9110 - loss: 0.2173 - val_accuracy: 0.8700 - val_loss: 0.2522\n",
            "Epoch 416/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9131 - loss: 0.2173 - val_accuracy: 0.8700 - val_loss: 0.2522\n",
            "Epoch 417/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9064 - loss: 0.2254 - val_accuracy: 0.8700 - val_loss: 0.2516\n",
            "Epoch 418/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9086 - loss: 0.2226 - val_accuracy: 0.8700 - val_loss: 0.2510\n",
            "Epoch 419/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9039 - loss: 0.2242 - val_accuracy: 0.8700 - val_loss: 0.2507\n",
            "Epoch 420/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9091 - loss: 0.2198 - val_accuracy: 0.8700 - val_loss: 0.2500\n",
            "Epoch 421/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9054 - loss: 0.2244 - val_accuracy: 0.8700 - val_loss: 0.2505\n",
            "Epoch 422/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9144 - loss: 0.2127 - val_accuracy: 0.8700 - val_loss: 0.2496\n",
            "Epoch 423/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9024 - loss: 0.2299 - val_accuracy: 0.8700 - val_loss: 0.2496\n",
            "Epoch 424/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9176 - loss: 0.2041 - val_accuracy: 0.8700 - val_loss: 0.2489\n",
            "Epoch 425/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9089 - loss: 0.2163 - val_accuracy: 0.8700 - val_loss: 0.2485\n",
            "Epoch 426/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9056 - loss: 0.2190 - val_accuracy: 0.8700 - val_loss: 0.2485\n",
            "Epoch 427/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9177 - loss: 0.2036 - val_accuracy: 0.8700 - val_loss: 0.2476\n",
            "Epoch 428/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9076 - loss: 0.2210 - val_accuracy: 0.8700 - val_loss: 0.2470\n",
            "Epoch 429/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9127 - loss: 0.2130 - val_accuracy: 0.8700 - val_loss: 0.2464\n",
            "Epoch 430/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9092 - loss: 0.2101 - val_accuracy: 0.8700 - val_loss: 0.2464\n",
            "Epoch 431/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9054 - loss: 0.2255 - val_accuracy: 0.8700 - val_loss: 0.2466\n",
            "Epoch 432/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9130 - loss: 0.2071 - val_accuracy: 0.8700 - val_loss: 0.2456\n",
            "Epoch 433/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9078 - loss: 0.2169 - val_accuracy: 0.8700 - val_loss: 0.2459\n",
            "Epoch 434/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9075 - loss: 0.2152 - val_accuracy: 0.8700 - val_loss: 0.2461\n",
            "Epoch 435/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9110 - loss: 0.2101 - val_accuracy: 0.8700 - val_loss: 0.2464\n",
            "Epoch 436/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9057 - loss: 0.2170 - val_accuracy: 0.8700 - val_loss: 0.2455\n",
            "Epoch 437/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9115 - loss: 0.2117 - val_accuracy: 0.8700 - val_loss: 0.2448\n",
            "Epoch 438/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9065 - loss: 0.2184 - val_accuracy: 0.8700 - val_loss: 0.2451\n",
            "Epoch 439/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9089 - loss: 0.2111 - val_accuracy: 0.8700 - val_loss: 0.2445\n",
            "Epoch 440/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9059 - loss: 0.2241 - val_accuracy: 0.8700 - val_loss: 0.2435\n",
            "Epoch 441/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9129 - loss: 0.2081 - val_accuracy: 0.8700 - val_loss: 0.2440\n",
            "Epoch 442/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9082 - loss: 0.2140 - val_accuracy: 0.8700 - val_loss: 0.2434\n",
            "Epoch 443/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9061 - loss: 0.2155 - val_accuracy: 0.8700 - val_loss: 0.2431\n",
            "Epoch 444/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9087 - loss: 0.2159 - val_accuracy: 0.8700 - val_loss: 0.2427\n",
            "Epoch 445/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9052 - loss: 0.2191 - val_accuracy: 0.8700 - val_loss: 0.2418\n",
            "Epoch 446/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9049 - loss: 0.2188 - val_accuracy: 0.8700 - val_loss: 0.2409\n",
            "Epoch 447/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9117 - loss: 0.2209 - val_accuracy: 0.8700 - val_loss: 0.2412\n",
            "Epoch 448/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9189 - loss: 0.1982 - val_accuracy: 0.8700 - val_loss: 0.2411\n",
            "Epoch 449/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9203 - loss: 0.1956 - val_accuracy: 0.8700 - val_loss: 0.2405\n",
            "Epoch 450/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9063 - loss: 0.2068 - val_accuracy: 0.8700 - val_loss: 0.2397\n",
            "Epoch 451/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.2111 - val_accuracy: 0.8700 - val_loss: 0.2394\n",
            "Epoch 452/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9055 - loss: 0.2147 - val_accuracy: 0.8700 - val_loss: 0.2397\n",
            "Epoch 453/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9074 - loss: 0.2128 - val_accuracy: 0.8700 - val_loss: 0.2395\n",
            "Epoch 454/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9127 - loss: 0.2041 - val_accuracy: 0.8700 - val_loss: 0.2389\n",
            "Epoch 455/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9148 - loss: 0.2054 - val_accuracy: 0.8700 - val_loss: 0.2384\n",
            "Epoch 456/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9035 - loss: 0.2141 - val_accuracy: 0.8700 - val_loss: 0.2374\n",
            "Epoch 457/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9096 - loss: 0.2054 - val_accuracy: 0.8800 - val_loss: 0.2368\n",
            "Epoch 458/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9037 - loss: 0.2165 - val_accuracy: 0.8700 - val_loss: 0.2368\n",
            "Epoch 459/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9085 - loss: 0.2128 - val_accuracy: 0.8700 - val_loss: 0.2364\n",
            "Epoch 460/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9167 - loss: 0.2007 - val_accuracy: 0.8700 - val_loss: 0.2367\n",
            "Epoch 461/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9070 - loss: 0.2163 - val_accuracy: 0.8700 - val_loss: 0.2364\n",
            "Epoch 462/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9051 - loss: 0.2145 - val_accuracy: 0.8700 - val_loss: 0.2360\n",
            "Epoch 463/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9147 - loss: 0.2009 - val_accuracy: 0.8700 - val_loss: 0.2352\n",
            "Epoch 464/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9035 - loss: 0.2164 - val_accuracy: 0.8700 - val_loss: 0.2355\n",
            "Epoch 465/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9063 - loss: 0.2116 - val_accuracy: 0.8700 - val_loss: 0.2356\n",
            "Epoch 466/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9166 - loss: 0.2003 - val_accuracy: 0.8700 - val_loss: 0.2353\n",
            "Epoch 467/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9152 - loss: 0.2072 - val_accuracy: 0.8700 - val_loss: 0.2349\n",
            "Epoch 468/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9225 - loss: 0.1954 - val_accuracy: 0.8700 - val_loss: 0.2342\n",
            "Epoch 469/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9073 - loss: 0.2156 - val_accuracy: 0.8700 - val_loss: 0.2333\n",
            "Epoch 470/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9174 - loss: 0.1944 - val_accuracy: 0.8800 - val_loss: 0.2329\n",
            "Epoch 471/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9032 - loss: 0.2121 - val_accuracy: 0.8800 - val_loss: 0.2325\n",
            "Epoch 472/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9150 - loss: 0.2075 - val_accuracy: 0.8700 - val_loss: 0.2324\n",
            "Epoch 473/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9117 - loss: 0.2095 - val_accuracy: 0.8800 - val_loss: 0.2317\n",
            "Epoch 474/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9103 - loss: 0.2076 - val_accuracy: 0.8800 - val_loss: 0.2308\n",
            "Epoch 475/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9153 - loss: 0.1973 - val_accuracy: 0.8800 - val_loss: 0.2306\n",
            "Epoch 476/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9102 - loss: 0.2053 - val_accuracy: 0.8800 - val_loss: 0.2297\n",
            "Epoch 477/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9161 - loss: 0.1990 - val_accuracy: 0.8800 - val_loss: 0.2296\n",
            "Epoch 478/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9151 - loss: 0.2054 - val_accuracy: 0.8800 - val_loss: 0.2289\n",
            "Epoch 479/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9028 - loss: 0.2036 - val_accuracy: 0.8800 - val_loss: 0.2285\n",
            "Epoch 480/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9150 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2280\n",
            "Epoch 481/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9062 - loss: 0.2095 - val_accuracy: 0.8800 - val_loss: 0.2277\n",
            "Epoch 482/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9205 - loss: 0.1959 - val_accuracy: 0.8900 - val_loss: 0.2280\n",
            "Epoch 483/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9190 - loss: 0.1918 - val_accuracy: 0.8900 - val_loss: 0.2278\n",
            "Epoch 484/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9141 - loss: 0.2008 - val_accuracy: 0.8900 - val_loss: 0.2272\n",
            "Epoch 485/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9129 - loss: 0.2084 - val_accuracy: 0.8900 - val_loss: 0.2260\n",
            "Epoch 486/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9143 - loss: 0.1998 - val_accuracy: 0.9000 - val_loss: 0.2255\n",
            "Epoch 487/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9181 - loss: 0.1993 - val_accuracy: 0.9000 - val_loss: 0.2251\n",
            "Epoch 488/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9175 - loss: 0.1965 - val_accuracy: 0.8900 - val_loss: 0.2251\n",
            "Epoch 489/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9174 - loss: 0.2042 - val_accuracy: 0.8900 - val_loss: 0.2246\n",
            "Epoch 490/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9139 - loss: 0.2020 - val_accuracy: 0.8900 - val_loss: 0.2249\n",
            "Epoch 491/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9223 - loss: 0.1901 - val_accuracy: 0.8900 - val_loss: 0.2240\n",
            "Epoch 492/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9158 - loss: 0.1944 - val_accuracy: 0.9000 - val_loss: 0.2233\n",
            "Epoch 493/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9170 - loss: 0.1969 - val_accuracy: 0.9000 - val_loss: 0.2228\n",
            "Epoch 494/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9118 - loss: 0.2013 - val_accuracy: 0.9000 - val_loss: 0.2224\n",
            "Epoch 495/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9122 - loss: 0.2090 - val_accuracy: 0.9000 - val_loss: 0.2222\n",
            "Epoch 496/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9244 - loss: 0.1964 - val_accuracy: 0.9000 - val_loss: 0.2215\n",
            "Epoch 497/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9162 - loss: 0.2048 - val_accuracy: 0.9000 - val_loss: 0.2213\n",
            "Epoch 498/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9307 - loss: 0.1865 - val_accuracy: 0.9000 - val_loss: 0.2210\n",
            "Epoch 499/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9212 - loss: 0.2018 - val_accuracy: 0.9000 - val_loss: 0.2209\n",
            "Epoch 500/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9207 - loss: 0.1879 - val_accuracy: 0.9000 - val_loss: 0.2201\n",
            "Epoch 501/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9201 - loss: 0.2048 - val_accuracy: 0.9000 - val_loss: 0.2202\n",
            "Epoch 502/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9206 - loss: 0.2010 - val_accuracy: 0.9000 - val_loss: 0.2188\n",
            "Epoch 503/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9249 - loss: 0.1911 - val_accuracy: 0.9000 - val_loss: 0.2180\n",
            "Epoch 504/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9239 - loss: 0.1948 - val_accuracy: 0.9000 - val_loss: 0.2177\n",
            "Epoch 505/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9260 - loss: 0.1810 - val_accuracy: 0.9000 - val_loss: 0.2176\n",
            "Epoch 506/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9225 - loss: 0.1946 - val_accuracy: 0.9000 - val_loss: 0.2165\n",
            "Epoch 507/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9282 - loss: 0.1864 - val_accuracy: 0.9000 - val_loss: 0.2170\n",
            "Epoch 508/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9209 - loss: 0.1974 - val_accuracy: 0.9000 - val_loss: 0.2162\n",
            "Epoch 509/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9219 - loss: 0.1938 - val_accuracy: 0.9000 - val_loss: 0.2166\n",
            "Epoch 510/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9251 - loss: 0.1892 - val_accuracy: 0.9000 - val_loss: 0.2159\n",
            "Epoch 511/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9285 - loss: 0.1824 - val_accuracy: 0.9000 - val_loss: 0.2149\n",
            "Epoch 512/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9206 - loss: 0.1996 - val_accuracy: 0.9000 - val_loss: 0.2147\n",
            "Epoch 513/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9357 - loss: 0.1780 - val_accuracy: 0.9000 - val_loss: 0.2147\n",
            "Epoch 514/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9230 - loss: 0.1893 - val_accuracy: 0.9000 - val_loss: 0.2141\n",
            "Epoch 515/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9276 - loss: 0.1836 - val_accuracy: 0.9000 - val_loss: 0.2145\n",
            "Epoch 516/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9229 - loss: 0.1911 - val_accuracy: 0.9000 - val_loss: 0.2129\n",
            "Epoch 517/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9245 - loss: 0.1903 - val_accuracy: 0.9000 - val_loss: 0.2122\n",
            "Epoch 518/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9264 - loss: 0.1812 - val_accuracy: 0.9000 - val_loss: 0.2118\n",
            "Epoch 519/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9276 - loss: 0.1855 - val_accuracy: 0.9000 - val_loss: 0.2107\n",
            "Epoch 520/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9286 - loss: 0.1955 - val_accuracy: 0.9000 - val_loss: 0.2100\n",
            "Epoch 521/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9278 - loss: 0.1823 - val_accuracy: 0.9000 - val_loss: 0.2099\n",
            "Epoch 522/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9276 - loss: 0.1786 - val_accuracy: 0.9000 - val_loss: 0.2098\n",
            "Epoch 523/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9230 - loss: 0.1908 - val_accuracy: 0.9000 - val_loss: 0.2097\n",
            "Epoch 524/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9280 - loss: 0.1844 - val_accuracy: 0.9000 - val_loss: 0.2093\n",
            "Epoch 525/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9215 - loss: 0.1952 - val_accuracy: 0.9000 - val_loss: 0.2089\n",
            "Epoch 526/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9324 - loss: 0.1784 - val_accuracy: 0.9000 - val_loss: 0.2087\n",
            "Epoch 527/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9236 - loss: 0.1866 - val_accuracy: 0.9000 - val_loss: 0.2081\n",
            "Epoch 528/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9257 - loss: 0.1902 - val_accuracy: 0.9000 - val_loss: 0.2072\n",
            "Epoch 529/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9332 - loss: 0.1794 - val_accuracy: 0.9000 - val_loss: 0.2072\n",
            "Epoch 530/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9248 - loss: 0.1941 - val_accuracy: 0.9000 - val_loss: 0.2064\n",
            "Epoch 531/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9294 - loss: 0.1817 - val_accuracy: 0.9000 - val_loss: 0.2064\n",
            "Epoch 532/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9259 - loss: 0.1850 - val_accuracy: 0.9000 - val_loss: 0.2057\n",
            "Epoch 533/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9278 - loss: 0.1841 - val_accuracy: 0.9000 - val_loss: 0.2057\n",
            "Epoch 534/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9283 - loss: 0.1818 - val_accuracy: 0.9000 - val_loss: 0.2063\n",
            "Epoch 535/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9203 - loss: 0.1962 - val_accuracy: 0.9000 - val_loss: 0.2053\n",
            "Epoch 536/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9285 - loss: 0.1800 - val_accuracy: 0.9000 - val_loss: 0.2044\n",
            "Epoch 537/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9358 - loss: 0.1725 - val_accuracy: 0.9000 - val_loss: 0.2041\n",
            "Epoch 538/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9245 - loss: 0.1913 - val_accuracy: 0.9000 - val_loss: 0.2037\n",
            "Epoch 539/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9279 - loss: 0.1820 - val_accuracy: 0.9000 - val_loss: 0.2025\n",
            "Epoch 540/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9299 - loss: 0.1759 - val_accuracy: 0.9000 - val_loss: 0.2018\n",
            "Epoch 541/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9300 - loss: 0.1760 - val_accuracy: 0.9000 - val_loss: 0.2026\n",
            "Epoch 542/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9328 - loss: 0.1773 - val_accuracy: 0.9000 - val_loss: 0.2013\n",
            "Epoch 543/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9311 - loss: 0.1755 - val_accuracy: 0.9000 - val_loss: 0.2007\n",
            "Epoch 544/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9324 - loss: 0.1735 - val_accuracy: 0.9000 - val_loss: 0.2002\n",
            "Epoch 545/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9304 - loss: 0.1773 - val_accuracy: 0.9000 - val_loss: 0.1994\n",
            "Epoch 546/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9317 - loss: 0.1726 - val_accuracy: 0.9000 - val_loss: 0.1991\n",
            "Epoch 547/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9267 - loss: 0.1797 - val_accuracy: 0.9000 - val_loss: 0.1989\n",
            "Epoch 548/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9346 - loss: 0.1716 - val_accuracy: 0.9000 - val_loss: 0.1986\n",
            "Epoch 549/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9288 - loss: 0.1741 - val_accuracy: 0.9000 - val_loss: 0.1976\n",
            "Epoch 550/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9341 - loss: 0.1736 - val_accuracy: 0.9000 - val_loss: 0.1979\n",
            "Epoch 551/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9323 - loss: 0.1771 - val_accuracy: 0.9000 - val_loss: 0.1970\n",
            "Epoch 552/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9335 - loss: 0.1713 - val_accuracy: 0.9000 - val_loss: 0.1967\n",
            "Epoch 553/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9303 - loss: 0.1776 - val_accuracy: 0.9000 - val_loss: 0.1961\n",
            "Epoch 554/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9342 - loss: 0.1760 - val_accuracy: 0.9000 - val_loss: 0.1958\n",
            "Epoch 555/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9346 - loss: 0.1702 - val_accuracy: 0.9000 - val_loss: 0.1955\n",
            "Epoch 556/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9272 - loss: 0.1821 - val_accuracy: 0.9000 - val_loss: 0.1948\n",
            "Epoch 557/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9375 - loss: 0.1724 - val_accuracy: 0.9000 - val_loss: 0.1952\n",
            "Epoch 558/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9302 - loss: 0.1810 - val_accuracy: 0.9000 - val_loss: 0.1940\n",
            "Epoch 559/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9358 - loss: 0.1721 - val_accuracy: 0.9000 - val_loss: 0.1940\n",
            "Epoch 560/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9268 - loss: 0.1766 - val_accuracy: 0.9000 - val_loss: 0.1937\n",
            "Epoch 561/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9278 - loss: 0.1755 - val_accuracy: 0.9000 - val_loss: 0.1928\n",
            "Epoch 562/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9381 - loss: 0.1673 - val_accuracy: 0.9000 - val_loss: 0.1921\n",
            "Epoch 563/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9319 - loss: 0.1728 - val_accuracy: 0.9000 - val_loss: 0.1916\n",
            "Epoch 564/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9328 - loss: 0.1713 - val_accuracy: 0.9000 - val_loss: 0.1917\n",
            "Epoch 565/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9320 - loss: 0.1710 - val_accuracy: 0.9000 - val_loss: 0.1919\n",
            "Epoch 566/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9420 - loss: 0.1586 - val_accuracy: 0.9000 - val_loss: 0.1921\n",
            "Epoch 567/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9402 - loss: 0.1698 - val_accuracy: 0.9000 - val_loss: 0.1911\n",
            "Epoch 568/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9333 - loss: 0.1800 - val_accuracy: 0.9000 - val_loss: 0.1903\n",
            "Epoch 569/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9397 - loss: 0.1631 - val_accuracy: 0.9000 - val_loss: 0.1896\n",
            "Epoch 570/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9338 - loss: 0.1708 - val_accuracy: 0.9000 - val_loss: 0.1897\n",
            "Epoch 571/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9361 - loss: 0.1729 - val_accuracy: 0.9000 - val_loss: 0.1891\n",
            "Epoch 572/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9284 - loss: 0.1777 - val_accuracy: 0.9000 - val_loss: 0.1890\n",
            "Epoch 573/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9389 - loss: 0.1631 - val_accuracy: 0.9000 - val_loss: 0.1885\n",
            "Epoch 574/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9340 - loss: 0.1689 - val_accuracy: 0.9000 - val_loss: 0.1885\n",
            "Epoch 575/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9310 - loss: 0.1730 - val_accuracy: 0.9000 - val_loss: 0.1879\n",
            "Epoch 576/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9313 - loss: 0.1760 - val_accuracy: 0.9000 - val_loss: 0.1874\n",
            "Epoch 577/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9325 - loss: 0.1743 - val_accuracy: 0.9000 - val_loss: 0.1873\n",
            "Epoch 578/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9398 - loss: 0.1653 - val_accuracy: 0.9000 - val_loss: 0.1856\n",
            "Epoch 579/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9428 - loss: 0.1650 - val_accuracy: 0.9000 - val_loss: 0.1854\n",
            "Epoch 580/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9327 - loss: 0.1717 - val_accuracy: 0.9000 - val_loss: 0.1842\n",
            "Epoch 581/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9365 - loss: 0.1639 - val_accuracy: 0.9000 - val_loss: 0.1850\n",
            "Epoch 582/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9388 - loss: 0.1681 - val_accuracy: 0.9000 - val_loss: 0.1848\n",
            "Epoch 583/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9472 - loss: 0.1524 - val_accuracy: 0.9000 - val_loss: 0.1839\n",
            "Epoch 584/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9405 - loss: 0.1591 - val_accuracy: 0.9000 - val_loss: 0.1830\n",
            "Epoch 585/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9337 - loss: 0.1718 - val_accuracy: 0.9000 - val_loss: 0.1830\n",
            "Epoch 586/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9321 - loss: 0.1755 - val_accuracy: 0.9000 - val_loss: 0.1823\n",
            "Epoch 587/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9414 - loss: 0.1596 - val_accuracy: 0.9000 - val_loss: 0.1821\n",
            "Epoch 588/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9370 - loss: 0.1669 - val_accuracy: 0.9000 - val_loss: 0.1808\n",
            "Epoch 589/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9357 - loss: 0.1601 - val_accuracy: 0.9000 - val_loss: 0.1799\n",
            "Epoch 590/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9377 - loss: 0.1634 - val_accuracy: 0.9000 - val_loss: 0.1802\n",
            "Epoch 591/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9409 - loss: 0.1596 - val_accuracy: 0.9000 - val_loss: 0.1798\n",
            "Epoch 592/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9438 - loss: 0.1598 - val_accuracy: 0.9100 - val_loss: 0.1802\n",
            "Epoch 593/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9349 - loss: 0.1660 - val_accuracy: 0.9000 - val_loss: 0.1793\n",
            "Epoch 594/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9409 - loss: 0.1539 - val_accuracy: 0.9100 - val_loss: 0.1789\n",
            "Epoch 595/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9407 - loss: 0.1575 - val_accuracy: 0.9100 - val_loss: 0.1788\n",
            "Epoch 596/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9345 - loss: 0.1632 - val_accuracy: 0.9100 - val_loss: 0.1785\n",
            "Epoch 597/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9334 - loss: 0.1664 - val_accuracy: 0.9100 - val_loss: 0.1776\n",
            "Epoch 598/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9348 - loss: 0.1715 - val_accuracy: 0.9000 - val_loss: 0.1769\n",
            "Epoch 599/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9350 - loss: 0.1588 - val_accuracy: 0.9000 - val_loss: 0.1766\n",
            "Epoch 600/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9345 - loss: 0.1641 - val_accuracy: 0.9000 - val_loss: 0.1759\n",
            "Epoch 601/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9353 - loss: 0.1675 - val_accuracy: 0.9200 - val_loss: 0.1762\n",
            "Epoch 602/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9397 - loss: 0.1622 - val_accuracy: 0.9200 - val_loss: 0.1754\n",
            "Epoch 603/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9417 - loss: 0.1549 - val_accuracy: 0.9200 - val_loss: 0.1748\n",
            "Epoch 604/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9371 - loss: 0.1572 - val_accuracy: 0.9200 - val_loss: 0.1744\n",
            "Epoch 605/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9437 - loss: 0.1560 - val_accuracy: 0.9200 - val_loss: 0.1743\n",
            "Epoch 606/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9345 - loss: 0.1662 - val_accuracy: 0.9200 - val_loss: 0.1736\n",
            "Epoch 607/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9307 - loss: 0.1697 - val_accuracy: 0.9200 - val_loss: 0.1731\n",
            "Epoch 608/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9458 - loss: 0.1505 - val_accuracy: 0.9200 - val_loss: 0.1728\n",
            "Epoch 609/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9363 - loss: 0.1666 - val_accuracy: 0.9200 - val_loss: 0.1726\n",
            "Epoch 610/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9434 - loss: 0.1589 - val_accuracy: 0.9200 - val_loss: 0.1719\n",
            "Epoch 611/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9424 - loss: 0.1494 - val_accuracy: 0.9200 - val_loss: 0.1709\n",
            "Epoch 612/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9448 - loss: 0.1530 - val_accuracy: 0.9200 - val_loss: 0.1712\n",
            "Epoch 613/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9373 - loss: 0.1560 - val_accuracy: 0.9200 - val_loss: 0.1710\n",
            "Epoch 614/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9442 - loss: 0.1528 - val_accuracy: 0.9200 - val_loss: 0.1711\n",
            "Epoch 615/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9389 - loss: 0.1576 - val_accuracy: 0.9200 - val_loss: 0.1708\n",
            "Epoch 616/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9487 - loss: 0.1509 - val_accuracy: 0.9200 - val_loss: 0.1700\n",
            "Epoch 617/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9369 - loss: 0.1615 - val_accuracy: 0.9200 - val_loss: 0.1695\n",
            "Epoch 618/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9481 - loss: 0.1478 - val_accuracy: 0.9200 - val_loss: 0.1691\n",
            "Epoch 619/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9429 - loss: 0.1486 - val_accuracy: 0.9300 - val_loss: 0.1676\n",
            "Epoch 620/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9429 - loss: 0.1520 - val_accuracy: 0.9200 - val_loss: 0.1676\n",
            "Epoch 621/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9402 - loss: 0.1536 - val_accuracy: 0.9200 - val_loss: 0.1675\n",
            "Epoch 622/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9419 - loss: 0.1543 - val_accuracy: 0.9200 - val_loss: 0.1679\n",
            "Epoch 623/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9425 - loss: 0.1562 - val_accuracy: 0.9200 - val_loss: 0.1672\n",
            "Epoch 624/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9431 - loss: 0.1488 - val_accuracy: 0.9300 - val_loss: 0.1658\n",
            "Epoch 625/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9427 - loss: 0.1493 - val_accuracy: 0.9300 - val_loss: 0.1651\n",
            "Epoch 626/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9429 - loss: 0.1572 - val_accuracy: 0.9300 - val_loss: 0.1651\n",
            "Epoch 627/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9397 - loss: 0.1584 - val_accuracy: 0.9300 - val_loss: 0.1639\n",
            "Epoch 628/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9388 - loss: 0.1538 - val_accuracy: 0.9300 - val_loss: 0.1645\n",
            "Epoch 629/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9389 - loss: 0.1522 - val_accuracy: 0.9300 - val_loss: 0.1642\n",
            "Epoch 630/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9388 - loss: 0.1513 - val_accuracy: 0.9300 - val_loss: 0.1627\n",
            "Epoch 631/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9426 - loss: 0.1468 - val_accuracy: 0.9300 - val_loss: 0.1629\n",
            "Epoch 632/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9359 - loss: 0.1518 - val_accuracy: 0.9300 - val_loss: 0.1629\n",
            "Epoch 633/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9392 - loss: 0.1531 - val_accuracy: 0.9400 - val_loss: 0.1625\n",
            "Epoch 634/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9412 - loss: 0.1478 - val_accuracy: 0.9300 - val_loss: 0.1632\n",
            "Epoch 635/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9431 - loss: 0.1543 - val_accuracy: 0.9400 - val_loss: 0.1615\n",
            "Epoch 636/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9409 - loss: 0.1494 - val_accuracy: 0.9400 - val_loss: 0.1610\n",
            "Epoch 637/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9397 - loss: 0.1528 - val_accuracy: 0.9400 - val_loss: 0.1611\n",
            "Epoch 638/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9406 - loss: 0.1446 - val_accuracy: 0.9400 - val_loss: 0.1607\n",
            "Epoch 639/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9427 - loss: 0.1476 - val_accuracy: 0.9400 - val_loss: 0.1598\n",
            "Epoch 640/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9387 - loss: 0.1514 - val_accuracy: 0.9400 - val_loss: 0.1595\n",
            "Epoch 641/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9371 - loss: 0.1532 - val_accuracy: 0.9400 - val_loss: 0.1594\n",
            "Epoch 642/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9458 - loss: 0.1437 - val_accuracy: 0.9400 - val_loss: 0.1581\n",
            "Epoch 643/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9371 - loss: 0.1521 - val_accuracy: 0.9400 - val_loss: 0.1578\n",
            "Epoch 644/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9402 - loss: 0.1486 - val_accuracy: 0.9300 - val_loss: 0.1568\n",
            "Epoch 645/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9434 - loss: 0.1429 - val_accuracy: 0.9300 - val_loss: 0.1565\n",
            "Epoch 646/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9420 - loss: 0.1505 - val_accuracy: 0.9400 - val_loss: 0.1567\n",
            "Epoch 647/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9417 - loss: 0.1490 - val_accuracy: 0.9400 - val_loss: 0.1562\n",
            "Epoch 648/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9429 - loss: 0.1318 - val_accuracy: 0.9300 - val_loss: 0.1554\n",
            "Epoch 649/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9404 - loss: 0.1480 - val_accuracy: 0.9300 - val_loss: 0.1546\n",
            "Epoch 650/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9482 - loss: 0.1339 - val_accuracy: 0.9300 - val_loss: 0.1542\n",
            "Epoch 651/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9418 - loss: 0.1470 - val_accuracy: 0.9300 - val_loss: 0.1539\n",
            "Epoch 652/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9432 - loss: 0.1426 - val_accuracy: 0.9300 - val_loss: 0.1537\n",
            "Epoch 653/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9420 - loss: 0.1453 - val_accuracy: 0.9400 - val_loss: 0.1535\n",
            "Epoch 654/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9423 - loss: 0.1377 - val_accuracy: 0.9400 - val_loss: 0.1529\n",
            "Epoch 655/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9492 - loss: 0.1340 - val_accuracy: 0.9400 - val_loss: 0.1531\n",
            "Epoch 656/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9445 - loss: 0.1411 - val_accuracy: 0.9500 - val_loss: 0.1532\n",
            "Epoch 657/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9435 - loss: 0.1481 - val_accuracy: 0.9500 - val_loss: 0.1529\n",
            "Epoch 658/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9382 - loss: 0.1460 - val_accuracy: 0.9400 - val_loss: 0.1516\n",
            "Epoch 659/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9444 - loss: 0.1432 - val_accuracy: 0.9500 - val_loss: 0.1516\n",
            "Epoch 660/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9438 - loss: 0.1414 - val_accuracy: 0.9400 - val_loss: 0.1507\n",
            "Epoch 661/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9443 - loss: 0.1357 - val_accuracy: 0.9400 - val_loss: 0.1504\n",
            "Epoch 662/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9444 - loss: 0.1356 - val_accuracy: 0.9500 - val_loss: 0.1503\n",
            "Epoch 663/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9418 - loss: 0.1436 - val_accuracy: 0.9500 - val_loss: 0.1500\n",
            "Epoch 664/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9427 - loss: 0.1464 - val_accuracy: 0.9400 - val_loss: 0.1487\n",
            "Epoch 665/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9428 - loss: 0.1434 - val_accuracy: 0.9400 - val_loss: 0.1485\n",
            "Epoch 666/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9480 - loss: 0.1324 - val_accuracy: 0.9500 - val_loss: 0.1484\n",
            "Epoch 667/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9441 - loss: 0.1417 - val_accuracy: 0.9500 - val_loss: 0.1489\n",
            "Epoch 668/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9480 - loss: 0.1306 - val_accuracy: 0.9500 - val_loss: 0.1480\n",
            "Epoch 669/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9532 - loss: 0.1286 - val_accuracy: 0.9500 - val_loss: 0.1473\n",
            "Epoch 670/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9462 - loss: 0.1351 - val_accuracy: 0.9500 - val_loss: 0.1476\n",
            "Epoch 671/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9471 - loss: 0.1314 - val_accuracy: 0.9500 - val_loss: 0.1471\n",
            "Epoch 672/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9462 - loss: 0.1384 - val_accuracy: 0.9500 - val_loss: 0.1467\n",
            "Epoch 673/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9449 - loss: 0.1431 - val_accuracy: 0.9500 - val_loss: 0.1463\n",
            "Epoch 674/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9465 - loss: 0.1402 - val_accuracy: 0.9500 - val_loss: 0.1456\n",
            "Epoch 675/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9440 - loss: 0.1390 - val_accuracy: 0.9500 - val_loss: 0.1448\n",
            "Epoch 676/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9420 - loss: 0.1427 - val_accuracy: 0.9500 - val_loss: 0.1451\n",
            "Epoch 677/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9460 - loss: 0.1328 - val_accuracy: 0.9500 - val_loss: 0.1446\n",
            "Epoch 678/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9551 - loss: 0.1267 - val_accuracy: 0.9500 - val_loss: 0.1446\n",
            "Epoch 679/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9435 - loss: 0.1374 - val_accuracy: 0.9500 - val_loss: 0.1439\n",
            "Epoch 680/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9418 - loss: 0.1398 - val_accuracy: 0.9500 - val_loss: 0.1435\n",
            "Epoch 681/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9501 - loss: 0.1294 - val_accuracy: 0.9500 - val_loss: 0.1434\n",
            "Epoch 682/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9479 - loss: 0.1296 - val_accuracy: 0.9500 - val_loss: 0.1422\n",
            "Epoch 683/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9518 - loss: 0.1327 - val_accuracy: 0.9600 - val_loss: 0.1414\n",
            "Epoch 684/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9435 - loss: 0.1434 - val_accuracy: 0.9500 - val_loss: 0.1418\n",
            "Epoch 685/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9447 - loss: 0.1369 - val_accuracy: 0.9600 - val_loss: 0.1404\n",
            "Epoch 686/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9542 - loss: 0.1273 - val_accuracy: 0.9500 - val_loss: 0.1406\n",
            "Epoch 687/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9500 - loss: 0.1267 - val_accuracy: 0.9500 - val_loss: 0.1406\n",
            "Epoch 688/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9504 - loss: 0.1330 - val_accuracy: 0.9500 - val_loss: 0.1402\n",
            "Epoch 689/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9556 - loss: 0.1219 - val_accuracy: 0.9600 - val_loss: 0.1390\n",
            "Epoch 690/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9490 - loss: 0.1366 - val_accuracy: 0.9500 - val_loss: 0.1393\n",
            "Epoch 691/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9498 - loss: 0.1297 - val_accuracy: 0.9500 - val_loss: 0.1385\n",
            "Epoch 692/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9521 - loss: 0.1245 - val_accuracy: 0.9600 - val_loss: 0.1377\n",
            "Epoch 693/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9488 - loss: 0.1349 - val_accuracy: 0.9500 - val_loss: 0.1380\n",
            "Epoch 694/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9461 - loss: 0.1360 - val_accuracy: 0.9500 - val_loss: 0.1377\n",
            "Epoch 695/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9592 - loss: 0.1223 - val_accuracy: 0.9600 - val_loss: 0.1363\n",
            "Epoch 696/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9506 - loss: 0.1325 - val_accuracy: 0.9600 - val_loss: 0.1363\n",
            "Epoch 697/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9521 - loss: 0.1275 - val_accuracy: 0.9600 - val_loss: 0.1358\n",
            "Epoch 698/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9484 - loss: 0.1316 - val_accuracy: 0.9500 - val_loss: 0.1364\n",
            "Epoch 699/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9506 - loss: 0.1353 - val_accuracy: 0.9500 - val_loss: 0.1362\n",
            "Epoch 700/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9489 - loss: 0.1292 - val_accuracy: 0.9600 - val_loss: 0.1354\n",
            "Epoch 701/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9419 - loss: 0.1389 - val_accuracy: 0.9600 - val_loss: 0.1349\n",
            "Epoch 702/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9514 - loss: 0.1257 - val_accuracy: 0.9600 - val_loss: 0.1344\n",
            "Epoch 703/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9552 - loss: 0.1227 - val_accuracy: 0.9600 - val_loss: 0.1341\n",
            "Epoch 704/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9485 - loss: 0.1291 - val_accuracy: 0.9600 - val_loss: 0.1341\n",
            "Epoch 705/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9532 - loss: 0.1208 - val_accuracy: 0.9500 - val_loss: 0.1339\n",
            "Epoch 706/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9569 - loss: 0.1297 - val_accuracy: 0.9600 - val_loss: 0.1326\n",
            "Epoch 707/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9487 - loss: 0.1279 - val_accuracy: 0.9600 - val_loss: 0.1328\n",
            "Epoch 708/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9503 - loss: 0.1219 - val_accuracy: 0.9600 - val_loss: 0.1322\n",
            "Epoch 709/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9585 - loss: 0.1247 - val_accuracy: 0.9600 - val_loss: 0.1325\n",
            "Epoch 710/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9567 - loss: 0.1276 - val_accuracy: 0.9600 - val_loss: 0.1310\n",
            "Epoch 711/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9489 - loss: 0.1277 - val_accuracy: 0.9600 - val_loss: 0.1312\n",
            "Epoch 712/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9575 - loss: 0.1184 - val_accuracy: 0.9600 - val_loss: 0.1311\n",
            "Epoch 713/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9519 - loss: 0.1324 - val_accuracy: 0.9600 - val_loss: 0.1304\n",
            "Epoch 714/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9544 - loss: 0.1286 - val_accuracy: 0.9600 - val_loss: 0.1305\n",
            "Epoch 715/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9548 - loss: 0.1327 - val_accuracy: 0.9600 - val_loss: 0.1303\n",
            "Epoch 716/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9569 - loss: 0.1222 - val_accuracy: 0.9600 - val_loss: 0.1304\n",
            "Epoch 717/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9473 - loss: 0.1373 - val_accuracy: 0.9500 - val_loss: 0.1301\n",
            "Epoch 718/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9481 - loss: 0.1313 - val_accuracy: 0.9600 - val_loss: 0.1289\n",
            "Epoch 719/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9520 - loss: 0.1286 - val_accuracy: 0.9600 - val_loss: 0.1286\n",
            "Epoch 720/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9572 - loss: 0.1211 - val_accuracy: 0.9600 - val_loss: 0.1282\n",
            "Epoch 721/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9494 - loss: 0.1236 - val_accuracy: 0.9600 - val_loss: 0.1287\n",
            "Epoch 722/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9582 - loss: 0.1275 - val_accuracy: 0.9600 - val_loss: 0.1280\n",
            "Epoch 723/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9478 - loss: 0.1365 - val_accuracy: 0.9600 - val_loss: 0.1279\n",
            "Epoch 724/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9534 - loss: 0.1254 - val_accuracy: 0.9500 - val_loss: 0.1280\n",
            "Epoch 725/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9524 - loss: 0.1252 - val_accuracy: 0.9600 - val_loss: 0.1277\n",
            "Epoch 726/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9496 - loss: 0.1254 - val_accuracy: 0.9600 - val_loss: 0.1267\n",
            "Epoch 727/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9480 - loss: 0.1345 - val_accuracy: 0.9600 - val_loss: 0.1257\n",
            "Epoch 728/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9567 - loss: 0.1257 - val_accuracy: 0.9600 - val_loss: 0.1257\n",
            "Epoch 729/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9574 - loss: 0.1128 - val_accuracy: 0.9600 - val_loss: 0.1248\n",
            "Epoch 730/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9571 - loss: 0.1219 - val_accuracy: 0.9600 - val_loss: 0.1251\n",
            "Epoch 731/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9529 - loss: 0.1298 - val_accuracy: 0.9600 - val_loss: 0.1237\n",
            "Epoch 732/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9550 - loss: 0.1128 - val_accuracy: 0.9600 - val_loss: 0.1237\n",
            "Epoch 733/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9601 - loss: 0.1163 - val_accuracy: 0.9600 - val_loss: 0.1244\n",
            "Epoch 734/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9517 - loss: 0.1268 - val_accuracy: 0.9600 - val_loss: 0.1239\n",
            "Epoch 735/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9576 - loss: 0.1230 - val_accuracy: 0.9600 - val_loss: 0.1238\n",
            "Epoch 736/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9572 - loss: 0.1186 - val_accuracy: 0.9600 - val_loss: 0.1232\n",
            "Epoch 737/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9509 - loss: 0.1223 - val_accuracy: 0.9600 - val_loss: 0.1228\n",
            "Epoch 738/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9488 - loss: 0.1273 - val_accuracy: 0.9600 - val_loss: 0.1224\n",
            "Epoch 739/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9600 - loss: 0.1124 - val_accuracy: 0.9600 - val_loss: 0.1216\n",
            "Epoch 740/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9583 - loss: 0.1159 - val_accuracy: 0.9600 - val_loss: 0.1218\n",
            "Epoch 741/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9623 - loss: 0.1108 - val_accuracy: 0.9600 - val_loss: 0.1213\n",
            "Epoch 742/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9602 - loss: 0.1146 - val_accuracy: 0.9600 - val_loss: 0.1209\n",
            "Epoch 743/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9643 - loss: 0.1088 - val_accuracy: 0.9600 - val_loss: 0.1210\n",
            "Epoch 744/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9634 - loss: 0.1093 - val_accuracy: 0.9600 - val_loss: 0.1207\n",
            "Epoch 745/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9514 - loss: 0.1214 - val_accuracy: 0.9600 - val_loss: 0.1199\n",
            "Epoch 746/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9568 - loss: 0.1172 - val_accuracy: 0.9600 - val_loss: 0.1189\n",
            "Epoch 747/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9588 - loss: 0.1149 - val_accuracy: 0.9600 - val_loss: 0.1185\n",
            "Epoch 748/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9586 - loss: 0.1233 - val_accuracy: 0.9600 - val_loss: 0.1192\n",
            "Epoch 749/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9558 - loss: 0.1155 - val_accuracy: 0.9600 - val_loss: 0.1184\n",
            "Epoch 750/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9610 - loss: 0.1175 - val_accuracy: 0.9600 - val_loss: 0.1177\n",
            "Epoch 751/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9599 - loss: 0.1127 - val_accuracy: 0.9600 - val_loss: 0.1173\n",
            "Epoch 752/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9565 - loss: 0.1215 - val_accuracy: 0.9600 - val_loss: 0.1168\n",
            "Epoch 753/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9557 - loss: 0.1238 - val_accuracy: 0.9600 - val_loss: 0.1164\n",
            "Epoch 754/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9575 - loss: 0.1208 - val_accuracy: 0.9600 - val_loss: 0.1168\n",
            "Epoch 755/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9592 - loss: 0.1144 - val_accuracy: 0.9600 - val_loss: 0.1161\n",
            "Epoch 756/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9575 - loss: 0.1155 - val_accuracy: 0.9600 - val_loss: 0.1159\n",
            "Epoch 757/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9658 - loss: 0.1041 - val_accuracy: 0.9600 - val_loss: 0.1175\n",
            "Epoch 758/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9544 - loss: 0.1189 - val_accuracy: 0.9600 - val_loss: 0.1172\n",
            "Epoch 759/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9611 - loss: 0.1116 - val_accuracy: 0.9600 - val_loss: 0.1175\n",
            "Epoch 760/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9557 - loss: 0.1214 - val_accuracy: 0.9600 - val_loss: 0.1163\n",
            "Epoch 761/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9582 - loss: 0.1156 - val_accuracy: 0.9600 - val_loss: 0.1151\n",
            "Epoch 762/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9538 - loss: 0.1121 - val_accuracy: 0.9600 - val_loss: 0.1149\n",
            "Epoch 763/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9551 - loss: 0.1242 - val_accuracy: 0.9600 - val_loss: 0.1153\n",
            "Epoch 764/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9539 - loss: 0.1167 - val_accuracy: 0.9600 - val_loss: 0.1155\n",
            "Epoch 765/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9584 - loss: 0.1129 - val_accuracy: 0.9600 - val_loss: 0.1149\n",
            "Epoch 766/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9579 - loss: 0.1178 - val_accuracy: 0.9600 - val_loss: 0.1140\n",
            "Epoch 767/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9608 - loss: 0.1103 - val_accuracy: 0.9600 - val_loss: 0.1134\n",
            "Epoch 768/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9574 - loss: 0.1171 - val_accuracy: 0.9600 - val_loss: 0.1131\n",
            "Epoch 769/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9619 - loss: 0.1127 - val_accuracy: 0.9600 - val_loss: 0.1121\n",
            "Epoch 770/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9642 - loss: 0.1064 - val_accuracy: 0.9600 - val_loss: 0.1117\n",
            "Epoch 771/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9608 - loss: 0.1060 - val_accuracy: 0.9600 - val_loss: 0.1133\n",
            "Epoch 772/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9606 - loss: 0.1143 - val_accuracy: 0.9600 - val_loss: 0.1129\n",
            "Epoch 773/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9624 - loss: 0.1042 - val_accuracy: 0.9600 - val_loss: 0.1122\n",
            "Epoch 774/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9609 - loss: 0.1094 - val_accuracy: 0.9600 - val_loss: 0.1110\n",
            "Epoch 775/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9616 - loss: 0.1045 - val_accuracy: 0.9600 - val_loss: 0.1107\n",
            "Epoch 776/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9601 - loss: 0.1065 - val_accuracy: 0.9600 - val_loss: 0.1100\n",
            "Epoch 777/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9606 - loss: 0.1110 - val_accuracy: 0.9600 - val_loss: 0.1095\n",
            "Epoch 778/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9583 - loss: 0.1107 - val_accuracy: 0.9700 - val_loss: 0.1092\n",
            "Epoch 779/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9625 - loss: 0.1049 - val_accuracy: 0.9600 - val_loss: 0.1092\n",
            "Epoch 780/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9651 - loss: 0.1033 - val_accuracy: 0.9600 - val_loss: 0.1092\n",
            "Epoch 781/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9561 - loss: 0.1156 - val_accuracy: 0.9700 - val_loss: 0.1083\n",
            "Epoch 782/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9611 - loss: 0.1072 - val_accuracy: 0.9700 - val_loss: 0.1077\n",
            "Epoch 783/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9554 - loss: 0.1119 - val_accuracy: 0.9700 - val_loss: 0.1076\n",
            "Epoch 784/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9586 - loss: 0.1068 - val_accuracy: 0.9600 - val_loss: 0.1079\n",
            "Epoch 785/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9601 - loss: 0.1080 - val_accuracy: 0.9600 - val_loss: 0.1078\n",
            "Epoch 786/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9620 - loss: 0.1092 - val_accuracy: 0.9600 - val_loss: 0.1091\n",
            "Epoch 787/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9537 - loss: 0.1225 - val_accuracy: 0.9600 - val_loss: 0.1081\n",
            "Epoch 788/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9588 - loss: 0.1052 - val_accuracy: 0.9600 - val_loss: 0.1080\n",
            "Epoch 789/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9593 - loss: 0.1087 - val_accuracy: 0.9600 - val_loss: 0.1073\n",
            "Epoch 790/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9598 - loss: 0.1072 - val_accuracy: 0.9600 - val_loss: 0.1085\n",
            "Epoch 791/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9608 - loss: 0.1104 - val_accuracy: 0.9600 - val_loss: 0.1081\n",
            "Epoch 792/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9654 - loss: 0.1056 - val_accuracy: 0.9700 - val_loss: 0.1061\n",
            "Epoch 793/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9557 - loss: 0.1172 - val_accuracy: 0.9600 - val_loss: 0.1063\n",
            "Epoch 794/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9593 - loss: 0.1012 - val_accuracy: 0.9700 - val_loss: 0.1057\n",
            "Epoch 795/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9610 - loss: 0.1050 - val_accuracy: 0.9700 - val_loss: 0.1054\n",
            "Epoch 796/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9555 - loss: 0.1118 - val_accuracy: 0.9600 - val_loss: 0.1061\n",
            "Epoch 797/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9557 - loss: 0.1153 - val_accuracy: 0.9700 - val_loss: 0.1049\n",
            "Epoch 798/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9539 - loss: 0.1189 - val_accuracy: 0.9700 - val_loss: 0.1039\n",
            "Epoch 799/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9557 - loss: 0.1133 - val_accuracy: 0.9700 - val_loss: 0.1039\n",
            "Epoch 800/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9652 - loss: 0.0997 - val_accuracy: 0.9700 - val_loss: 0.1038\n",
            "Epoch 801/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9641 - loss: 0.1008 - val_accuracy: 0.9800 - val_loss: 0.1037\n",
            "Epoch 802/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9625 - loss: 0.1009 - val_accuracy: 0.9700 - val_loss: 0.1039\n",
            "Epoch 803/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9615 - loss: 0.1044 - val_accuracy: 0.9700 - val_loss: 0.1040\n",
            "Epoch 804/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9610 - loss: 0.1080 - val_accuracy: 0.9800 - val_loss: 0.1025\n",
            "Epoch 805/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9635 - loss: 0.1000 - val_accuracy: 0.9800 - val_loss: 0.1024\n",
            "Epoch 806/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9595 - loss: 0.1064 - val_accuracy: 0.9800 - val_loss: 0.1019\n",
            "Epoch 807/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9635 - loss: 0.1027 - val_accuracy: 0.9800 - val_loss: 0.1013\n",
            "Epoch 808/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9652 - loss: 0.0986 - val_accuracy: 0.9800 - val_loss: 0.1014\n",
            "Epoch 809/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9613 - loss: 0.1059 - val_accuracy: 0.9800 - val_loss: 0.1007\n",
            "Epoch 810/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9599 - loss: 0.1106 - val_accuracy: 0.9800 - val_loss: 0.1013\n",
            "Epoch 811/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9667 - loss: 0.0937 - val_accuracy: 0.9800 - val_loss: 0.1018\n",
            "Epoch 812/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9593 - loss: 0.1101 - val_accuracy: 0.9800 - val_loss: 0.1012\n",
            "Epoch 813/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9628 - loss: 0.1036 - val_accuracy: 0.9800 - val_loss: 0.1010\n",
            "Epoch 814/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9609 - loss: 0.1064 - val_accuracy: 0.9800 - val_loss: 0.1004\n",
            "Epoch 815/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9543 - loss: 0.1091 - val_accuracy: 0.9800 - val_loss: 0.1003\n",
            "Epoch 816/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9572 - loss: 0.1122 - val_accuracy: 0.9800 - val_loss: 0.1005\n",
            "Epoch 817/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9614 - loss: 0.1006 - val_accuracy: 0.9800 - val_loss: 0.1004\n",
            "Epoch 818/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9592 - loss: 0.1056 - val_accuracy: 0.9800 - val_loss: 0.0999\n",
            "Epoch 819/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9611 - loss: 0.1006 - val_accuracy: 0.9800 - val_loss: 0.1007\n",
            "Epoch 820/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9601 - loss: 0.1019 - val_accuracy: 0.9800 - val_loss: 0.1003\n",
            "Epoch 821/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9562 - loss: 0.1131 - val_accuracy: 0.9800 - val_loss: 0.1002\n",
            "Epoch 822/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9653 - loss: 0.0968 - val_accuracy: 0.9800 - val_loss: 0.0993\n",
            "Epoch 823/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9641 - loss: 0.0954 - val_accuracy: 0.9800 - val_loss: 0.0990\n",
            "Epoch 824/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9644 - loss: 0.1017 - val_accuracy: 0.9800 - val_loss: 0.0978\n",
            "Epoch 825/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9611 - loss: 0.1041 - val_accuracy: 0.9800 - val_loss: 0.0979\n",
            "Epoch 826/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9652 - loss: 0.0994 - val_accuracy: 0.9800 - val_loss: 0.0986\n",
            "Epoch 827/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9657 - loss: 0.1043 - val_accuracy: 0.9800 - val_loss: 0.0987\n",
            "Epoch 828/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9574 - loss: 0.1084 - val_accuracy: 0.9800 - val_loss: 0.0979\n",
            "Epoch 829/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9611 - loss: 0.1067 - val_accuracy: 0.9800 - val_loss: 0.0977\n",
            "Epoch 830/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9641 - loss: 0.1014 - val_accuracy: 0.9800 - val_loss: 0.0977\n",
            "Epoch 831/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9586 - loss: 0.1075 - val_accuracy: 0.9800 - val_loss: 0.0971\n",
            "Epoch 832/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9657 - loss: 0.1030 - val_accuracy: 0.9800 - val_loss: 0.0974\n",
            "Epoch 833/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9645 - loss: 0.0954 - val_accuracy: 0.9800 - val_loss: 0.0979\n",
            "Epoch 834/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9672 - loss: 0.1000 - val_accuracy: 0.9800 - val_loss: 0.0978\n",
            "Epoch 835/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9630 - loss: 0.1051 - val_accuracy: 0.9800 - val_loss: 0.0957\n",
            "Epoch 836/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9586 - loss: 0.1040 - val_accuracy: 0.9800 - val_loss: 0.0958\n",
            "Epoch 837/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9641 - loss: 0.1026 - val_accuracy: 0.9800 - val_loss: 0.0952\n",
            "Epoch 838/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9628 - loss: 0.0982 - val_accuracy: 0.9800 - val_loss: 0.0955\n",
            "Epoch 839/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9653 - loss: 0.1039 - val_accuracy: 0.9800 - val_loss: 0.0956\n",
            "Epoch 840/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9641 - loss: 0.0958 - val_accuracy: 0.9800 - val_loss: 0.0949\n",
            "Epoch 841/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9654 - loss: 0.0984 - val_accuracy: 0.9800 - val_loss: 0.0951\n",
            "Epoch 842/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9665 - loss: 0.0976 - val_accuracy: 0.9800 - val_loss: 0.0948\n",
            "Epoch 843/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9616 - loss: 0.1027 - val_accuracy: 0.9800 - val_loss: 0.0947\n",
            "Epoch 844/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9558 - loss: 0.1101 - val_accuracy: 0.9800 - val_loss: 0.0946\n",
            "Epoch 845/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9617 - loss: 0.1011 - val_accuracy: 0.9800 - val_loss: 0.0961\n",
            "Epoch 846/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9643 - loss: 0.0983 - val_accuracy: 0.9800 - val_loss: 0.0945\n",
            "Epoch 847/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9628 - loss: 0.1046 - val_accuracy: 0.9800 - val_loss: 0.0933\n",
            "Epoch 848/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9626 - loss: 0.1040 - val_accuracy: 0.9800 - val_loss: 0.0929\n",
            "Epoch 849/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9677 - loss: 0.0981 - val_accuracy: 0.9800 - val_loss: 0.0932\n",
            "Epoch 850/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9641 - loss: 0.0958 - val_accuracy: 0.9800 - val_loss: 0.0925\n",
            "Epoch 851/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9629 - loss: 0.0959 - val_accuracy: 0.9800 - val_loss: 0.0931\n",
            "Epoch 852/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9631 - loss: 0.1019 - val_accuracy: 0.9800 - val_loss: 0.0920\n",
            "Epoch 853/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9644 - loss: 0.0986 - val_accuracy: 0.9800 - val_loss: 0.0919\n",
            "Epoch 854/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9604 - loss: 0.1079 - val_accuracy: 0.9800 - val_loss: 0.0911\n",
            "Epoch 855/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9630 - loss: 0.0991 - val_accuracy: 0.9800 - val_loss: 0.0913\n",
            "Epoch 856/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9657 - loss: 0.0958 - val_accuracy: 0.9800 - val_loss: 0.0928\n",
            "Epoch 857/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9663 - loss: 0.0947 - val_accuracy: 0.9800 - val_loss: 0.0923\n",
            "Epoch 858/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9654 - loss: 0.0998 - val_accuracy: 0.9800 - val_loss: 0.0920\n",
            "Epoch 859/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9653 - loss: 0.0923 - val_accuracy: 0.9800 - val_loss: 0.0920\n",
            "Epoch 860/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9651 - loss: 0.0929 - val_accuracy: 0.9800 - val_loss: 0.0923\n",
            "Epoch 861/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9678 - loss: 0.0939 - val_accuracy: 0.9800 - val_loss: 0.0910\n",
            "Epoch 862/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9656 - loss: 0.0933 - val_accuracy: 0.9800 - val_loss: 0.0913\n",
            "Epoch 863/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9708 - loss: 0.0920 - val_accuracy: 0.9800 - val_loss: 0.0905\n",
            "Epoch 864/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9678 - loss: 0.0929 - val_accuracy: 0.9800 - val_loss: 0.0903\n",
            "Epoch 865/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9630 - loss: 0.0958 - val_accuracy: 0.9800 - val_loss: 0.0895\n",
            "Epoch 866/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9613 - loss: 0.1011 - val_accuracy: 0.9800 - val_loss: 0.0892\n",
            "Epoch 867/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9634 - loss: 0.0975 - val_accuracy: 0.9800 - val_loss: 0.0896\n",
            "Epoch 868/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9610 - loss: 0.1036 - val_accuracy: 0.9800 - val_loss: 0.0889\n",
            "Epoch 869/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9669 - loss: 0.0935 - val_accuracy: 0.9800 - val_loss: 0.0885\n",
            "Epoch 870/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9659 - loss: 0.0886 - val_accuracy: 0.9800 - val_loss: 0.0883\n",
            "Epoch 871/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9576 - loss: 0.1054 - val_accuracy: 0.9800 - val_loss: 0.0886\n",
            "Epoch 872/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9625 - loss: 0.1014 - val_accuracy: 0.9800 - val_loss: 0.0887\n",
            "Epoch 873/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9631 - loss: 0.0973 - val_accuracy: 0.9800 - val_loss: 0.0881\n",
            "Epoch 874/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9648 - loss: 0.0938 - val_accuracy: 0.9800 - val_loss: 0.0888\n",
            "Epoch 875/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9693 - loss: 0.0956 - val_accuracy: 0.9800 - val_loss: 0.0886\n",
            "Epoch 876/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9631 - loss: 0.1013 - val_accuracy: 0.9800 - val_loss: 0.0883\n",
            "Epoch 877/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9727 - loss: 0.0860 - val_accuracy: 0.9800 - val_loss: 0.0874\n",
            "Epoch 878/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9642 - loss: 0.0924 - val_accuracy: 0.9800 - val_loss: 0.0877\n",
            "Epoch 879/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9632 - loss: 0.0899 - val_accuracy: 0.9800 - val_loss: 0.0884\n",
            "Epoch 880/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9618 - loss: 0.0999 - val_accuracy: 0.9800 - val_loss: 0.0883\n",
            "Epoch 881/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9633 - loss: 0.0992 - val_accuracy: 0.9800 - val_loss: 0.0886\n",
            "Epoch 882/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9679 - loss: 0.0902 - val_accuracy: 0.9800 - val_loss: 0.0876\n",
            "Epoch 883/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9696 - loss: 0.0901 - val_accuracy: 0.9800 - val_loss: 0.0878\n",
            "Epoch 884/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9668 - loss: 0.0928 - val_accuracy: 0.9800 - val_loss: 0.0873\n",
            "Epoch 885/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9738 - loss: 0.0830 - val_accuracy: 0.9800 - val_loss: 0.0860\n",
            "Epoch 886/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9647 - loss: 0.0876 - val_accuracy: 0.9800 - val_loss: 0.0864\n",
            "Epoch 887/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9707 - loss: 0.0866 - val_accuracy: 0.9800 - val_loss: 0.0871\n",
            "Epoch 888/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9673 - loss: 0.0921 - val_accuracy: 0.9800 - val_loss: 0.0856\n",
            "Epoch 889/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9659 - loss: 0.0899 - val_accuracy: 0.9800 - val_loss: 0.0865\n",
            "Epoch 890/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9647 - loss: 0.0966 - val_accuracy: 0.9800 - val_loss: 0.0855\n",
            "Epoch 891/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9646 - loss: 0.0880 - val_accuracy: 0.9800 - val_loss: 0.0856\n",
            "Epoch 892/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9698 - loss: 0.0872 - val_accuracy: 0.9800 - val_loss: 0.0852\n",
            "Epoch 893/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9646 - loss: 0.0955 - val_accuracy: 0.9800 - val_loss: 0.0850\n",
            "Epoch 894/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9681 - loss: 0.0878 - val_accuracy: 0.9800 - val_loss: 0.0855\n",
            "Epoch 895/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9732 - loss: 0.0805 - val_accuracy: 0.9800 - val_loss: 0.0862\n",
            "Epoch 896/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9703 - loss: 0.0948 - val_accuracy: 0.9800 - val_loss: 0.0854\n",
            "Epoch 897/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9741 - loss: 0.0837 - val_accuracy: 0.9800 - val_loss: 0.0847\n",
            "Epoch 898/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9685 - loss: 0.0960 - val_accuracy: 0.9800 - val_loss: 0.0841\n",
            "Epoch 899/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9617 - loss: 0.1019 - val_accuracy: 0.9800 - val_loss: 0.0846\n",
            "Epoch 900/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9617 - loss: 0.0974 - val_accuracy: 0.9800 - val_loss: 0.0842\n",
            "Epoch 901/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9623 - loss: 0.1013 - val_accuracy: 0.9800 - val_loss: 0.0833\n",
            "Epoch 902/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9651 - loss: 0.0948 - val_accuracy: 0.9800 - val_loss: 0.0834\n",
            "Epoch 903/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9606 - loss: 0.0985 - val_accuracy: 0.9800 - val_loss: 0.0836\n",
            "Epoch 904/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9675 - loss: 0.0880 - val_accuracy: 0.9800 - val_loss: 0.0826\n",
            "Epoch 905/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9681 - loss: 0.0905 - val_accuracy: 0.9800 - val_loss: 0.0832\n",
            "Epoch 906/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9572 - loss: 0.0973 - val_accuracy: 0.9800 - val_loss: 0.0832\n",
            "Epoch 907/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9660 - loss: 0.0950 - val_accuracy: 0.9800 - val_loss: 0.0838\n",
            "Epoch 908/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9651 - loss: 0.0992 - val_accuracy: 0.9800 - val_loss: 0.0836\n",
            "Epoch 909/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9600 - loss: 0.1072 - val_accuracy: 0.9800 - val_loss: 0.0834\n",
            "Epoch 910/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9686 - loss: 0.0874 - val_accuracy: 0.9800 - val_loss: 0.0818\n",
            "Epoch 911/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9628 - loss: 0.0979 - val_accuracy: 0.9800 - val_loss: 0.0819\n",
            "Epoch 912/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9595 - loss: 0.1007 - val_accuracy: 0.9800 - val_loss: 0.0826\n",
            "Epoch 913/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9674 - loss: 0.0881 - val_accuracy: 0.9800 - val_loss: 0.0815\n",
            "Epoch 914/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9638 - loss: 0.0957 - val_accuracy: 0.9800 - val_loss: 0.0815\n",
            "Epoch 915/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9651 - loss: 0.0938 - val_accuracy: 0.9800 - val_loss: 0.0811\n",
            "Epoch 916/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9645 - loss: 0.0946 - val_accuracy: 0.9900 - val_loss: 0.0809\n",
            "Epoch 917/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9624 - loss: 0.0979 - val_accuracy: 0.9900 - val_loss: 0.0808\n",
            "Epoch 918/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9681 - loss: 0.0858 - val_accuracy: 0.9900 - val_loss: 0.0808\n",
            "Epoch 919/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9651 - loss: 0.0907 - val_accuracy: 0.9900 - val_loss: 0.0806\n",
            "Epoch 920/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9591 - loss: 0.0936 - val_accuracy: 0.9800 - val_loss: 0.0816\n",
            "Epoch 921/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9653 - loss: 0.0970 - val_accuracy: 0.9800 - val_loss: 0.0815\n",
            "Epoch 922/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9667 - loss: 0.0903 - val_accuracy: 0.9800 - val_loss: 0.0811\n",
            "Epoch 923/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9658 - loss: 0.0915 - val_accuracy: 0.9800 - val_loss: 0.0806\n",
            "Epoch 924/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9658 - loss: 0.0898 - val_accuracy: 0.9800 - val_loss: 0.0807\n",
            "Epoch 925/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9664 - loss: 0.0933 - val_accuracy: 0.9800 - val_loss: 0.0807\n",
            "Epoch 926/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9647 - loss: 0.0887 - val_accuracy: 0.9800 - val_loss: 0.0821\n",
            "Epoch 927/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9697 - loss: 0.0876 - val_accuracy: 0.9800 - val_loss: 0.0812\n",
            "Epoch 928/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9710 - loss: 0.0856 - val_accuracy: 0.9900 - val_loss: 0.0794\n",
            "Epoch 929/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9628 - loss: 0.0959 - val_accuracy: 0.9800 - val_loss: 0.0801\n",
            "Epoch 930/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9618 - loss: 0.0975 - val_accuracy: 0.9800 - val_loss: 0.0798\n",
            "Epoch 931/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9667 - loss: 0.0899 - val_accuracy: 0.9800 - val_loss: 0.0792\n",
            "Epoch 932/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9696 - loss: 0.0869 - val_accuracy: 0.9900 - val_loss: 0.0783\n",
            "Epoch 933/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9666 - loss: 0.0902 - val_accuracy: 0.9900 - val_loss: 0.0782\n",
            "Epoch 934/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9672 - loss: 0.0950 - val_accuracy: 0.9900 - val_loss: 0.0769\n",
            "Epoch 935/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9655 - loss: 0.0909 - val_accuracy: 0.9800 - val_loss: 0.0784\n",
            "Epoch 936/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9660 - loss: 0.0863 - val_accuracy: 0.9900 - val_loss: 0.0784\n",
            "Epoch 937/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9626 - loss: 0.0969 - val_accuracy: 0.9800 - val_loss: 0.0789\n",
            "Epoch 938/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9686 - loss: 0.0859 - val_accuracy: 0.9800 - val_loss: 0.0787\n",
            "Epoch 939/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9635 - loss: 0.0909 - val_accuracy: 0.9900 - val_loss: 0.0782\n",
            "Epoch 940/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9723 - loss: 0.0832 - val_accuracy: 0.9900 - val_loss: 0.0767\n",
            "Epoch 941/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9641 - loss: 0.0920 - val_accuracy: 0.9800 - val_loss: 0.0784\n",
            "Epoch 942/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9680 - loss: 0.0894 - val_accuracy: 0.9800 - val_loss: 0.0784\n",
            "Epoch 943/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9592 - loss: 0.1038 - val_accuracy: 0.9800 - val_loss: 0.0788\n",
            "Epoch 944/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9667 - loss: 0.0915 - val_accuracy: 0.9800 - val_loss: 0.0775\n",
            "Epoch 945/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9601 - loss: 0.0954 - val_accuracy: 0.9900 - val_loss: 0.0768\n",
            "Epoch 946/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9704 - loss: 0.0857 - val_accuracy: 0.9900 - val_loss: 0.0767\n",
            "Epoch 947/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9700 - loss: 0.0902 - val_accuracy: 0.9900 - val_loss: 0.0763\n",
            "Epoch 948/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9695 - loss: 0.0850 - val_accuracy: 0.9900 - val_loss: 0.0766\n",
            "Epoch 949/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9681 - loss: 0.0923 - val_accuracy: 0.9900 - val_loss: 0.0770\n",
            "Epoch 950/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9678 - loss: 0.0842 - val_accuracy: 0.9800 - val_loss: 0.0781\n",
            "Epoch 951/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9661 - loss: 0.0922 - val_accuracy: 0.9800 - val_loss: 0.0789\n",
            "Epoch 952/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9639 - loss: 0.0879 - val_accuracy: 0.9800 - val_loss: 0.0781\n",
            "Epoch 953/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9667 - loss: 0.0893 - val_accuracy: 0.9800 - val_loss: 0.0778\n",
            "Epoch 954/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9686 - loss: 0.0866 - val_accuracy: 0.9900 - val_loss: 0.0761\n",
            "Epoch 955/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9694 - loss: 0.0880 - val_accuracy: 0.9900 - val_loss: 0.0756\n",
            "Epoch 956/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9696 - loss: 0.0901 - val_accuracy: 0.9900 - val_loss: 0.0758\n",
            "Epoch 957/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9662 - loss: 0.0907 - val_accuracy: 0.9800 - val_loss: 0.0765\n",
            "Epoch 958/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9641 - loss: 0.0933 - val_accuracy: 0.9900 - val_loss: 0.0750\n",
            "Epoch 959/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9685 - loss: 0.0845 - val_accuracy: 0.9900 - val_loss: 0.0756\n",
            "Epoch 960/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9664 - loss: 0.0924 - val_accuracy: 0.9900 - val_loss: 0.0756\n",
            "Epoch 961/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9685 - loss: 0.0905 - val_accuracy: 0.9900 - val_loss: 0.0747\n",
            "Epoch 962/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9664 - loss: 0.0928 - val_accuracy: 0.9900 - val_loss: 0.0741\n",
            "Epoch 963/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9701 - loss: 0.0833 - val_accuracy: 0.9900 - val_loss: 0.0740\n",
            "Epoch 964/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9696 - loss: 0.0809 - val_accuracy: 0.9900 - val_loss: 0.0744\n",
            "Epoch 965/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9710 - loss: 0.0765 - val_accuracy: 0.9900 - val_loss: 0.0742\n",
            "Epoch 966/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9672 - loss: 0.0861 - val_accuracy: 0.9900 - val_loss: 0.0748\n",
            "Epoch 967/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9710 - loss: 0.0853 - val_accuracy: 0.9800 - val_loss: 0.0752\n",
            "Epoch 968/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9708 - loss: 0.0857 - val_accuracy: 0.9800 - val_loss: 0.0751\n",
            "Epoch 969/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9651 - loss: 0.0921 - val_accuracy: 0.9800 - val_loss: 0.0756\n",
            "Epoch 970/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9676 - loss: 0.0853 - val_accuracy: 0.9900 - val_loss: 0.0740\n",
            "Epoch 971/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9671 - loss: 0.0873 - val_accuracy: 0.9900 - val_loss: 0.0741\n",
            "Epoch 972/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9677 - loss: 0.0864 - val_accuracy: 0.9800 - val_loss: 0.0751\n",
            "Epoch 973/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9714 - loss: 0.0792 - val_accuracy: 0.9900 - val_loss: 0.0741\n",
            "Epoch 974/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9698 - loss: 0.0864 - val_accuracy: 0.9900 - val_loss: 0.0729\n",
            "Epoch 975/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9658 - loss: 0.0929 - val_accuracy: 0.9900 - val_loss: 0.0731\n",
            "Epoch 976/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9616 - loss: 0.0939 - val_accuracy: 0.9900 - val_loss: 0.0744\n",
            "Epoch 977/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9718 - loss: 0.0815 - val_accuracy: 0.9800 - val_loss: 0.0749\n",
            "Epoch 978/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9689 - loss: 0.0841 - val_accuracy: 0.9900 - val_loss: 0.0735\n",
            "Epoch 979/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9680 - loss: 0.0885 - val_accuracy: 0.9900 - val_loss: 0.0726\n",
            "Epoch 980/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9668 - loss: 0.0904 - val_accuracy: 0.9900 - val_loss: 0.0720\n",
            "Epoch 981/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9706 - loss: 0.0794 - val_accuracy: 0.9900 - val_loss: 0.0714\n",
            "Epoch 982/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9695 - loss: 0.0882 - val_accuracy: 0.9900 - val_loss: 0.0715\n",
            "Epoch 983/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9685 - loss: 0.0825 - val_accuracy: 0.9900 - val_loss: 0.0723\n",
            "Epoch 984/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9646 - loss: 0.0871 - val_accuracy: 0.9900 - val_loss: 0.0723\n",
            "Epoch 985/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9699 - loss: 0.0881 - val_accuracy: 0.9900 - val_loss: 0.0728\n",
            "Epoch 986/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9725 - loss: 0.0776 - val_accuracy: 0.9900 - val_loss: 0.0729\n",
            "Epoch 987/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9679 - loss: 0.0893 - val_accuracy: 0.9900 - val_loss: 0.0721\n",
            "Epoch 988/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9682 - loss: 0.0867 - val_accuracy: 0.9900 - val_loss: 0.0717\n",
            "Epoch 989/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9647 - loss: 0.0931 - val_accuracy: 0.9900 - val_loss: 0.0718\n",
            "Epoch 990/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9665 - loss: 0.0899 - val_accuracy: 0.9900 - val_loss: 0.0710\n",
            "Epoch 991/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9643 - loss: 0.0921 - val_accuracy: 0.9900 - val_loss: 0.0729\n",
            "Epoch 992/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9704 - loss: 0.0780 - val_accuracy: 0.9900 - val_loss: 0.0722\n",
            "Epoch 993/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9621 - loss: 0.0920 - val_accuracy: 0.9900 - val_loss: 0.0731\n",
            "Epoch 994/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9693 - loss: 0.0835 - val_accuracy: 0.9900 - val_loss: 0.0710\n",
            "Epoch 995/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9656 - loss: 0.0854 - val_accuracy: 0.9900 - val_loss: 0.0711\n",
            "Epoch 996/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9678 - loss: 0.0785 - val_accuracy: 0.9900 - val_loss: 0.0721\n",
            "Epoch 997/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9695 - loss: 0.0843 - val_accuracy: 0.9900 - val_loss: 0.0703\n",
            "Epoch 998/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9699 - loss: 0.0838 - val_accuracy: 0.9900 - val_loss: 0.0711\n",
            "Epoch 999/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9688 - loss: 0.0805 - val_accuracy: 0.9900 - val_loss: 0.0712\n",
            "Epoch 1000/1000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9643 - loss: 0.0893 - val_accuracy: 0.9900 - val_loss: 0.0713\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ef857a1b250>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb1HCDM_X1Y3",
        "outputId": "64da88d2-1155-4c77-8166-58c30160454f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.0672 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07133176177740097, 0.9900000095367432]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2MfMmfC3Y_l0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}