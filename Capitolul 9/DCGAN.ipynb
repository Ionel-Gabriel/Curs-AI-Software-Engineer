{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "## Initializare hyperparametri model la nivel de args, suporta cmdline-execution\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=2, help=\"number of epochs of training\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=1024, help=\"size of the batches\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
        "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
        "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\n",
        "opt = parser.parse_args(args=[])\n",
        "print(opt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idVNHwXAioWP",
        "outputId": "ea3f2bcb-e698-4935-911a-84d19b2c2f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(n_epochs=2, batch_size=1024, lr=0.0002, b1=0.5, b2=0.999, n_cpu=8, latent_dim=100, img_size=32, channels=1, sample_interval=400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiTTRR-TeNvm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "metadata": {
        "id": "ggRIil5-qfh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# m - stratul retelei\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__ # Obtin numele stratului\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02) # Initializare dupa distributie normala gausiana de medie 0 si std 0.02\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02) # Initializare dupa distributie normala gausiana de medie 0 si std 0.02\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0) # Bias initial 0\n",
        "\n",
        "# BatchNorm2D normalizează fiecare canal pe baza mediei și deviației standard a valorilor sale în batch-ul curent"
      ],
      "metadata": {
        "id": "batOMvlWIiSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = opt.img_size // 4 # Declaram dimensiunea inaginii initiale\n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2)) # input -> vectorul de zgomot, out -> features(128) * dim imaginii\n",
        "\n",
        "\n",
        "        ## Reconstructia imaginii\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.Upsample(scale_factor=2), # \\\\4 -> \\\\2\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1), # Conv pe uppersampling\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2), # \\\\2 -> \\\\1\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1), # Conv pe uppersampling\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1), # Convertim la imaginea de input (color sau gray). Nu mai fac conv transpose pentru ca sunt deja la dimensiunea imaginii\n",
        "            nn.Tanh(), # Normalizarea iesirii\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z) # Transforma zgomotul intr-o reprezentare intermediara\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size) # Reshape pentru input la blocurile convolutionale\n",
        "        img = self.conv_blocks(out) # obtine imaginea rezultat (batch_size, channels, img_size, img_size)\n",
        "        return img"
      ],
      "metadata": {
        "id": "imdvOucuMCTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
        "                     nn.LeakyReLU(0.2, inplace=True),\n",
        "                     nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        ds_size = opt.img_size // 2 ** 4 # Dimensiunea imaginii dupa 4 pasi de downsampling\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1),\n",
        "                                       nn.Sigmoid()) # Obtine predictia finala\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "\n",
        "        return validity\n",
        "\n",
        "## 3x3 e pentru mai multe detalii fine, imaginea este 32x32 este ok si cu acesta\n",
        "## 4x4 pentru mai multe caracteristici, folositi pentru imagini de dimensiune mai mare"
      ],
      "metadata": {
        "id": "6FoHqidjfNf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)\n"
      ],
      "metadata": {
        "id": "aOj7Y7qhq4Q3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d107b7c9-06f6-4b7a-ebf2-c40fd94b92fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout2d(p=0.25, inplace=False)\n",
              "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Dropout2d(p=0.25, inplace=False)\n",
              "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (9): Dropout2d(p=0.25, inplace=False)\n",
              "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (13): Dropout2d(p=0.25, inplace=False)\n",
              "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (adv_layer): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure data loader\n",
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"../../data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "MV90O3k5q9Pe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c1a14606-befa-4351-cfc7-705dcc6fe8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 562kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 5.16MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.92MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "metadata": {
        "id": "9HOcLzv2rOcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "for epoch in range(opt.n_epochs): # Itereaza prin fiecare epoca\n",
        "    for i, (imgs, _) in enumerate(dataloader): # Scot imaginile din fiecare batch\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False) # Tensor eticheta pentru valori reale\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False) # Tensor eticheta pentru valori false\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor)) # Conversie la tensori\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad() # Reseteaza gradientul pentru generator\n",
        "\n",
        "\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim)))) # Se creeaza vectorul de zgomot\n",
        "\n",
        "        # Generam un batch de imagini\n",
        "        gen_imgs = generator(z) # Se trece zgomotul prin generator pentru a genera imagini false\n",
        "\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step() # Propagare backwards and update\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad() # Reseteaza gradientul pentru discriminator\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid) # Se trec imaginile prin discriminator si se calculeaza pierderile pe imaginile reale\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) # Se iau imaginile false gen_imgs se trec prin discriminator si se calculeaza pierderile\n",
        "\n",
        "        d_loss = (real_loss + fake_loss) / 2 # Calcul pierdere discriminator\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step() # Actualizare si backward prop\n",
        "\n",
        "        # Print detalii antrenare\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "        )\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i"
      ],
      "metadata": {
        "id": "S3TUYxfKeXuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osHot9qafrLH",
        "outputId": "24be21f1-8be7-4d76-bf85-fab39df1cbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (l1): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=8192, bias=True)\n",
              "  )\n",
              "  (conv_blocks): Sequential(\n",
              "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (1): Upsample(scale_factor=2.0, mode='nearest')\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Upsample(scale_factor=2.0, mode='nearest')\n",
              "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator.to(device)\n",
        "\n",
        "latent_dim = 100\n",
        "z = torch.randn(1, latent_dim).to(device)\n",
        "with torch.no_grad():\n",
        "    fake_img = generator(z)\n",
        "\n",
        "fake_img = (fake_img + 1) / 2\n",
        "\n",
        "\n",
        "# Display\n",
        "img = fake_img.squeeze().cpu().numpy()  # Convert to NumPy and move to CPU\n",
        "plt.imshow(img, cmap=\"gray\")  # Show grayscale image\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "aYOe03pD8pMf",
        "outputId": "41b4759a-668c-4b0b-9f71-18b25ece1b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFoJJREFUeJzt3FlvFea5BeDPgGcweMAYbAiEkIlmqFpFSqVU6s/rn+gvyVUvorRRozQJ0AbiMHkAG2yw8YCxfe7e2/OtC3TOxfNcL73a7MGLfbHXwPHx8XEDgNbaif/rBwDA/x9KAYCiFAAoSgGAohQAKEoBgKIUAChKAYByqjf417/+NTq8ubnZnd3Y2Ihu7+/vv5Vsa62dP3++Ozs2Nhbd3t3d7c4ODAxEtycnJ6P8s2fPurPJc9Jaa2fOnOnOrq2tRbenp6e7s+lrf+/evSif3J+ZmYlu7+zsdGeT56S11ra3t7uz6XM4Ojoa5RODg4NRfmJiojs7Pj4e3X758mV39tWrV9Ht4eHh7uzy8nJ0+29/+9v/mvFNAYCiFAAoSgGAohQAKEoBgKIUAChKAYCiFAAoSgGAohQAKEoBgNK9fZTudyR7RskWS2utHRwcdGevXLkS3b506VJ39sWLF9Ht5N954kTW18nWVGutLS4uRvlE8l5J96O+/PLL7myyT9NavtuzsrLSnT08PIxuJ8/L48ePo9tv3rzpzh4dHUW3k32vdA9qaWkpyj948KA7e+pU95/C1lpr586d684mf69aa+3999/vziYbWb18UwCgKAUAilIAoCgFAIpSAKAoBQCKUgCgKAUAilIAoCgFAEr3b7vHx8ejw0NDQ93Zqamp6Hbys/F0uuDixYvd2fSn8aurq93ZdObio48+ivLJz/RHRkai2/fv3+/ODgwMRLe/++677uz09HR0+8aNG1E+ma54/vx5dHtra6s7m7yvWss+y+l8SjKhkc4/zM/PR/lkouPMmTPR7WTO49GjR9HtZD7l5MmT0e0evikAUJQCAEUpAFCUAgBFKQBQlAIARSkAUJQCAEUpAFCUAgBFKQBQusd7vv/+++jw8PBwd/aLL76Ibr/N7aM//OEP3dnFxcXo9t7eXnd2fX09up16/fp1dzbdhUnyyfuktdZ2dna6s3Nzc9HtCxcuRPlko+bp06fR7eS9cnx8HN1eXl7uzqabZ8mO2fXr16Pb165di/KPHz/uzp49eza6neyBpZ+f5HbyWvbyTQGAohQAKEoBgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUACjdMxeDg4PR4WS+4MGDB9HtiYmJ7uzR0VF0e39/P8onPv300+7s2tpadHt+fj7KJ6/PnTt3otsDAwPd2XQq5OTJk93ZoaGh6PbGxkaU39zc7M6OjY1FtxcWFqJ84v79+93Z5LVsLZtP+emnn6Lb6WzJvXv3urM3btyIbifTIsnz3VprH374YXd2eno6ut3DNwUAilIAoCgFAIpSAKAoBQCKUgCgKAUAilIAoCgFAIpSAKAoBQBK9/bRlStXosOHh4fd2XPnzkW3x8fHu7PPnj2Lbu/u7nZn0z2b7e3t7my62ZRsArXW2tTUVHd2ZGQkur2zs9OdTZ7v1rJ/Z7qtk7xnW8s2uJKdpNayrbHTp09Htz/55JPu7KlT3X8iYunnPn2vvPvuu28l21q2kZb8vUrzyQZTL98UAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYCiFAAoSgGA0v0b9nQC4OrVq93Z4eHh6PbW1lZ3NpkiaK21tbW17mz6nNy6das7m84LfPvtt1F+ZmamO5tMLrTW2vT0dHd2dHQ0up3Mrdy5cye6/eOPP0b5gYGB7uzS0lJ0+8KFC93Z2dnZ6HYyo5BONJw40f//zHTm4sGDB1F+aGioO7u6uhrdTqZf0smaZJrnbcyQ+KYAQFEKABSlAEBRCgAUpQBAUQoAFKUAQFEKABSlAEBRCgAUpQBA6R7OSLaMWmvt9OnT3dnJycnodrLF880330S3t7e3u7OLi4vR7WRX6fLly9HtZFeptda++OKL7mz6+iwsLHRnDw4OotvJ1suZM2ei22k+2flJ96OSTah0nyh5b62vr0e3j4+Pu7PJflBrre3t7UX5ZD8qvf306dPu7OPHj6PbyVZSur/WwzcFAIpSAKAoBQCKUgCgKAUAilIAoCgFAIpSAKAoBQCKUgCgdG8GpD+l/+STT7qzV65ciW6/efOmO/vo0aPo9o8//tid/de//hXdTqY/tra2otv/+c9/onwy6TA3NxfdTiYdxsbGotvJtMTu7m50e3Z2Nsonz+HJkyej2x988EF3dmJiIrr93nvvdWf//e9/R7eT1z59X3399ddRPpkKSacolpaWurPJbEVr2XOYzg/18E0BgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYCiFAAoSgGA0r19NDAwEB2emprqzo6MjES3k72cjz76KLqdbKCkuz3J9tGlS5ei2zs7O2/tsezv70e3nz592p2dn5+Pbp87d647e/Hixeh2uiOT7FMlezatZe+tlZWV6PbCwkJ39vj4OLqdbKQlfyNaa+3atWtR/vPPP+/OJu/Z1lq7detWd/bg4CC6nfw9fPnyZXS7h28KABSlAEBRCgAUpQBAUQoAFKUAQFEKABSlAEBRCgAUpQBAUQoAlO7to3RH5vDwsDv7888/R7fPnj3bnX39+nV0O9luuXnzZnR7eHi4Ozs5ORnd/uMf/xjlnz171p1dXl6Obm9vb3dn002t5LVPJa9Pa62tra11Z4+OjqLbT5486c6urq5Gt3/55ZfubLrvNTEx0Z1NPmuttXbjxo0on7wPL1y4EN1O/r6l79lTp7r/LLe9vb3odg/fFAAoSgGAohQAKEoBgKIUAChKAYCiFAAoSgGAohQAKEoBgNL9e+rNzc3o8Pr6enf24cOH0e3p6enu7NucuUh/dn/69Onu7MzMTHQ7/Sn9iRP9/x949epVdHtpaak7m06cJK9nMnPQWvactNbab7/91p1Npgtaa21oaKg7u7GxEd1++vRpd/bTTz+Nbn/wwQfd2d3d3eh2Ms3SWmsHBwfd2ZWVleh28vokn/vWsr+1V69ejW738E0BgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYCiFAAoSgGA0j3Isry8HB1Oto/29/ej28lGzYULF6Lbyb9zdXU1un358uXu7Pnz56Pb6fZRsk80ODgY3f7pp5+6s/Pz89HtZEdma2srup1uCM3OznZn37x5E90+Pj6O8om7d+92Z0dGRqLbyeNON4HSDa5kU+3w8DC6new2vXjxIro9OTnZnU03tXr4pgBAUQoAFKUAQFEKABSlAEBRCgAUpQBAUQoAFKUAQFEKAJTu30jfu3cvOnzp0qXu7MrKSnT75MmT3dmZmZnodjLpkE4XJP/O9Gf333//fZR/9OhRd3Z4eDi6fe7cue5sMhXRWjb/8fjx4+h2OnORTLmcOXMmuv3ee++9lWxrrW1ubnZn9/b2otvfffdddzZ97ZNpidZa++WXX7qzybREa629//773dl0gmZqaqo7OzAwEN3u4ZsCAEUpAFCUAgBFKQBQlAIARSkAUJQCAEUpAFCUAgBFKQBQlAIApXv76Pnz52/tQSwvL0f5ZP/m9u3b0e2hoaHubLrdkmzr/OUvf4luX7x4McqPjo6+lWxrrc3NzXVnp6eno9svX77szqabTcleV2vZPtVXX30V3U7eK/Pz89Hthw8fdmfX1tai28mu0vHxcXQ73QNL9qbSHbNkhynZU2uttQ8++KA7u7+/H93u4ZsCAEUpAFCUAgBFKQBQlAIARSkAUJQCAEUpAFCUAgBFKQBQumcukvmH1rKfjadzEcnP3ZOfo7fW2vj4eHd2ZWUlun327Nnu7NHRUXQ7fX2SCYD19fXo9rlz57qzH3/8cXQ7mX9IXsvW8qmDZGLgww8/jG6fOtX90Yzf4//4xz+6s+mMwqNHj7qz29vb0e3kOWktm89JX59kzuPy5cvR7cnJye5sMvvSyzcFAIpSAKAoBQCKUgCgKAUAilIAoCgFAIpSAKAoBQCKUgCgKAUASveYSLpPNDMz05198eJFdDt5LOluT3I73YX5/PPPu7MTExPR7cHBwSj/5z//uTu7uLgY3X79+nV3NtlJaq21f/7zn93ZdBdmamoqyv/www/d2fT1TDx8+DDK7+3tdWfTz8/BwcFbeRyt5Xtgyd+gsbGx6PZ7773XnZ2bm4tuDw8Pd2eTHbhevikAUJQCAEUpAFCUAgBFKQBQlAIARSkAUJQCAEUpAFCUAgBFKQBQureP5ufno8M3btzozqb7KslGTbLD01q2UXPp0qXo9rVr17qzp051vzSttXxD6MqVK93ZZIultdbu3r3bnU13r3Z2drqzr169im5vbGy8tfyDBw+i29PT093ZdEPo9OnT3dmRkZHodrLzk24Zpf/O5DORbDa11tru7m539smTJ9HtoaGh7qztIwDeKqUAQFEKABSlAEBRCgAUpQBAUQoAFKUAQFEKABSlAEDp3lIYHR2NDr///vvd2WRaorXWFhcXu7PpT+P/+9//dmevX78e3U5+kr62thbdTg0MDHRn07mIZAJgZmYmuj02NtadPXv2bHT75s2bUf7Zs2fd2fTzs7q62p29detWdDuZfknnVk6c6P9/ZpJtLZ+LSD5v6WRNMouRzsQkMySDg4PR7R6+KQBQlAIARSkAUJQCAEUpAFCUAgBFKQBQlAIARSkAUJQCAEUpAFC6h02STaDWsv2OdFsnMTQ0FOUXFha6s8m+U2vZxlO6fXR0dBTlNzY2urPp6zM+Pt6dTXevXr582Z1N3oOttTY7Oxvlf/vtt+5s8ny31tr6+np3Nt2PSp7zdJ9oZ2enO3v//v3o9tzcXJQ/Pj7uzqYbQlNTU93ZN2/eRLeTvan071sP3xQAKEoBgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYDS/Xvq5Gf3rbX27bffdmeHh4ej28nP+tOfgSczCul0wS+//NKdPTg4iG4/ffo0yq+srHRn0ymKCxcudGfTCYBkhmR3dze6/fXXX0f5ZALi/Pnz0e3k9R8YGIhub29vd2d/97vfRbeT98rIyEh0e3JyMson7/FLly5Ft1+/ft2dvXv3bnQ7+ZuV/u3s4ZsCAEUpAFCUAgBFKQBQlAIARSkAUJQCAEUpAFCUAgBFKQBQlAIApXv76Pnz59Hhw8PD7my6T5TsjszOzka39/b2urM//vhjdDt5DldXV6PbyfPdWmtPnjzpzp48eTK6/dlnn3Vnj4+Po9vJ65m+9un+TbLbND8/H93e3NzsziYbTK1lz/nPP/8c3b5y5Up39v79+9Ht5LPZWmu3b9/uziZ7UK21dvny5e7s/v5+dDt5366trUW3e/imAEBRCgAUpQBAUQoAFKUAQFEKABSlAEBRCgAUpQBAUQoAlO6Zi3SO4PHjx93Zq1evRreTn42nP42/ePFid/bevXvR7XRGIbGyshLlFxYWurPJa9laNtGQGh8f786eOXMmup3+OycmJrqzu7u70e2xsbHu7PDwcHR7a2urOzs6OhrdvnnzZnd2eXk5uj03Nxfll5aWurN///vfo9u///3vu7PJ891aa69everOvnz5MrrdwzcFAIpSAKAoBQCKUgCgKAUAilIAoCgFAIpSAKAoBQCKUgCgKAUASvf20eTkZHQ42dY5dar7YbTWsm2d2dnZ6Pbg4GB3Nt2DSvZsksfRWr6vkuxNHR0dRbcvXLjQnU0f98OHD6N8It3Jevr0aXc2eU5aa+3Jkyfd2UePHkW3k+2wK1euRLfT1zOR7F611tr09HR3dmBgILqdvFfS2+vr693Z1dXV6HYP3xQAKEoBgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYDSvS8xOjoaHZ6YmOjOvvPOO9HtZ8+evbXbyU/Sv/nmm+j2mzdvurN3796NbifTBa1l8wXpa3/y5Mkon9jd3e3OJu+T1lqbmZmJ8rdv3+7O/vrrr9Ht58+fd2dfvHgR3T5//nx3dmhoKLr9th5Ha/l7PJmKSf5epbfTz08yoZFOBPXwTQGAohQAKEoBgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYDSPZyR7Pa01trm5mZ39sGDB9Ht1dXV7uzFixej2zdu3OjOrq2tRbeTPaM//elP0e2lpaUo/+mnn3Znk9eytdaePHnSnU13km7dutWdffToUXT7iy++iPLJps3GxkZ0e3x8vDt7dHQU3b5582Z39rPPPotuJ6/n9evXo9sHBwdv7bEke0OtZZtQ6e3k85ZsMPXyTQGAohQAKEoBgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYDSvX307rvvRoeT3ZE7d+5Et5eXl7uzW1tb0e2JiYnu7MjISHT78PCwO/v8+fPo9tmzZ6P8+fPnu7Pz8/PR7WQna3JyMrqdbAKtrKxEt9ONml9//bU7u729Hd1ONrvS1/706dPd2YGBgej28fFxdzZ93I8fP47yyeuZvsf39/e7s++88050+/bt293Z9fX16HYP3xQAKEoBgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYDSPXORzkWcOtV9Op4XSGYUrly5Et0+caK/J4+OjqLbly9f7s4mMyGttbawsPDWHsvY2Fh0+8GDB93Zubm56HYyu5BMLrTW2vT0dJTf2Njozr569eqtPZZkPqW11nZ2drqz6VRIMunw5MmT6Pb9+/ej/PDwcHf24cOH0e0XL150Zz/++OPo9ocfftidTac/evimAEBRCgAUpQBAUQoAFKUAQFEKABSlAEBRCgAUpQBAUQoAFKUAQOkeKJqdnY0OJ5sp6X7H4uJid/bly5fR7UuXLnVn092eZP9mZmYmup3u39y6das7Ozg4GN1eW1vrzo6Pj0e3Jycnu7Pp9lGyqZU+lqtXr0a3k12t9N+ZvJ7pc3Lx4sXubPL8tZZ/3pK/K+l7PNltSp/D5DORbMz18k0BgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYCiFAAo3b+RHh0djQ5fv369/0GEP9VOJh1Onz4d3T5//nx39rPPPotuv/POO93Zu3fvRrc3Nzej/J07d7qzQ0ND0e2JiYnu7LVr16LbX375ZXc2nf5YXl6O8snzsrS0FN3e3d3tzu7t7UW3k8/E69evo9u3b9/uzqbTOelnOZnFWFhYiG7/8MMP3dlksqS1bBYjeZ/08k0BgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYCiFAAoSgGA0j06lG5szMzMdGeTvaHWWvvqq6+6s8kOT2utTU9Pd2fTvaFkL2V9fT26fe7cuSh/5syZ7uzw8HB0++zZs93ZjY2N6PbW1lZ39uDgILp9//79KL+/v9+dTV/P5POWblOlG0+JZIfp8uXL0e10++jhw4fd2fTz8/z58+5suk2V7IGNj49Ht3v4pgBAUQoAFKUAQFEKABSlAEBRCgAUpQBAUQoAFKUAQFEKAJS3NnORzBGkP19Pfh6fTlEkkwHpz9d3dna6swMDA9HtdLogmRYZGxuLbifP4eDgYHR7ZWWlO/vixYvo9r1796L80tLSW3ssp051fzTb4eFhdDuZLUlnYra3t7uzR0dH0e3FxcUon34+E69fv+7OTk1NRbffvHnTnU3/TvTwTQGAohQAKEoBgKIUAChKAYCiFAAoSgGAohQAKEoBgKIUAChKAYAycHx8fPx//SAA+P/BNwUAilIAoCgFAIpSAKAoBQCKUgCgKAUAilIAoCgFAMr/APP91UfBsfOgAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    prediction = discriminator(fake_img)\n",
        "\n",
        "# Print discriminator's output\n",
        "print(f\"Discriminator's Output: {prediction.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRVCxUqs87Do",
        "outputId": "18444551-9679-4861-bb58-fbc105046502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator's Output: 0.4907\n"
          ]
        }
      ]
    }
  ]
}