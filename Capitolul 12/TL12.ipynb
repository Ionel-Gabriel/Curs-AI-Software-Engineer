{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bi_OTS6MrTtV"
   },
   "source": [
    "# Define training grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OyjXmWtxnzBT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T_QQZHTooe-j"
   },
   "outputs": [],
   "source": [
    "TRAINING_GRID = {\n",
    "    \"base_model\": [\n",
    "        \"bert-base-multilingual-cased\",\n",
    "        \"bert-base-multilingual-uncased\",\n",
    "    ],\n",
    "    \"class_imbalance\": [1, 2, 3],\n",
    "    \"device\": ['cpu'],\n",
    "    \"epochs\": [4, 6, 8],\n",
    "    \"batch_size\": [8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pH3e_uyzo7_m"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from copy import copy\n",
    "\n",
    "def generate_hyperparameters_grid(values: dict) -> List[dict]:\n",
    "  def recursive_parameters_generation(keys: List[str], i: int=0, current_params: dict = {}):\n",
    "    grid = []\n",
    "    for value in values[keys[i]]:\n",
    "      current_params[keys[i]] = value\n",
    "      if i < len(keys) - 1:\n",
    "        grid += recursive_parameters_generation(keys=keys, i=i+1, current_params=current_params)\n",
    "      else:\n",
    "        grid.append(copy(current_params))\n",
    "    return grid\n",
    "\n",
    "  return recursive_parameters_generation(list(values.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ya2YWR-Jpz3J",
    "outputId": "29ec420e-65d9-4718-dd24-3cd68bd55f8b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_hyperparameters_grid(values= TRAINING_GRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkSDaoAsradU"
   },
   "source": [
    "# Build csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gn2xT-FbrRb-",
    "outputId": "b88013d6-58da-4f8c-f979-cfe513b5b9c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    file_name                                          paragraph\n",
      "0   art10.txt  Este interzisă circulaţia pe drumurile publice...\n",
      "1   art10.txt  Constatarea deficienţelor vehiculelor se face ...\n",
      "2   art12.txt  Vehiculele care circulă pe drumurile publice t...\n",
      "3   art12.txt  Pentru a circula pe drumurile publice, vehicul...\n",
      "4   art12.txt  Vehiculele care nu sunt supuse înmatriculării ...\n",
      "5   art12.txt  Este interzisă conducerea pe drumurile publice...\n",
      "6   art13.txt  Autovehiculele şi remorcile se înmatriculează ...\n",
      "7   art13.txt  Sunt exceptate de la prevederile alin. (1) mop...\n",
      "8   art13.txt  Autovehiculele, remorcile și tractoarele agric...\n",
      "9   art13.txt  Autovehiculele și remorcile destinate a fi tra...\n",
      "10  art13.txt  Până la înmatriculare, vehiculele prevăzute la...\n",
      "11  art13.txt  La cerere, instituțiilor din sistemul de apăra...\n",
      "12  art13.txt  Pot beneficia de autorizații și numere pentru ...\n",
      "13  art13.txt  Autorizația de circulație pentru probe este va...\n",
      "14  art13.txt  Evidența vehiculelor înmatriculate se ține la ...\n",
      "15  art14.txt  Tramvaiele, troleibuzele, mopedele, tractoarel...\n",
      "16  art14.txt  Evidența vehiculelor înregistrate se ține la a...\n",
      "17  art14.txt  Prelucrarea unor date din Registrul de evidenț...\n",
      "18   art8.txt  Pentru a fi conduse pe drumurile publice, fiec...\n",
      "19   art9.txt  Pentru a fi înmatriculate, înregistrate sau ad...\n",
      "20   art9.txt  Sunt exceptate de la prevederile alin. (1) veh...\n",
      "21   art9.txt  Omologarea este opțională în cazul vehiculelor...\n",
      "22   art9.txt  Categoriile de vehicule care pot fi admise în ...\n",
      "23   art9.txt  Documentul care atestă omologarea este cartea ...\n",
      "24   art9.txt  Pentru a fi menținute în circulație, vehiculel...\n",
      "25   art9.txt  Inspecţia tehnică periodică se efectuează în s...\n",
      "26   art9.txt  Pentru autovehiculele şi tractoarele agricole ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "folder_path = \"legislatie/\"\n",
    "\n",
    "data = []\n",
    "pattern = r\"(#\\d+(\\.\\d+)?)([\\s\\S]*?)(?=#\\d+(\\.\\d+)?|$)\"\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "  file_path = os.path.join(folder_path, file)\n",
    "\n",
    "  with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "      content = f.read()\n",
    "\n",
    "      # Use regex to find all paragraphs that start with (1), (2), etc.\n",
    "      paragraphs = re.findall(pattern, content)\n",
    "\n",
    "      # Store each paragraph with the file name\n",
    "\n",
    "      for match in paragraphs:\n",
    "        paragraph_text = match[2]\n",
    "        data.append({\"file_name\": file, \"paragraph\": paragraph_text.strip()})\n",
    "\n",
    "# Convert to DataFrame\n",
    "paragraphs = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yjWeGMR-7Pam"
   },
   "outputs": [],
   "source": [
    "\n",
    "questions = [\"Care sunt echipamentele obligatorii pe care trebuie să le aibă un autovehicul pentru a putea circula pe drumurile publice?\",\n",
    "             \"Ce condiție trebuie să îndeplinească autovehiculele, remorcile și tramvaiele pentru a fi înmatriculate, înregistrate sau admise în circulație?\",\\\n",
    "             \"Care sunt categoriile de vehicule exceptate de la obligația de omologare?\",\n",
    "             \"Care sunt categoriile de vehicule exceptate de la obligația de omologare?\",\n",
    "             \"Cine stabilește categoriile de vehicule care pot fi admise în circulație fără omologare?\",\n",
    "             \"Ce document atestă omologarea unui vehicul?\",\n",
    "             \"Unde se efectuează inspecția tehnică periodică a vehiculelor?\",\n",
    "             \"Unde se efectuează inspecția tehnică periodică a vehiculelor?\",\n",
    "             \"Ce categorii de vehicule au interdicția de a circula pe drumurile publice?\",\n",
    "             \"Cine are responsabilitatea de a constata deficiențele vehiculelor și de a verifica starea tehnică a acestora în trafic?\",\n",
    "             \"Care sunt categoriile de vehicule exceptate de la obligația de înmatriculare sau înregistrare pentru a circula pe drumurile publice?\",\n",
    "             \"Ce obligație au vehiculele înmatriculate sau înregistrate pentru a putea circula pe drumurile publice?\",\n",
    "             \"În ce condiții pot circula pe drumurile publice vehiculele care nu sunt supuse înmatriculării sau înregistrării?\",\n",
    "             \"Unde se înmatriculează autovehiculele și remorcile și în ce condiții?\",\n",
    "             \"Ce categorii de vehicule sunt exceptate de la obligația de înmatriculare?\",\n",
    "             \"La ce instituții se înregistrează autovehiculele, remorcile și tractoarele agricole sau forestiere din dotarea unor instituții de stat?\",\n",
    "             \"În ce condiții pot circula vehiculele înainte de a fi înmatriculate?\",\n",
    "             \"Cine poate beneficia de autorizații și numere pentru probe pentru vehiculele care se supun înmatriculării?\",\n",
    "             \"Cine ține evidența vehiculelor înmatriculate și pe ce criteriu teritorial?\",\n",
    "             \"La ce autorități se înregistrează tramvaiele, troleibuzele, mopedele, tractoarele agricole sau forestiere și alte vehicule menționate?\",\n",
    "             \"La ce autorități se înregistrează tramvaiele, troleibuzele, mopedele, tractoarele agricole sau forestiere și alte vehicule menționate?\",\n",
    "             \"În ce condiții pot autoritățile din domeniul apărării, ordinii publice și securității naționale să prelucreze date din Registrul de evidență a vehiculelor înregistrate?\"]\n",
    "\n",
    "\n",
    "pgs = [paragraphs.iloc[0].paragraph,\n",
    "       paragraphs.iloc[16].paragraph,\n",
    "       paragraphs.iloc[17].paragraph,\n",
    "       paragraphs.iloc[18].paragraph,\n",
    "       paragraphs.iloc[19].paragraph,\n",
    "       paragraphs.iloc[20].paragraph,\n",
    "       paragraphs.iloc[22].paragraph,\n",
    "       paragraphs.iloc[23].paragraph,\n",
    "       paragraphs.iloc[14].paragraph,\n",
    "       paragraphs.iloc[15].paragraph,\n",
    "       paragraphs.iloc[10].paragraph,\n",
    "       paragraphs.iloc[11].paragraph,\n",
    "       paragraphs.iloc[12].paragraph,\n",
    "       paragraphs.iloc[1].paragraph,\n",
    "       paragraphs.iloc[2].paragraph,\n",
    "       paragraphs.iloc[3].paragraph,\n",
    "       paragraphs.iloc[5].paragraph,\n",
    "       paragraphs.iloc[7].paragraph,\n",
    "       paragraphs.iloc[9].paragraph,\n",
    "       paragraphs.iloc[24].paragraph,\n",
    "       paragraphs.iloc[25].paragraph,\n",
    "       paragraphs.iloc[26].paragraph]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kHrytsaANwaR"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()\n",
    "dataset['paragraphs'] = pgs\n",
    "dataset['questions'] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JTjwuz_8WvK9"
   },
   "outputs": [],
   "source": [
    "dataset.to_csv(\"dataset.csv\", sep='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "43I88oiXqoYn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Union, Optional\n",
    "import ast\n",
    "from sentence_transformers import util, InputExample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ReRankingDataLoader:\n",
    "  def __init__(\n",
    "        self,\n",
    "        dict_ds: pd.DataFrame,\n",
    "        raw_ds: pd.DataFrame,\n",
    "        class_imbalance: int = 1\n",
    "    ):\n",
    "        self.dict_ds = dict_ds\n",
    "        self.raw_ds = raw_ds\n",
    "        self.class_imbalance = class_imbalance\n",
    "\n",
    "  def load_data(self) -> Union[pd.DataFrame, Tuple[List[InputExample], List[InputExample]]]:\n",
    "    dataset  = []\n",
    "    for i in tqdm(range(len(self.raw_ds))):\n",
    "        question_row = self.raw_ds.iloc[i]\n",
    "        descs = question_row.paragraphs\n",
    "        if not descs:\n",
    "            continue\n",
    "        sample = pd.DataFrame()\n",
    "        sample['description'] = [descs]\n",
    "\n",
    "        sample['question'] = question_row['questions']\n",
    "        sample['Score'] = 1\n",
    "\n",
    "\n",
    "        negative_questions = self.dict_ds.loc[~self.dict_ds.paragraph.isin(list(sample.description))]\n",
    "        if self.class_imbalance:\n",
    "            negative_questions = negative_questions.sample(self.class_imbalance * len(sample))\n",
    "\n",
    "        negative_questions = negative_questions[['paragraph']]\n",
    "        negative_questions=negative_questions.rename(columns={'paragraph':'description'  })\n",
    "        negative_questions['question'] = question_row['questions']\n",
    "        negative_questions['Score'] = 0\n",
    "        sample = pd.concat([sample, negative_questions], ignore_index=True)\n",
    "        dataset.append(sample)\n",
    "    dataset = pd.concat(dataset).reset_index(drop=True)\n",
    "    print(dataset.columns)\n",
    "\n",
    "    train, test = train_test_split(dataset, test_size=0.15, random_state=42)\n",
    "    train_samples = []\n",
    "    for i in tqdm(range(len(train))):\n",
    "        current_sample = train.iloc[i]\n",
    "\n",
    "        train_samples.append(\n",
    "            InputExample(\n",
    "                texts=[current_sample[\"description\"], current_sample[\"question\"]],\n",
    "                label=current_sample[\"Score\"],\n",
    "            )\n",
    "        )\n",
    "    dev_samples = []\n",
    "    for i in tqdm(range(len(test))):\n",
    "        current_sample = test.iloc[i]\n",
    "\n",
    "        dev_samples.append(\n",
    "            InputExample(\n",
    "                texts=[current_sample[\"description\"], current_sample[\"question\"]],\n",
    "                label=current_sample[\"Score\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    return (train_samples, dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mR5ocxdOaz_o",
    "outputId": "914f6dc0-a654-4477-b1a2-112008f6a8f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 500.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['description', 'question', 'Score'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 26793.72it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 18157.16it/s]\n"
     ]
    }
   ],
   "source": [
    "loader = ReRankingDataLoader(\n",
    "    dict_ds=paragraphs,\n",
    "    raw_ds=dataset,\n",
    "    class_imbalance=1)\n",
    "\n",
    "# train_samples, dev_samples = loader.load_data()\n",
    "train_samples, dev_samples = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHoS33xWbRFb",
    "outputId": "7bed83ca-cd32-4c98-ac0b-8f9f0bb5f54d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(train_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaGjaIjVsMt0"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "C9KflM2XfdYC"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ReRankerConfig:\n",
    "    base_model: str\n",
    "    train_data: Union[List[InputExample], DataLoader]\n",
    "    dev_data: List[InputExample]\n",
    "    device: str\n",
    "    epochs: int\n",
    "    batch_size: int\n",
    "    class_imbalance: int\n",
    "    warmup_steps: Optional[int] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if not isinstance(self.train_data, DataLoader):\n",
    "            self.train_data = DataLoader(\n",
    "                self.train_data, shuffle=True, batch_size=self.batch_size\n",
    "            )\n",
    "        if not self.warmup_steps:\n",
    "            self.warmup_steps = math.ceil(len(self.train_data) * self.epochs * 0.1)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"base_model\": self.base_model,\n",
    "            \"train_size\": len(self.train_data) * self.batch_size,\n",
    "            \"dev_size\": len(self.dev_data),\n",
    "            \"device\": self.device,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"class_imbalance\": self.class_imbalance\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t4MOXfQWpysL"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CEBinaryClassificationEvaluator\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "class ReRanker:\n",
    "    def __init__(self, config: ReRankerConfig) -> None:\n",
    "        self.__config = config\n",
    "        self.device = config.device\n",
    "        self.epochs = config.epochs\n",
    "        self.warmup_steps = config.warmup_steps\n",
    "        self.class_imbalance = config.class_imbalance\n",
    "        self.trained = False\n",
    "        self.model = CrossEncoder(config.base_model, num_labels=1, device=self.device)\n",
    "        self.evaluator = CEBinaryClassificationEvaluator.from_input_examples(config.dev_data, name=f\"{config.base_model} re-ranker tables\")\n",
    "        self.prediction_threshold = 0.5\n",
    "\n",
    "    def __call__(self, x: List[List[str]]) -> np.array:\n",
    "        \"\"\"\n",
    "        The predict function\n",
    "        @param x: The sample for the model to do predictions on. It should be a list of lists containing the pair `[candidate, query]`\n",
    "        @retruns np.array: Returns an array with the probability for each pair to be a match\n",
    "        \"\"\"\n",
    "        if self.trained:\n",
    "            return self.model.predict(x).tolist()\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Model is not trained! Train before making predictions!\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        return self.config.to_dict()\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        train_dataset: List[InputExample] = None,\n",
    "        test_dataset: List[InputExample] = None,\n",
    "        output_path: str = None,\n",
    "        ) -> Union[None, dict]:\n",
    "        \"\"\"\n",
    "        The main training function\n",
    "        @param train_dataset: The list of InputExamples used to train the model\n",
    "        @param test_dataset: The list of InputExamples used to evaluate the model. If `None` is provided then no evaluation will occur.\n",
    "        @param output_path: The path where the model weights should be saved locally. If `None` is provided then the model weigths will not be saved.\n",
    "        @returns Union[None, dict]: Returns either `None` or the results from evaluation\n",
    "        \"\"\"\n",
    "\n",
    "        if train_dataset:\n",
    "            train = train_dataset\n",
    "        else:\n",
    "            train = self.__config.train_data\n",
    "\n",
    "        if test_dataset:\n",
    "            test = test_dataset\n",
    "        else:\n",
    "            test = self.__config.dev_data\n",
    "\n",
    "        self.model.fit(\n",
    "            train_dataloader=train,\n",
    "            evaluator=self.evaluator,\n",
    "            evaluation_steps=math.ceil(len(train) * 0.5),\n",
    "            warmup_steps=self.warmup_steps,\n",
    "            output_path=output_path,\n",
    "        )\n",
    "        self.trained = True\n",
    "\n",
    "        if test:\n",
    "            return self.evaluate(test)\n",
    "\n",
    "    def evaluate(self, dataset: List[InputExample]):\n",
    "        evaluation_inputs = [t.texts for t in dataset]\n",
    "        evaluation_outputs = [t.label for t in dataset]\n",
    "\n",
    "        predictions = self.model.predict(evaluation_inputs) > self.prediction_threshold\n",
    "\n",
    "        return {\n",
    "            \"accuracy_score\": accuracy_score(evaluation_outputs, predictions),\n",
    "            \"f1_score\": f1_score(evaluation_outputs, predictions),\n",
    "            \"precision_score\": precision_score(evaluation_outputs, predictions),\n",
    "            \"recall_score\": recall_score(evaluation_outputs, predictions),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbosHUIxs3Ub"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341,
     "referenced_widgets": [
      "877dd2ff00e64562be171d2b4b7c2096",
      "01002f14fca648b18785344be2c4adf1",
      "c48f464d5c0645b1baa1ae7eaaab348a",
      "ec77f3c642384c678d338e52d7a41baf",
      "43019495e2f04e5eb5a152ef5d659a9f",
      "8ea47b725a6747a0876fc3a3a323ddb9",
      "a776f64e62c74154ab1a83a16fae4400",
      "0c7c537a5eda441ea552bbef5fe4ca38",
      "84b0bac344534475829e869283f4892d",
      "a094b0f1d06b478c8cdd5d934a8f33b0",
      "a98322bc76054235bb85700a11cfe8b3",
      "fcfc602c315849f39ef132ddc7e73638",
      "dfc2db2022c94cf4bafc3dbf9629bab1",
      "c8721cc6e55b47a589d91370bad29de6",
      "cfe3be006aa24736a11b82dd084925ee",
      "8a651af5a7834aa99945d17bd79f318d",
      "d5c1aa1ace4e4f9a87cdf475bab0e204",
      "849e6b6d68574c6b9eecaaf5ac4f0a7b",
      "738826f63313464e8122b752ba54a213",
      "270ae5d61edd49cb898c493f13196386",
      "ddc090942fe14dd39716b7e7197ce230",
      "e67f230e92bb47a581248cffe7daf9a8"
     ]
    },
    "id": "zEAtiwMfszOl",
    "outputId": "614db0c1-07ab-4cd1-c41f-b1913d61dd5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 530.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['description', 'question', 'Score'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 24547.49it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 9464.90it/s]\n",
      "2025/04/09 15:12:01 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading tokenizer_config.json: 100%|██████████| 49.0/49.0 [00:00<00:00, 252kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 2.49MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.96M/1.96M [00:00<00:00, 3.49MB/s]\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  20%|██        | 1/5 [00:04<00:17,  4.28s/it]\u001b[A\n",
      "Iteration:  40%|████      | 2/5 [00:06<00:09,  3.13s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 3/5 [00:08<00:05,  2.96s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 4/5 [00:11<00:02,  2.97s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 5/5 [00:13<00:00,  2.65s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 1/1 [00:13<00:00, 13.96s/it]\n",
      "2025/04/09 15:12:21 INFO mlflow.models.signature: Inferring model signature from type hints\n",
      "/usr/local/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:3139: UserWarning: Decorate your function with `@mlflow.pyfunc.utils.pyfunc` to enable auto data validation against model input type hints.\n",
      "  signature_from_type_hints = _infer_signature_from_type_hints(\n",
      "2025/04/09 15:12:21 INFO mlflow.models.signature: Failed to infer output type hint, setting output schema to AnyType. Unsupported type hint `<built-in function array>`. Type hints must be a list[...] where collection element type is one of these types: [<class 'int'>, <class 'str'>, <class 'bool'>, <class 'float'>, <class 'bytes'>, <class 'datetime.datetime'>], pydantic BaseModel subclasses, lists and dictionaries of primitive types, or typing.Any. Check https://mlflow.org/docs/latest/model/python_model.html#supported-type-hints for more details.\n",
      "2025/04/09 15:12:21 INFO mlflow.models.signature: Running the predict function to generate output based on input example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run rogue-tern-514 at: http://mlflow:5000/#/experiments/363813354049388447/runs/c88c693ef0a44916be3e14979e9a72ec\n",
      "🧪 View experiment at: http://mlflow:5000/#/experiments/363813354049388447\n",
      "\n",
      "------------------------Model Configurations ---------------------------\n",
      "Model: bert-base-multilingual-cased \n",
      "Device: cpu \n",
      "Epochs: 4 \n",
      "Batch Size: 8 \n",
      "Class Imbalance: 1\n",
      "\n",
      "Metrics:  {'accuracy_score': 0.42857142857142855, 'f1_score': 0.3333333333333333, 'precision_score': 1.0, 'recall_score': 0.2, 'run_id': 'c88c693ef0a44916be3e14979e9a72ec'}\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "mlflow.set_experiment(\"Reranker Experiment\")\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "for config in generate_hyperparameters_grid(TRAINING_GRID):\n",
    "\n",
    "    loader = ReRankingDataLoader(\n",
    "        dict_ds=paragraphs,\n",
    "        raw_ds=dataset,\n",
    "        class_imbalance=config[\"class_imbalance\"])\n",
    "\n",
    "    train_samples, dev_samples = loader.load_data()\n",
    "\n",
    "    train_config = ReRankerConfig(\n",
    "        base_model=config[\"base_model\"],\n",
    "        train_data=train_samples,\n",
    "        dev_data=dev_samples,\n",
    "        device=config[\"device\"],\n",
    "        epochs=config[\"epochs\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        class_imbalance=config[\"class_imbalance\"]\n",
    "    )\n",
    "    with mlflow.start_run() as run:\n",
    "        model=ReRanker(train_config)\n",
    "        mlflow.log_params(train_config.to_dict())\n",
    "        metrics = model.fit()\n",
    "        mlflow.pyfunc.log_model(\n",
    "            \"reranking_crossencoder\",\n",
    "            python_model=model,\n",
    "            input_example=[[\"Reference sentence\", \"Validation sentence\"]],\n",
    "        )\n",
    "        mlflow.log_metrics(metrics)\n",
    "        metrics[\"run_id\"] = run.info.run_id\n",
    "\n",
    "    print(\"\\n------------------------Model Configurations ---------------------------\")\n",
    "    print(\"Model:\", train_config.base_model,\n",
    "      \"\\nDevice:\",  train_config.device,\n",
    "      \"\\nEpochs:\", train_config.epochs,\n",
    "      \"\\nBatch Size:\", train_config.batch_size,\n",
    "      \"\\nClass Imbalance:\", train_config.class_imbalance)\n",
    "    print(\"\\nMetrics: \", metrics)\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    config_df = pd.DataFrame([config])\n",
    "    run_df = pd.concat([config_df, metrics_df], axis=1)\n",
    "    results_df = pd.concat([results_df, run_df])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bCVi0jttcYi",
    "outputId": "0394a5ad-07a8-472d-d1b6-d73b70a8b8a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4791676700115204"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([\"Care sunt dotarile necesare pentru autovehicule?\", paragraphs.iloc[0].paragraph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.31.0 in /usr/local/lib/python3.10/site-packages (4.31.0)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in /usr/local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub==0.16.4 in /usr/local/lib/python3.10/site-packages (0.16.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (3.18.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (4.67.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (2024.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (2.2.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.6.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.15.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (4.13.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.21.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (9.1.0.70)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (0.6.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.3.1.170)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.10)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \\\n",
    "  transformers==4.31.0 \\\n",
    "  sentence-transformers==2.2.2 \\\n",
    "  huggingface-hub==0.16.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==0.31.0\n",
      "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (0.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (7.0.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (2.2.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (2.6.0)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (0.6.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (2.21.5)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (11.6.1.9)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (11.2.1.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.18.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (10.3.5.147)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (4.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.31.0) (1.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.31.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.31.0) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.31.0) (3.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (3.10)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.31.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate==0.31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hdghaoTB_YFA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:09<00:00,  1.42s/it] \n"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(\"models:/ReRanker Demo@production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PyFuncModel' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloaded_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCare sunt dotarile necesare pentru autovehicule?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparagraphs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparagraph\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PyFuncModel' object is not callable"
     ]
    }
   ],
   "source": [
    "loaded_model([\"Care sunt dotarile necesare pentru autovehicule?\", paragraphs.iloc[0].paragraph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Array(string) (required)]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.metadata.get_input_schema().inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4765057861804962]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model._model_impl.predict([[\"Care sunt dotarile necesare pentru autovehicule?\", paragraphs.iloc[0].paragraph]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01002f14fca648b18785344be2c4adf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ea47b725a6747a0876fc3a3a323ddb9",
      "placeholder": "​",
      "style": "IPY_MODEL_a776f64e62c74154ab1a83a16fae4400",
      "value": "Epoch: 100%"
     }
    },
    "0c7c537a5eda441ea552bbef5fe4ca38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "270ae5d61edd49cb898c493f13196386": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43019495e2f04e5eb5a152ef5d659a9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "738826f63313464e8122b752ba54a213": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "849e6b6d68574c6b9eecaaf5ac4f0a7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84b0bac344534475829e869283f4892d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "877dd2ff00e64562be171d2b4b7c2096": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01002f14fca648b18785344be2c4adf1",
       "IPY_MODEL_c48f464d5c0645b1baa1ae7eaaab348a",
       "IPY_MODEL_ec77f3c642384c678d338e52d7a41baf"
      ],
      "layout": "IPY_MODEL_43019495e2f04e5eb5a152ef5d659a9f"
     }
    },
    "8a651af5a7834aa99945d17bd79f318d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ea47b725a6747a0876fc3a3a323ddb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a094b0f1d06b478c8cdd5d934a8f33b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a776f64e62c74154ab1a83a16fae4400": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a98322bc76054235bb85700a11cfe8b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c48f464d5c0645b1baa1ae7eaaab348a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c7c537a5eda441ea552bbef5fe4ca38",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_84b0bac344534475829e869283f4892d",
      "value": 1
     }
    },
    "c8721cc6e55b47a589d91370bad29de6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_738826f63313464e8122b752ba54a213",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_270ae5d61edd49cb898c493f13196386",
      "value": 5
     }
    },
    "cfe3be006aa24736a11b82dd084925ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddc090942fe14dd39716b7e7197ce230",
      "placeholder": "​",
      "style": "IPY_MODEL_e67f230e92bb47a581248cffe7daf9a8",
      "value": " 5/5 [01:31&lt;00:00, 17.93s/it]"
     }
    },
    "d5c1aa1ace4e4f9a87cdf475bab0e204": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddc090942fe14dd39716b7e7197ce230": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfc2db2022c94cf4bafc3dbf9629bab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5c1aa1ace4e4f9a87cdf475bab0e204",
      "placeholder": "​",
      "style": "IPY_MODEL_849e6b6d68574c6b9eecaaf5ac4f0a7b",
      "value": "Iteration: 100%"
     }
    },
    "e67f230e92bb47a581248cffe7daf9a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec77f3c642384c678d338e52d7a41baf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a094b0f1d06b478c8cdd5d934a8f33b0",
      "placeholder": "​",
      "style": "IPY_MODEL_a98322bc76054235bb85700a11cfe8b3",
      "value": " 1/1 [01:36&lt;00:00, 96.19s/it]"
     }
    },
    "fcfc602c315849f39ef132ddc7e73638": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dfc2db2022c94cf4bafc3dbf9629bab1",
       "IPY_MODEL_c8721cc6e55b47a589d91370bad29de6",
       "IPY_MODEL_cfe3be006aa24736a11b82dd084925ee"
      ],
      "layout": "IPY_MODEL_8a651af5a7834aa99945d17bd79f318d"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
