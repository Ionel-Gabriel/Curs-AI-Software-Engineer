{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bi_OTS6MrTtV"
   },
   "source": [
    "# Define training grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OyjXmWtxnzBT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T_QQZHTooe-j"
   },
   "outputs": [],
   "source": [
    "TRAINING_GRID = {\n",
    "    \"base_model\": [\n",
    "        \"bert-base-multilingual-cased\",\n",
    "        \"bert-base-multilingual-uncased\",\n",
    "    ],\n",
    "    \"class_imbalance\": [1, 2, 3],\n",
    "    \"device\": ['cpu'],\n",
    "    \"epochs\": [4, 6, 8],\n",
    "    \"batch_size\": [8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pH3e_uyzo7_m"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from copy import copy\n",
    "\n",
    "def generate_hyperparameters_grid(values: dict) -> List[dict]:\n",
    "  def recursive_parameters_generation(keys: List[str], i: int=0, current_params: dict = {}):\n",
    "    grid = []\n",
    "    for value in values[keys[i]]:\n",
    "      current_params[keys[i]] = value\n",
    "      if i < len(keys) - 1:\n",
    "        grid += recursive_parameters_generation(keys=keys, i=i+1, current_params=current_params)\n",
    "      else:\n",
    "        grid.append(copy(current_params))\n",
    "    return grid\n",
    "\n",
    "  return recursive_parameters_generation(list(values.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ya2YWR-Jpz3J",
    "outputId": "29ec420e-65d9-4718-dd24-3cd68bd55f8b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-cased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 1,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 2,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 4,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 6,\n",
       "  'batch_size': 8},\n",
       " {'base_model': 'bert-base-multilingual-uncased',\n",
       "  'class_imbalance': 3,\n",
       "  'device': 'cpu',\n",
       "  'epochs': 8,\n",
       "  'batch_size': 8}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_hyperparameters_grid(values= TRAINING_GRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkSDaoAsradU"
   },
   "source": [
    "# Build csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gn2xT-FbrRb-",
    "outputId": "b88013d6-58da-4f8c-f979-cfe513b5b9c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    file_name                                          paragraph\n",
      "0   art10.txt  Este interzisƒÉ circula≈£ia pe drumurile publice...\n",
      "1   art10.txt  Constatarea deficien≈£elor vehiculelor se face ...\n",
      "2   art12.txt  Vehiculele care circulƒÉ pe drumurile publice t...\n",
      "3   art12.txt  Pentru a circula pe drumurile publice, vehicul...\n",
      "4   art12.txt  Vehiculele care nu sunt supuse √ÆnmatriculƒÉrii ...\n",
      "5   art12.txt  Este interzisƒÉ conducerea pe drumurile publice...\n",
      "6   art13.txt  Autovehiculele ≈üi remorcile se √ÆnmatriculeazƒÉ ...\n",
      "7   art13.txt  Sunt exceptate de la prevederile alin. (1) mop...\n",
      "8   art13.txt  Autovehiculele, remorcile »ôi tractoarele agric...\n",
      "9   art13.txt  Autovehiculele »ôi remorcile destinate a fi tra...\n",
      "10  art13.txt  P√¢nƒÉ la √Ænmatriculare, vehiculele prevƒÉzute la...\n",
      "11  art13.txt  La cerere, institu»õiilor din sistemul de apƒÉra...\n",
      "12  art13.txt  Pot beneficia de autoriza»õii »ôi numere pentru ...\n",
      "13  art13.txt  Autoriza»õia de circula»õie pentru probe este va...\n",
      "14  art13.txt  Eviden»õa vehiculelor √Ænmatriculate se »õine la ...\n",
      "15  art14.txt  Tramvaiele, troleibuzele, mopedele, tractoarel...\n",
      "16  art14.txt  Eviden»õa vehiculelor √Ænregistrate se »õine la a...\n",
      "17  art14.txt  Prelucrarea unor date din Registrul de eviden»õ...\n",
      "18   art8.txt  Pentru a fi conduse pe drumurile publice, fiec...\n",
      "19   art9.txt  Pentru a fi √Ænmatriculate, √Ænregistrate sau ad...\n",
      "20   art9.txt  Sunt exceptate de la prevederile alin. (1) veh...\n",
      "21   art9.txt  Omologarea este op»õionalƒÉ √Æn cazul vehiculelor...\n",
      "22   art9.txt  Categoriile de vehicule care pot fi admise √Æn ...\n",
      "23   art9.txt  Documentul care atestƒÉ omologarea este cartea ...\n",
      "24   art9.txt  Pentru a fi men»õinute √Æn circula»õie, vehiculel...\n",
      "25   art9.txt  Inspec≈£ia tehnicƒÉ periodicƒÉ se efectueazƒÉ √Æn s...\n",
      "26   art9.txt  Pentru autovehiculele ≈üi tractoarele agricole ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "folder_path = \"legislatie/\"\n",
    "\n",
    "data = []\n",
    "pattern = r\"(#\\d+(\\.\\d+)?)([\\s\\S]*?)(?=#\\d+(\\.\\d+)?|$)\"\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "  file_path = os.path.join(folder_path, file)\n",
    "\n",
    "  with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "      content = f.read()\n",
    "\n",
    "      # Use regex to find all paragraphs that start with (1), (2), etc.\n",
    "      paragraphs = re.findall(pattern, content)\n",
    "\n",
    "      # Store each paragraph with the file name\n",
    "\n",
    "      for match in paragraphs:\n",
    "        paragraph_text = match[2]\n",
    "        data.append({\"file_name\": file, \"paragraph\": paragraph_text.strip()})\n",
    "\n",
    "# Convert to DataFrame\n",
    "paragraphs = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yjWeGMR-7Pam"
   },
   "outputs": [],
   "source": [
    "\n",
    "questions = [\"Care sunt echipamentele obligatorii pe care trebuie sƒÉ le aibƒÉ un autovehicul pentru a putea circula pe drumurile publice?\",\n",
    "             \"Ce condi»õie trebuie sƒÉ √ÆndeplineascƒÉ autovehiculele, remorcile »ôi tramvaiele pentru a fi √Ænmatriculate, √Ænregistrate sau admise √Æn circula»õie?\",\\\n",
    "             \"Care sunt categoriile de vehicule exceptate de la obliga»õia de omologare?\",\n",
    "             \"Care sunt categoriile de vehicule exceptate de la obliga»õia de omologare?\",\n",
    "             \"Cine stabile»ôte categoriile de vehicule care pot fi admise √Æn circula»õie fƒÉrƒÉ omologare?\",\n",
    "             \"Ce document atestƒÉ omologarea unui vehicul?\",\n",
    "             \"Unde se efectueazƒÉ inspec»õia tehnicƒÉ periodicƒÉ a vehiculelor?\",\n",
    "             \"Unde se efectueazƒÉ inspec»õia tehnicƒÉ periodicƒÉ a vehiculelor?\",\n",
    "             \"Ce categorii de vehicule au interdic»õia de a circula pe drumurile publice?\",\n",
    "             \"Cine are responsabilitatea de a constata deficien»õele vehiculelor »ôi de a verifica starea tehnicƒÉ a acestora √Æn trafic?\",\n",
    "             \"Care sunt categoriile de vehicule exceptate de la obliga»õia de √Ænmatriculare sau √Ænregistrare pentru a circula pe drumurile publice?\",\n",
    "             \"Ce obliga»õie au vehiculele √Ænmatriculate sau √Ænregistrate pentru a putea circula pe drumurile publice?\",\n",
    "             \"√én ce condi»õii pot circula pe drumurile publice vehiculele care nu sunt supuse √ÆnmatriculƒÉrii sau √ÆnregistrƒÉrii?\",\n",
    "             \"Unde se √ÆnmatriculeazƒÉ autovehiculele »ôi remorcile »ôi √Æn ce condi»õii?\",\n",
    "             \"Ce categorii de vehicule sunt exceptate de la obliga»õia de √Ænmatriculare?\",\n",
    "             \"La ce institu»õii se √ÆnregistreazƒÉ autovehiculele, remorcile »ôi tractoarele agricole sau forestiere din dotarea unor institu»õii de stat?\",\n",
    "             \"√én ce condi»õii pot circula vehiculele √Ænainte de a fi √Ænmatriculate?\",\n",
    "             \"Cine poate beneficia de autoriza»õii »ôi numere pentru probe pentru vehiculele care se supun √ÆnmatriculƒÉrii?\",\n",
    "             \"Cine »õine eviden»õa vehiculelor √Ænmatriculate »ôi pe ce criteriu teritorial?\",\n",
    "             \"La ce autoritƒÉ»õi se √ÆnregistreazƒÉ tramvaiele, troleibuzele, mopedele, tractoarele agricole sau forestiere »ôi alte vehicule men»õionate?\",\n",
    "             \"La ce autoritƒÉ»õi se √ÆnregistreazƒÉ tramvaiele, troleibuzele, mopedele, tractoarele agricole sau forestiere »ôi alte vehicule men»õionate?\",\n",
    "             \"√én ce condi»õii pot autoritƒÉ»õile din domeniul apƒÉrƒÉrii, ordinii publice »ôi securitƒÉ»õii na»õionale sƒÉ prelucreze date din Registrul de eviden»õƒÉ a vehiculelor √Ænregistrate?\"]\n",
    "\n",
    "\n",
    "pgs = [paragraphs.iloc[0].paragraph,\n",
    "       paragraphs.iloc[16].paragraph,\n",
    "       paragraphs.iloc[17].paragraph,\n",
    "       paragraphs.iloc[18].paragraph,\n",
    "       paragraphs.iloc[19].paragraph,\n",
    "       paragraphs.iloc[20].paragraph,\n",
    "       paragraphs.iloc[22].paragraph,\n",
    "       paragraphs.iloc[23].paragraph,\n",
    "       paragraphs.iloc[14].paragraph,\n",
    "       paragraphs.iloc[15].paragraph,\n",
    "       paragraphs.iloc[10].paragraph,\n",
    "       paragraphs.iloc[11].paragraph,\n",
    "       paragraphs.iloc[12].paragraph,\n",
    "       paragraphs.iloc[1].paragraph,\n",
    "       paragraphs.iloc[2].paragraph,\n",
    "       paragraphs.iloc[3].paragraph,\n",
    "       paragraphs.iloc[5].paragraph,\n",
    "       paragraphs.iloc[7].paragraph,\n",
    "       paragraphs.iloc[9].paragraph,\n",
    "       paragraphs.iloc[24].paragraph,\n",
    "       paragraphs.iloc[25].paragraph,\n",
    "       paragraphs.iloc[26].paragraph]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kHrytsaANwaR"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()\n",
    "dataset['paragraphs'] = pgs\n",
    "dataset['questions'] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JTjwuz_8WvK9"
   },
   "outputs": [],
   "source": [
    "dataset.to_csv(\"dataset.csv\", sep='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "43I88oiXqoYn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Union, Optional\n",
    "import ast\n",
    "from sentence_transformers import util, InputExample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ReRankingDataLoader:\n",
    "  def __init__(\n",
    "        self,\n",
    "        dict_ds: pd.DataFrame,\n",
    "        raw_ds: pd.DataFrame,\n",
    "        class_imbalance: int = 1\n",
    "    ):\n",
    "        self.dict_ds = dict_ds\n",
    "        self.raw_ds = raw_ds\n",
    "        self.class_imbalance = class_imbalance\n",
    "\n",
    "  def load_data(self) -> Union[pd.DataFrame, Tuple[List[InputExample], List[InputExample]]]:\n",
    "    dataset  = []\n",
    "    for i in tqdm(range(len(self.raw_ds))):\n",
    "        question_row = self.raw_ds.iloc[i]\n",
    "        descs = question_row.paragraphs\n",
    "        if not descs:\n",
    "            continue\n",
    "        sample = pd.DataFrame()\n",
    "        sample['description'] = [descs]\n",
    "\n",
    "        sample['question'] = question_row['questions']\n",
    "        sample['Score'] = 1\n",
    "\n",
    "\n",
    "        negative_questions = self.dict_ds.loc[~self.dict_ds.paragraph.isin(list(sample.description))]\n",
    "        if self.class_imbalance:\n",
    "            negative_questions = negative_questions.sample(self.class_imbalance * len(sample))\n",
    "\n",
    "        negative_questions = negative_questions[['paragraph']]\n",
    "        negative_questions=negative_questions.rename(columns={'paragraph':'description'  })\n",
    "        negative_questions['question'] = question_row['questions']\n",
    "        negative_questions['Score'] = 0\n",
    "        sample = pd.concat([sample, negative_questions], ignore_index=True)\n",
    "        dataset.append(sample)\n",
    "    dataset = pd.concat(dataset).reset_index(drop=True)\n",
    "    print(dataset.columns)\n",
    "\n",
    "    train, test = train_test_split(dataset, test_size=0.15, random_state=42)\n",
    "    train_samples = []\n",
    "    for i in tqdm(range(len(train))):\n",
    "        current_sample = train.iloc[i]\n",
    "\n",
    "        train_samples.append(\n",
    "            InputExample(\n",
    "                texts=[current_sample[\"description\"], current_sample[\"question\"]],\n",
    "                label=current_sample[\"Score\"],\n",
    "            )\n",
    "        )\n",
    "    dev_samples = []\n",
    "    for i in tqdm(range(len(test))):\n",
    "        current_sample = test.iloc[i]\n",
    "\n",
    "        dev_samples.append(\n",
    "            InputExample(\n",
    "                texts=[current_sample[\"description\"], current_sample[\"question\"]],\n",
    "                label=current_sample[\"Score\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    return (train_samples, dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mR5ocxdOaz_o",
    "outputId": "914f6dc0-a654-4477-b1a2-112008f6a8f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 500.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['description', 'question', 'Score'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37/37 [00:00<00:00, 26793.72it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 18157.16it/s]\n"
     ]
    }
   ],
   "source": [
    "loader = ReRankingDataLoader(\n",
    "    dict_ds=paragraphs,\n",
    "    raw_ds=dataset,\n",
    "    class_imbalance=1)\n",
    "\n",
    "# train_samples, dev_samples = loader.load_data()\n",
    "train_samples, dev_samples = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHoS33xWbRFb",
    "outputId": "7bed83ca-cd32-4c98-ac0b-8f9f0bb5f54d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(train_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaGjaIjVsMt0"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "C9KflM2XfdYC"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ReRankerConfig:\n",
    "    base_model: str\n",
    "    train_data: Union[List[InputExample], DataLoader]\n",
    "    dev_data: List[InputExample]\n",
    "    device: str\n",
    "    epochs: int\n",
    "    batch_size: int\n",
    "    class_imbalance: int\n",
    "    warmup_steps: Optional[int] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if not isinstance(self.train_data, DataLoader):\n",
    "            self.train_data = DataLoader(\n",
    "                self.train_data, shuffle=True, batch_size=self.batch_size\n",
    "            )\n",
    "        if not self.warmup_steps:\n",
    "            self.warmup_steps = math.ceil(len(self.train_data) * self.epochs * 0.1)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"base_model\": self.base_model,\n",
    "            \"train_size\": len(self.train_data) * self.batch_size,\n",
    "            \"dev_size\": len(self.dev_data),\n",
    "            \"device\": self.device,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"class_imbalance\": self.class_imbalance\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t4MOXfQWpysL"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CEBinaryClassificationEvaluator\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "class ReRanker:\n",
    "    def __init__(self, config: ReRankerConfig) -> None:\n",
    "        self.__config = config\n",
    "        self.device = config.device\n",
    "        self.epochs = config.epochs\n",
    "        self.warmup_steps = config.warmup_steps\n",
    "        self.class_imbalance = config.class_imbalance\n",
    "        self.trained = False\n",
    "        self.model = CrossEncoder(config.base_model, num_labels=1, device=self.device)\n",
    "        self.evaluator = CEBinaryClassificationEvaluator.from_input_examples(config.dev_data, name=f\"{config.base_model} re-ranker tables\")\n",
    "        self.prediction_threshold = 0.5\n",
    "\n",
    "    def __call__(self, x: List[List[str]]) -> np.array:\n",
    "        \"\"\"\n",
    "        The predict function\n",
    "        @param x: The sample for the model to do predictions on. It should be a list of lists containing the pair `[candidate, query]`\n",
    "        @retruns np.array: Returns an array with the probability for each pair to be a match\n",
    "        \"\"\"\n",
    "        if self.trained:\n",
    "            return self.model.predict(x).tolist()\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Model is not trained! Train before making predictions!\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        return self.config.to_dict()\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        train_dataset: List[InputExample] = None,\n",
    "        test_dataset: List[InputExample] = None,\n",
    "        output_path: str = None,\n",
    "        ) -> Union[None, dict]:\n",
    "        \"\"\"\n",
    "        The main training function\n",
    "        @param train_dataset: The list of InputExamples used to train the model\n",
    "        @param test_dataset: The list of InputExamples used to evaluate the model. If `None` is provided then no evaluation will occur.\n",
    "        @param output_path: The path where the model weights should be saved locally. If `None` is provided then the model weigths will not be saved.\n",
    "        @returns Union[None, dict]: Returns either `None` or the results from evaluation\n",
    "        \"\"\"\n",
    "\n",
    "        if train_dataset:\n",
    "            train = train_dataset\n",
    "        else:\n",
    "            train = self.__config.train_data\n",
    "\n",
    "        if test_dataset:\n",
    "            test = test_dataset\n",
    "        else:\n",
    "            test = self.__config.dev_data\n",
    "\n",
    "        self.model.fit(\n",
    "            train_dataloader=train,\n",
    "            evaluator=self.evaluator,\n",
    "            evaluation_steps=math.ceil(len(train) * 0.5),\n",
    "            warmup_steps=self.warmup_steps,\n",
    "            output_path=output_path,\n",
    "        )\n",
    "        self.trained = True\n",
    "\n",
    "        if test:\n",
    "            return self.evaluate(test)\n",
    "\n",
    "    def evaluate(self, dataset: List[InputExample]):\n",
    "        evaluation_inputs = [t.texts for t in dataset]\n",
    "        evaluation_outputs = [t.label for t in dataset]\n",
    "\n",
    "        predictions = self.model.predict(evaluation_inputs) > self.prediction_threshold\n",
    "\n",
    "        return {\n",
    "            \"accuracy_score\": accuracy_score(evaluation_outputs, predictions),\n",
    "            \"f1_score\": f1_score(evaluation_outputs, predictions),\n",
    "            \"precision_score\": precision_score(evaluation_outputs, predictions),\n",
    "            \"recall_score\": recall_score(evaluation_outputs, predictions),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbosHUIxs3Ub"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341,
     "referenced_widgets": [
      "877dd2ff00e64562be171d2b4b7c2096",
      "01002f14fca648b18785344be2c4adf1",
      "c48f464d5c0645b1baa1ae7eaaab348a",
      "ec77f3c642384c678d338e52d7a41baf",
      "43019495e2f04e5eb5a152ef5d659a9f",
      "8ea47b725a6747a0876fc3a3a323ddb9",
      "a776f64e62c74154ab1a83a16fae4400",
      "0c7c537a5eda441ea552bbef5fe4ca38",
      "84b0bac344534475829e869283f4892d",
      "a094b0f1d06b478c8cdd5d934a8f33b0",
      "a98322bc76054235bb85700a11cfe8b3",
      "fcfc602c315849f39ef132ddc7e73638",
      "dfc2db2022c94cf4bafc3dbf9629bab1",
      "c8721cc6e55b47a589d91370bad29de6",
      "cfe3be006aa24736a11b82dd084925ee",
      "8a651af5a7834aa99945d17bd79f318d",
      "d5c1aa1ace4e4f9a87cdf475bab0e204",
      "849e6b6d68574c6b9eecaaf5ac4f0a7b",
      "738826f63313464e8122b752ba54a213",
      "270ae5d61edd49cb898c493f13196386",
      "ddc090942fe14dd39716b7e7197ce230",
      "e67f230e92bb47a581248cffe7daf9a8"
     ]
    },
    "id": "zEAtiwMfszOl",
    "outputId": "614db0c1-07ab-4cd1-c41f-b1913d61dd5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 530.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['description', 'question', 'Score'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37/37 [00:00<00:00, 24547.49it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 9464.90it/s]\n",
      "2025/04/09 15:12:01 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading tokenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49.0/49.0 [00:00<00:00, 252kB/s]\n",
      "Downloading vocab.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 996k/996k [00:00<00:00, 2.49MB/s]\n",
      "Downloading tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.96M/1.96M [00:00<00:00, 3.49MB/s]\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  20%|‚ñà‚ñà        | 1/5 [00:04<00:17,  4.28s/it]\u001b[A\n",
      "Iteration:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:06<00:09,  3.13s/it]\u001b[A\n",
      "Iteration:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:08<00:05,  2.96s/it]\u001b[A\n",
      "Iteration:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:11<00:02,  2.97s/it]\u001b[A\n",
      "Iteration: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:13<00:00,  2.65s/it]\u001b[A\n",
      "Epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.96s/it]\n",
      "2025/04/09 15:12:21 INFO mlflow.models.signature: Inferring model signature from type hints\n",
      "/usr/local/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:3139: UserWarning: Decorate your function with `@mlflow.pyfunc.utils.pyfunc` to enable auto data validation against model input type hints.\n",
      "  signature_from_type_hints = _infer_signature_from_type_hints(\n",
      "2025/04/09 15:12:21 INFO mlflow.models.signature: Failed to infer output type hint, setting output schema to AnyType. Unsupported type hint `<built-in function array>`. Type hints must be a list[...] where collection element type is one of these types: [<class 'int'>, <class 'str'>, <class 'bool'>, <class 'float'>, <class 'bytes'>, <class 'datetime.datetime'>], pydantic BaseModel subclasses, lists and dictionaries of primitive types, or typing.Any. Check https://mlflow.org/docs/latest/model/python_model.html#supported-type-hints for more details.\n",
      "2025/04/09 15:12:21 INFO mlflow.models.signature: Running the predict function to generate output based on input example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run rogue-tern-514 at: http://mlflow:5000/#/experiments/363813354049388447/runs/c88c693ef0a44916be3e14979e9a72ec\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/363813354049388447\n",
      "\n",
      "------------------------Model Configurations ---------------------------\n",
      "Model: bert-base-multilingual-cased \n",
      "Device: cpu \n",
      "Epochs: 4 \n",
      "Batch Size: 8 \n",
      "Class Imbalance: 1\n",
      "\n",
      "Metrics:  {'accuracy_score': 0.42857142857142855, 'f1_score': 0.3333333333333333, 'precision_score': 1.0, 'recall_score': 0.2, 'run_id': 'c88c693ef0a44916be3e14979e9a72ec'}\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "mlflow.set_experiment(\"Reranker Experiment\")\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "for config in generate_hyperparameters_grid(TRAINING_GRID):\n",
    "\n",
    "    loader = ReRankingDataLoader(\n",
    "        dict_ds=paragraphs,\n",
    "        raw_ds=dataset,\n",
    "        class_imbalance=config[\"class_imbalance\"])\n",
    "\n",
    "    train_samples, dev_samples = loader.load_data()\n",
    "\n",
    "    train_config = ReRankerConfig(\n",
    "        base_model=config[\"base_model\"],\n",
    "        train_data=train_samples,\n",
    "        dev_data=dev_samples,\n",
    "        device=config[\"device\"],\n",
    "        epochs=config[\"epochs\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        class_imbalance=config[\"class_imbalance\"]\n",
    "    )\n",
    "    with mlflow.start_run() as run:\n",
    "        model=ReRanker(train_config)\n",
    "        mlflow.log_params(train_config.to_dict())\n",
    "        metrics = model.fit()\n",
    "        mlflow.pyfunc.log_model(\n",
    "            \"reranking_crossencoder\",\n",
    "            python_model=model,\n",
    "            input_example=[[\"Reference sentence\", \"Validation sentence\"]],\n",
    "        )\n",
    "        mlflow.log_metrics(metrics)\n",
    "        metrics[\"run_id\"] = run.info.run_id\n",
    "\n",
    "    print(\"\\n------------------------Model Configurations ---------------------------\")\n",
    "    print(\"Model:\", train_config.base_model,\n",
    "      \"\\nDevice:\",  train_config.device,\n",
    "      \"\\nEpochs:\", train_config.epochs,\n",
    "      \"\\nBatch Size:\", train_config.batch_size,\n",
    "      \"\\nClass Imbalance:\", train_config.class_imbalance)\n",
    "    print(\"\\nMetrics: \", metrics)\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    config_df = pd.DataFrame([config])\n",
    "    run_df = pd.concat([config_df, metrics_df], axis=1)\n",
    "    results_df = pd.concat([results_df, run_df])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bCVi0jttcYi",
    "outputId": "0394a5ad-07a8-472d-d1b6-d73b70a8b8a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4791676700115204"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([\"Care sunt dotarile necesare pentru autovehicule?\", paragraphs.iloc[0].paragraph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.31.0 in /usr/local/lib/python3.10/site-packages (4.31.0)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in /usr/local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub==0.16.4 in /usr/local/lib/python3.10/site-packages (0.16.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (3.18.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (4.67.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (2024.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (2.2.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.6.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.15.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (4.13.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.21.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (9.1.0.70)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (0.6.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.3.1.170)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.10)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \\\n",
    "  transformers==4.31.0 \\\n",
    "  sentence-transformers==2.2.2 \\\n",
    "  huggingface-hub==0.16.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==0.31.0\n",
      "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (0.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (7.0.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (2.2.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/site-packages (from accelerate==0.31.0) (2.6.0)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (0.6.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (2.21.5)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (11.6.1.9)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (11.2.1.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.18.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (10.3.5.147)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.31.0) (4.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.31.0) (1.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.31.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.31.0) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.31.0) (3.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (3.10)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.31.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate==0.31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hdghaoTB_YFA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:09<00:00,  1.42s/it] \n"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(\"models:/ReRanker Demo@production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PyFuncModel' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloaded_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCare sunt dotarile necesare pentru autovehicule?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparagraphs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparagraph\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PyFuncModel' object is not callable"
     ]
    }
   ],
   "source": [
    "loaded_model([\"Care sunt dotarile necesare pentru autovehicule?\", paragraphs.iloc[0].paragraph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Array(string) (required)]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.metadata.get_input_schema().inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4765057861804962]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model._model_impl.predict([[\"Care sunt dotarile necesare pentru autovehicule?\", paragraphs.iloc[0].paragraph]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01002f14fca648b18785344be2c4adf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ea47b725a6747a0876fc3a3a323ddb9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a776f64e62c74154ab1a83a16fae4400",
      "value": "Epoch:‚Äá100%"
     }
    },
    "0c7c537a5eda441ea552bbef5fe4ca38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "270ae5d61edd49cb898c493f13196386": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43019495e2f04e5eb5a152ef5d659a9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "738826f63313464e8122b752ba54a213": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "849e6b6d68574c6b9eecaaf5ac4f0a7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84b0bac344534475829e869283f4892d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "877dd2ff00e64562be171d2b4b7c2096": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01002f14fca648b18785344be2c4adf1",
       "IPY_MODEL_c48f464d5c0645b1baa1ae7eaaab348a",
       "IPY_MODEL_ec77f3c642384c678d338e52d7a41baf"
      ],
      "layout": "IPY_MODEL_43019495e2f04e5eb5a152ef5d659a9f"
     }
    },
    "8a651af5a7834aa99945d17bd79f318d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ea47b725a6747a0876fc3a3a323ddb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a094b0f1d06b478c8cdd5d934a8f33b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a776f64e62c74154ab1a83a16fae4400": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a98322bc76054235bb85700a11cfe8b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c48f464d5c0645b1baa1ae7eaaab348a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c7c537a5eda441ea552bbef5fe4ca38",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_84b0bac344534475829e869283f4892d",
      "value": 1
     }
    },
    "c8721cc6e55b47a589d91370bad29de6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_738826f63313464e8122b752ba54a213",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_270ae5d61edd49cb898c493f13196386",
      "value": 5
     }
    },
    "cfe3be006aa24736a11b82dd084925ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddc090942fe14dd39716b7e7197ce230",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e67f230e92bb47a581248cffe7daf9a8",
      "value": "‚Äá5/5‚Äá[01:31&lt;00:00,‚Äá17.93s/it]"
     }
    },
    "d5c1aa1ace4e4f9a87cdf475bab0e204": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddc090942fe14dd39716b7e7197ce230": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfc2db2022c94cf4bafc3dbf9629bab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5c1aa1ace4e4f9a87cdf475bab0e204",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_849e6b6d68574c6b9eecaaf5ac4f0a7b",
      "value": "Iteration:‚Äá100%"
     }
    },
    "e67f230e92bb47a581248cffe7daf9a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec77f3c642384c678d338e52d7a41baf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a094b0f1d06b478c8cdd5d934a8f33b0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a98322bc76054235bb85700a11cfe8b3",
      "value": "‚Äá1/1‚Äá[01:36&lt;00:00,‚Äá96.19s/it]"
     }
    },
    "fcfc602c315849f39ef132ddc7e73638": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dfc2db2022c94cf4bafc3dbf9629bab1",
       "IPY_MODEL_c8721cc6e55b47a589d91370bad29de6",
       "IPY_MODEL_cfe3be006aa24736a11b82dd084925ee"
      ],
      "layout": "IPY_MODEL_8a651af5a7834aa99945d17bd79f318d"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
